# live

---

​		直播的原理是在基础的流媒体转码之外，加上网络相关的协议处理。协议依据处理流媒体的主动与被动分拉流和推流。流媒体服务器的主要作用是进行媒体源的广播分发。

- 推流：一般由媒体源将流媒体资源主动推流到流媒体服务器
- 拉流：由中心信令控制系统向媒体源下发拉流请求，媒体源将媒体资源推流到流媒体服务器
  - 实际上可以将媒体源看做一个独立的媒体服务，视为两个系统的媒体推送

![img](https://pics0.baidu.com/feed/cc11728b4710b912f87b6cc52344f50f9345229c.jpeg@f_auto?token=017d2901513d612cc46ede56e71b8d5b)

![img](https://pics3.baidu.com/feed/7a899e510fb30f24c0cbaf8a2e2cd84fac4b032f.jpeg@f_auto?token=2a42dabdb2f9c893e9c45c1f860c9c18)



## 参考

[直播相关讲解 -- 视频直播技术大全、直播架构、技术原理和实现思路方案整理(转载)-CSDN博客](https://blog.csdn.net/weixin_46932303/article/details/121581351)

[HLS直播协议在B站的实践 - 哔哩哔哩 (bilibili.com)](https://www.bilibili.com/read/cv18179472/)

[「网站架构」Nginx 4层、7层代理配置，正向代理、反向代理详解 (baidu.com)](https://baijiahao.baidu.com/s?id=1764793906954532912)



## 场景简介

### 直播

​		媒体源主动将媒体资源推送到流媒体直播平台，流媒体直播平台进行资源分发。

​		流媒体直播平台在资源分发的功能之外，可能还具有其它的功能：

- 直播转码：
  - 水印
  - 高清、流畅转换
  - 码率限制
  - 直播录像

​		如果不需要任何转码处理，且没有安全权限等设置的话，可以直接从流媒体服务中拉取视频观流看的，且推流和观看地址一般是一样。

​		**研发直播转码程序的意义在于一些高级功能**，如直播倒计时、信号中断自动补帧、导播/轮播、画中画等等。这部分正是一个直播系统的技术核心，毕竟流媒体服务器一般是协议兼容且现成的。

![img](https://pics0.baidu.com/feed/2f738bd4b31c870138ea0ae3c3c697230608ff99.jpeg@f_auto?token=ae68825e6ccf47125eacca1ed5178fa7)





### 转发

​		向另一流媒体平台拉取媒体资源。

### 录播

​		录播即文件直播，不是Real Time的实录实播，而是将已经准备好的媒体资源文件进行分发。可以不需要特定的流媒体服务参与，只需要一般的资源分发服务即可。



## 直播CDN

​		用户直接拉取流媒体服务的视频流是可以观看的，但在流媒体资源用户并发较高的情况下，中心媒体服务器的性能压力和带宽压力较高。

​		此时应用CDN技术，将分发压力向边缘节点分散。直播CDN实际上也可以看作是流媒体服务。

​		使用直播CDN可以由媒体源直接将媒体资源推送到直播CDN，一般是通过RTMP协议推送到CDN服务；也有主动拉取的CDN服务。

> ​		但主动拉取的CDN服务不建议使用，因为主动拉取的CDN服务可能会同时存在多个CDN回源，这样就很难准确预估带宽的需要

​		**直播CDN一般提供自动转观看协议的功能**，一般会提供RTMP、HTTP-FLV、WEBRTC、HLS等协议的观看地址。

​		一般直播CDN是不提供转码服务的，如高清、流畅转换等。

> 因为协议转换并不需要太多的性能，但转码非常耗费性能。

![img](https://pics7.baidu.com/feed/314e251f95cad1c8d53e9e9e98876e05cb3d51c3.jpeg@f_auto?token=e11d986ce40cd0b27000c7fd5db9790f)

## 协议选型

### `RTMP/HTTP-FLV`

​		RTMP和HTTP-FLV二者都建立在FLV封装之上。

- `RTMP`一般用作直播源在直播系统内部的推流传递
  - 推流到流媒体服务器：
  - 推流到直播`CDN`
- `HTTP-FLV`一般用于向客户端推流观看

![img](https://pics2.baidu.com/feed/79f0f736afc37931d93673e7a7b7ad4942a91125.jpeg@f_auto?token=5769d0830d1dc1ab0599e1b1ab775b74)

​		对比：

#### `RTMP`

- 可以推流和拉流
- `rtmp://`，推流地址和播放地址一致
- 一般只用作直播源推流到流媒体、推流到CDN
  - 客户端浏览器摒弃`Flash`
  - 高并发下不稳定
- 需要支持`RTMP`的流媒体服务器
  - `SRS`
  -  `ZLMediaServer `
  - `Red5`
  - `Nginx-rtmp`
    - 加入了RTMP插件的Nginx
- 延迟是比较低的，大概在1-3秒左右
- 是建立在TCP长连接通道上的，在封装音视频数据时会强制切片，限制每个数据包的大小
  - 强制切片也一定程度保证了实时性
  - 有一定的弱网抵抗能力
    - 因为每个数据包都不会太大，所以当某个数据包校验失败时，重新发送的成本不会太大
  - 由于合并数据包会加大CPU压力，所以是有一定的性能消耗的
- RTMP协议还有一些变种协议，如RTMPT、RTMPS等

![img](https://pics5.baidu.com/feed/54fbb2fb43166d22464ce8c40b5013fb9052d222.jpeg@f_auto?token=37f1815829b008477c522b823d5d6e59)

#### `http-flv`

- 一般只能用作拉流

- `http://`，基于HTTP协议的HTTP-FLV可以简单地理解为RTMP的HTTP协议版本

  - 功能和工作原理上是相似
  - 切片数据

-  HTTP-FLV延迟会略高于RTMP，但是HTTP-FLV相对RTMP适配更多的播放场景

- 一般需要需加入插件才能播放，如网页需要引入`flv.js`

  - > B站开源的`flv.js`

- 需要特定的流媒体服务器

  - 加入了HTTP-FLV插件的Nginx

  - > Nginx的HTTP-FLV插件是包含RTMP功能的，所以一般HTTP-FLV的流媒体服务，推流是以RTMP协议，拉流是用HTTP-FLV协议

- 现在比较流行的方案是，直播源推流是RTMP协议，直播拉流观看是HTTP-FLV协议。

![img](https://pics6.baidu.com/feed/267f9e2f070828386bbed00eeaeab30d4d08f1fc.jpeg@f_auto?token=d62fca0268226ecc560fea58b2bf37ea)



### `HLS`

- 一般只用作拉流观看
- 从严格意义上讲，HLS协议并不是流式协议
  - 通过HTTP协议批量下载静态文件
  - 这些静态文件都是直接写入磁盘的
  - 多个只有几秒长度的**.ts碎片视频文件**
  - 记录视频文件地址的**.m3u8索引文件**
- `http://****.m3u8`
  - 实际上这个地址就是索引文件的地址
  - 客户端获取到索引文件后，就可以下载对应的碎片视频文件并开始播放了
  - 实际上是通过HTTP协议请求文件
- 不需要特殊的流媒体服务器
  - HLS相关文件是直接写入磁盘的，使用Nginx等HTTP服务就可以
- 适配多种播放场景，一般加入插件就可以播放
  - 网页加入HLS的js插件就可以播放了，苹果设备是原生支持HLS协议的
- HLS协议可以用于点播和直播
- **HLS协议的.m3u8索引文件支持二级索**引
  - 就是高清、标清、流畅等多个观看地址可以整合到一个索引文件
  - 播放器可以根据当前带宽自动切换不同的观看地址
- **HLS协议**的视频文件、索引文件都是直接写入磁盘的，长时间且多个直播流同时处理，**会造成磁盘写入压力过大**，机械磁盘可能会磁道会损坏，固态硬盘的寿命会加速衰减。
  - 最好挂载一段内存空间作为HLS相关文件的写入位置，则不会造成磁盘写入压力过大的问题。
- HLS协议是苹果推出的标准，MPEG-DASH是国际标准协议
  - 二者相差不多

![img](https://pics2.baidu.com/feed/359b033b5bb5c9ea6e695895814aac0c3bf3b3a9.jpeg@f_auto?token=2585fbb963d7a88cdc7dbb5e8f83cba8)

#### 点播

​		.m3u8索引文件会记录所有的碎片视频文件地址，HLS在**点播**的场景下，**优势是更加明显的。**

​		HLS的相关文件是无状态的静态文件，且每个文件的大小是有限的，所以负载均衡、CDN加速的效果更佳明显。

​		HLS协议的点播视频，会比.mp4、.flv的视频更快地播放出来，且在加载中跳转视频也会更加顺滑。

![img](https://pics2.baidu.com/feed/c2fdfc039245d688f5aec1d2e9b16712d31b2492.jpeg@f_auto?token=65b0a49c18a3d557d4e66495147101c1)



#### 直播

- 转码软件可以直接生成HLS相关文件到磁盘，客户端通过HTTP服务下载文件即可。
- 也可以在Nginx加入RTMP插件，转码软件以RTMP协议推流到Nginx，再由Nginx生成HLS相关文件。

> **后一种方案更加推荐**，因为它对于前期研发和后期对接直播CDN的过度更加顺滑。

![img](https://pics6.baidu.com/feed/060828381f30e92477ce4c77017b740a1c95f78a.jpeg@f_auto?token=a04df1fb3ca087bd4c29948fac83f972)

​		直播场景下的HLS相关文件与点播是有不同

- 视频流数据每几秒会打包成一个以.ts为后缀的碎片视频文件，每生成一个新的视频文件都会同步更新.m3u8索引文件。
- 碎片视频文件的个数是有**上限的**，当达到上限后，默认会将最旧的视频文件删除且更新.m3u8索引文件
- 所以在直播的场景下，客户端也需要不断定时重新获取.m3u8索引文件
- HLS协议在直播的场景下是没什么优势的
  - 虽然HLS协议的直播流可以适配很多播放场景
  - 但是由于需要生成静态文件，**直播延迟很大**，**大概在5-30秒左右**
  - 使用直播CDN的话，由于边缘节点同步等问题，直播延迟甚至可能会达到1分钟左右
- HLS协议在直播切换时一定的优势
  - 在直播时移（直播转点播，点播转直播）的场景， 理论上只需要修改索引文件就可以了
  - 不需要重新进行耗费性能的编解码



### `webRTC`

​		WebRTC协议其实并不是为了直播场景而设计的，WebRTC是一种点对点的视频/语音通话协议。

- 基于UDP的，建立通信后，不断以流式发送数据，**所以延迟会比RTMP还要低**
- **交互性较高的直播场景**，如直播带货等场景，会使用WebRTC作为推流和观看协议
- 支持推流和拉流
- `webrtc://`
  - 推流和拉流地址一般是一样的
- 点对点的协议
  - 通过搭建`p2p`信令服务器，通过信令服务器调度直播源直接向某个播放端推流
    - 播放端作为一个推流端，经信令服务器调度向另一个播放端推流
    - 从而进行分布式推流
  - 在直播场景的话，可以通过**搭建WebRTC服务器**进行集中式推流
    - 流媒体服务软件可以使用`SRS/ mediasoup / janus`等

![img](https://pics1.baidu.com/feed/e7cd7b899e510fb3b40786889440d299d1430c16.jpeg@f_auto?token=84be192ef736cc225d81efb111eb526b)



### `rtsp`

​		**RTSP一般不用作直播场景**，`RTSP`一般用作摄像头、监控等硬件设备的实时视频流观看与推送上。

​		`RTSP`协议也支持推流/拉流，且支持`TCP`、`UDP`切换以及其他诸多优点。

​		但是泛用性不足，特别是现在的浏览器都不支持`RTSP`的播放。



## 延迟优化

​		造成延迟的原因：

- 协议传输的通信延迟
- 推流延迟
- 转码延迟
- 拉流延迟

​		延迟优化：

- 协议优化
- 禁止B帧
- GPU硬件加速
- 流媒体服务缓存I帧
- 码率限制