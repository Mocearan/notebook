# Codec

---

​		对音频或视频进行编码最重要目的就是**为了进行数据压缩，以此来降低数据传输和存储的成本**。

​		对信息进行压缩，可以从这几个方面着手：

- 1）**信源包含的符号出现概率的非均匀性，使得信源是可以被压缩的。**熵编码就利用信源的统计特性进行码率压缩的编码方式。比如著名的哈夫曼编码（也是熵编码的一种），就是当信源中各符号的出现概率都一样时编码效率最低。
- 2）**信源的相关性，使得信源是可以被压缩的。**比如信息 A 和信息 B 的相关性，使得我们可以由信息 A 加残差 D（D = A - B） 来推导信息 B，这样只编码 A 和 D 来实现压缩，这就是所谓的差分编码技术。
- 3）**人的感知对不同信源的敏感度不一样，使得信源是可以被压缩的。**对人感知不敏感的信息进行部分或全部忽略来实现压缩。

## 参考

[实时音视频开发理论必备：如何省流量？视频高度压缩背后的预测技术-实时音视频/专项技术区 - 即时通讯开发者社区! (52im.net)](http://www.52im.net/thread-3581-1-1.html)

## 音频编码

![img](https://pics7.baidu.com/feed/e61190ef76c6a7ef01ae77147e8fff5df2de66fe.jpeg@f_auto?token=84e5eea3d1eeafb271fb080a8692422e)

- `PCM`，无压缩。一种将模拟信号的数字化方法，无损编码。
  - PCM 是音频原始数据的基础格式

- `WAV (Waveform Audio File Format)`: 无压缩。提供高质量的音频数据，但文件较大。
  - 有多种实现方式，但是都不会进行压缩操作。
  - 其中一种实现就是在 PCM 数据格式的前面加上 44 字节，分别用来描述 PCM 的采样率、声道数、数据格式等信息。
  - 音质非常好，大量软件都支持。

- `MP3 (MPEG Audio Layer III)`: 最普遍的音频压缩格式，以较小的文件大小提供合理的声音质量。
  - 有损压缩。音质在 128 Kbps 以上表现还不错，压缩比比较高，大量软件和硬件都支持，兼容性好。

- `AAC (Advanced Audio Coding)`: 与`MP3`相比，它提供更好的音质和压缩率，被广泛用于`Apple`设备。
  - 有损压缩。在小于 128 Kbps 的码率下表现优异，并且多用于视频中的音频编码。
  - AAC 在短视频和直播场景广泛使用。

- `FLAC (Free Lossless Audio Codec)`: 无损压缩的音频格式，可以在不损失任何数据的情况下减小文件大小。
- `OGG (Ogg Vorbis)`: 一种开源的音频压缩格式，通常提供比MP3更好的压缩率。
- `OPUS`，有损压缩。可以用比 MP3 更小的码率实现比 MP3 更好的音质，高中低码率下均有良好的表现，兼容性不够好，流媒体特性不支持。
  - 适用于语音聊天的音频消息场景。




### **时域冗余**

​		音频信号时域上的冗余主要表现为下面几个方面：

- **幅度分布的非均匀性**：统计表明，在大多数类型的音频信号中，小幅度样值出现的概率比大幅度样值出现的概率要高。
  - 人的语音中，间歇、停顿等出现了大量的低电平样值；
  - 实际讲话的功率电平也趋向于出现在编码范围的较低电平端。
- **样值之间的相关性**：对语音波形的分析表明，相邻样值之间存在很强的相关性。
  - 当采样频率为 8k Hz 时，相邻样值之间的相关系数大于 0.85。
  - 如果进一步提高采样频率，则相邻样值之间的相关性将更强。
  - 因此，根据较强的维相关性，可以利用差分编码技术进行有效的数据压缩。
- **信号周期之间的相关性**：虽然音频信号分布于 20-20k Hz 的频带范围，但在特定的瞬间，某一声音却往往只是该频带内的少数频率成分在起作用。
  - 当声音中只存在少数几个频率时，就会像某些振荡波形一样，在周期与周期之间存在着一定的相关性。
  - 利用音频信号周期之间的相关性进行压缩的编码器，比仅仅利用邻近样值间的相关性的编码器效果好，但要复杂得多。
- **静止系数**：两个人之间打电话，平均每人讲话时间为通话时间的一半，并且在这一半的通话过程中也会出现间歇停顿。
  - 分析表明，话音间隙使全双工话路的典型效率约为 40% (或称静止系数为 0.6)。
  - 显然，话音间隔本身就是一种冗余，若能正确检测出这些静止段，可以进行压缩。
- **长时自相关性**：
  - 统计样值、周期间的一些相关性时，在 20 ms 时间间隔内进行统计的称为短时自相关函数。
  - 如果在较长的时间间隔（如几十秒）内进行统计时，则称为长时自相关函数。
  - 长时统计表明，当采样频率为 8k Hz 时，相邻的样值之间的平均相关系数可高达 0.9。
  - 这样的相关性也可以进行压缩。



### 频域冗余

- **长时功率谱密度的非均匀性**：长时功率谱密度函数，其功率谱呈现明显的非平坦性。
  - 从统计的观点看，这意味着没有充分利用给定的频段，或者说存在固有的冗余度。
  - 功率谱的高频成分能量较低。
- **语音特有的短时功率谱密度**：语音信号的短时功率谱，在某些频率上出现峰值，而在另一些频率上出现谷值。
  - 这些峰值频率，也就是能量较大的频率，通常称其为共振峰频率。共振峰频率不止一个，最主要的是前三个，由它们决定不同的语音特征。
  - 另外，整个功率谱也是随频率的增加而递减的。更重要的是整个功率谱的细节以基音频率为基础，形成了高次谐波结构。



### 听觉冗余

​	充分利用人类听觉的生理和心理特性对音频信号感知的影响。利用人耳的频率特性灵敏度以及掩蔽效应，可以压缩数字音频的数据量。

- 可以**将会被掩蔽的信号分量在传输之前就去除**，因为这部分信号即使传输了也不会被听见。
- 可以**不理会可能被掩蔽的量化噪声**。
- 可以**将人耳不敏感的频率信号在数字化之前滤除**，如语音信号只保留 300-3400 Hz 的信号。

​		人耳的掩蔽效应包括下面几种：

- **最小可闻阈值**：一个频率的声音能量小于某个阈值之后，人耳就会听不到。
- **频率掩蔽效应**：当有能量较大的声音出现的时候，该声音频率附近的其它频率的人耳可听阈值会提高很多，这样就会导致人耳听不到这些频率低于阈值的信号，即这些信号被掩蔽。

- **时域掩蔽效应**：当强音信号和弱音信号同时出现时，可能会发生前掩蔽、同时掩蔽、后掩蔽。
  - 前掩蔽是指人耳在听到强信号之前的短暂时间内，已经存在的弱信号会被掩蔽而听不到。
  - 同时掩蔽是指当强信号与弱信号同时存在时，弱信号会被强信号所掩蔽而听不到。
  - 后掩蔽是指当强信号消失后，需经过较长的一段时间才能重新听见弱信号。
  - 这些被掩蔽的弱信号即可视为冗余信号。

![图片](https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSueh8rjibvrKYLZ7jWN4IUkSdMSic13Ofgg3wg9ZelwcXBHibC4Qee9tVlvkwEJrjj8T7zufkoezFdibqiaQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

![图片](https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSueh8rjibvrKYLZ7jWN4IUkSdMIsYdHfVoGaOn26466aws6Tnr3TSMGRGYhI6zyTAlKRCJibqcKBQbKGA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

## 视频编码

​		视频编码最重要的目的也是**为了进行数据压缩，以此来降低数据传输和存储成本**。去除冗余信息。

​		通常有2种方法：一是压缩分辨率，去除重复多余的信息；二是质量压缩，去掉一些人感知不敏感的信息。

> 以一路分辨率 720x1280（常说的 720P），帧率为 30 fps 的视频为例，如果不经过编码压缩，直接传输或存储原始的 RGB 数据，对应的码率是：`720 * 1280 * 3 * 8 * 30 = 632.8125 Mbps (宽 * 高 * 像素字节数 * 字节比特数 * 帧数)`。一分钟的时间所需要的数据量是：`632.8125 Mbps * 60s = 4.63 GB`。

​		视频信息主要包括这几个方面的冗余：

- **空间冗余**：在同一张帧之中，相邻的像素之间通常有很强的关连性，这样的关连性即为空间上的冗余信息。
- **时间冗余**：在视频信息中，相邻的帧与帧之间通常有很强的关连性，这样的关连性即为时间上的冗余信息。
- **编码冗余**：视频中不同数据出现的概率不同，欲编码的符号的几率分布是不均匀的。
- **视觉冗余**：人的视觉系统对某些细节不敏感。视觉上的冗余信息是指在人在观看视频时，人眼无法察觉的信息。

![在这里插入图片描述](https://img-blog.csdnimg.cn/499580daf9ae4caf9c37223d6a7b6a4d.png#pic_center#pic_center)



### 编码标准发展

​		现在常见的视频编码格式有 3 个大的系列，分别由不同的组织主导制定

- **ISO-MPEG/ITU-T 系列**：由国际标准组织机构（ISO）下属的运动图象专家组（MPEG）和国际电传视讯联盟远程通信标准化组织（ITU-T）开发的系列编码标准。

  - **H.264**，也被称为高级视频编码（Advanced Video Coding，简称 **AVC**），是一种被广泛使用的高精度视频的录制、压缩和发布格式。该标准引入了一系列新的能够**大大提高压缩性能的技术**，并能够同时在高码率端和低码率端大大超越以前的诸标准。

  - **H.265**，也被称为高效率视频编码（High Efficiency Video Coding，简称 **HEVC**），是 H.264 的继任者。HEVC 被认为不仅提升图像质量，同时也能达到**H.264 两倍的压缩率**（等同于同样画面质量下比特率减少了 50%），可**支持 4K 分辨率甚至到超高画质**电视，**最高分辨率可达到 8192×4320（8K 分辨率）**，这是目前发展的趋势。

  - **H.266**，也被称为多功能视频编码（Versatile Video Coding，简称 **VVC**），是 H.265 的继任者。VVC 对 8K 超高清、屏幕、高动态和 360 度全景视频**等新的视频类型以及自适应带宽和分辨率的流媒体和实时通信等应用有了更好的支持**。根据最近的 `JVET `官方主观测试结果，VVC 的平均编码性能相对 HEVC 的提高已经可以达到 49%。

    > ITU-T是最先研发了音视频通话的，最先研究出了H261，后来发布H262,H263，指导后来的H视频编解码器，这是ITU-T的H26x系列。
    >
    > ISO也研发了MPEG-1、MPEG-2、MPEG-3、MPEG-4标准，对应H26x系列。
    >
    > 
    >
    > 1998年双方合作，在H264的基础上双方进行共同研发，发布了后来的更成熟的H264，作为后来的结晶:
    >
    > - 在ITU-T组织中依然称为H264
    >
    > - 但是在ISO组织中称为MPEG4-avc
    >
    >   ​	这只是在不同组织中的称呼名字。
    >
    >   
    >
    > ​        随着社会的进步，广泛的出现了4K、8K视频，这对于H264来说已经存在明显不足了，所以两个组织又一起合作H264的基础上研发了H265.达到更高压缩的同时实现画面更清晰H265编解码技术在ITU-T组织中称为H265，在ISO组织中称为HEVC。

- **AOM 系列**：前身是由 Google 主导的 VPx 系列的编码标准。后续由多家公司组件成立了开放媒体联盟（Alliance for Open Media，AOM）继续开发新的编码标准。

  - **VP8**，是一个开放的图像压缩格式，最早由 On2 Technologiesis 开发，随后由 Google 发布。同时 Google 也发布了 VP8 编码的实做库：libvpx，以 BSD 授权条款的方式发布，随后也附加了专利使用权。而在经过一些争论之后，最终 VP8 的授权确认为一个开放源代码授权。
  - **VP9**，是 Google 提供的开源的免费视频编码格式，是 VP8 的后续版本。
  - **AV1**，Alliance for Open Media Video 1 是由 AOM（Alliance for Open Media，开放媒体联盟）制定的一个开源、免版权费的视频编码格式，目标是解决 H.265 昂贵的专利费用和复杂的专利授权问题并成为新一代领先的免版权费的编码标准。此外，AV1 是 Google 制定的 VP9 标准的继任者，也是 H.265 强有力的竞争者。

- **AVS 系列**：AVS（Audio Video coding Standard）是中国具备自主知识产权的系列编码标准。

  - **AVS2**，第二代数字音视频编解码技术标准（AVS2），其首要应用目标是超高清晰度视频，支持超高分辨率（4K 以上）、高动态范围视频的高效压缩。
  - **AVS3**，AVS3 增加了对 8K 分辨率的支持，该技术将使用于中央广播电视总台 8K 超高清频道。

  > 只是仅仅用于机顶盒，广播电视，其他领域并没有用到。

​		

​	

### 视频编码流程

![img](https://raw.githubusercontent.com/Mocearan/picgo-server/main/v2-9f48db588dff3457c2924fde6290c404_720w.webp)

- 原始视频信号采集：视频信号通过摄像头等设备捕获，形成未压缩的原始视频数据

- 颜色空间转换：通常将原始视频数据从RGB色彩空间转换为YUV色彩空间

  - Y代表亮度信息（Luminance），U和V代表色度信息（Chrominance）
  - 这种转换有助于减少文件大小，因为人眼对亮度的敏感度远高于色度
  - 在YUV色彩空间中，色度信息（U和V）的视觉重要性低于亮度信息（Y）
    - 可以使用4:2:0或4:2:2等降采样方式
    - 大幅减少要处理的数据，尤其对于高分辨率视频，降低色度分辨率可以显著提升压缩效率

- 帧分割

  - 帧分割和选择是帮助编码器管理帧的信息量
    - I帧：关键帧，采用帧内压缩技术。
    - P帧：前向参考帧，只参考前面已经处理的帧。采用帧间压缩技术。
    - B帧：双向参考帧，既参考面帧，又参考后面的帧。采用帧间压缩技术。
  - 编码器会分析和选择关键帧间的P帧和B帧，以向观众提供最佳的图像质量，并在维持高效压缩的同时稳定视频流

- 去除时间和空间冗余：

  - 帧内预测压缩：利用像素之间的相关性，使用如离散余弦变换（DCT）等方法将空间域信号转换到频率域，通过去除高频信息（人眼不易察觉的细节）来减少数据量。

    - 整数离散余弦变换：高频信息通常会被量化。

      - 量化的过程会将较小的部分（常为高频信息）简化到较低的比特位，丢弃那些人眼不敏感的信息。

      > 解决的是视觉冗余问题。利用傅里叶变换把复杂波形变换成许多正弦波，在频率上压缩没有一致性的波。

  - 帧间预测压缩：分析视频序列中的帧，编码器只存储关键帧和与关键帧的差异。

    - 运动补偿：运动补偿是通过先前的局部图像来预测、补偿当前的局部图像，它是减少帧序列冗余信息的有效方法。
    - 运动表示：不同区域的图像需要使用不同的运动矢量来描述运动信息。
    - 运动估计：运动估计是从视频序列中抽取运动信息的一整套技术。

    - 视频在一段连续时间内的多张照片在画面整体上其实没有太大变化，针对这段时间内相同的数据可以进行重复度的压缩。


- 量化：通过量化将频率域的数值进行近似，从而丢弃一些细节信息。

  - 量化程度越高，压缩率越大
  - 但会导致更显著的图像质量损失。
  - 量化涉及使用一个量化矩阵，对频率域中的DCT系数进行简化。

    - 这些矩阵是根据视频的内容和人眼的视觉感知特性设计的，常见的量化矩阵会对高频分量采用较大数值，从而在不显著影响画质的情况下，丢弃信息。


- 熵编码：CABAC压缩，无损压缩。对量化后的数据进行进一步的压缩，以减小位流大小。

  > 这是真正的编码环节，将前面3步处理得到的数据使用编码算法编码为最终的码流。


  - 霍夫曼编码通过分析各个符号在数据流中出现的频率，生成不同长度的编码。

    - 频繁出现的符号使用短编码，不常出现的符号使用长编码，使得整体的编码长度最小化。
  - 算术编码是将整个消息视为一个连续的数字范围，根据字符概率分布动态缩小范围。

    - 与霍夫曼编码相比，算术编码通常能达到更高的压缩率，因为它能够以更细粒度的方式对数据进行编码。
  - 编码的熵编码数据流可以与其他信息（如时间戳、帧信息等）一起组合形成输出数据

- 生成编码流：将处理后的数据组合形成压缩后的视频文件。


  - 常见的视频编码标准有H.264、H.265（HEVC）、VP9等。



### 编码压缩

#### 划分宏块

​		信源编码器将图像划分为宏块。

- 在H.264中的宏块大小是固定的16x16
- 在H.265中宏块的大小是可变的，最小8x8最大64x64。

#### 帧内预测

##### 空间冗余

​		利用一幅图像中像素之间的关联关系来去除冗余信息。

​		一幅图像中相邻像素的亮度和色度信息是比较接近的，并且亮度和色度信息也是逐渐变化的，不太会出现突变。也就是说，图像具有空间相关性。利用这种相关性，视频压缩就可以去除空间冗余信息。





#### 帧间预测

​		消除时域冗余信息。利用之前编码过的图像来预测要编码的图像。其中涉及到两个重要的概念：运动估计和运动补偿。

- 运动估计：寻找当前编码的块在已编码的图像（参考帧）中的最佳对应块，并且计算出对应块的偏移（运动矢量）。
- 运动补偿：根据运动矢量和帧间预测方法，求得当前帧的估计值过程。
  - 其实就是将运动矢量参数贴到参考帧上获取当前帧。
  - 另外运动补偿是一个过程。

##### 时间冗余

​		一个视频中，一般前后两帧图像往往变化比较小，这就是视频的时间相关性。而视频一般往往一秒会播放20-30帧，所以存在大量重复的图像数据，所以会有巨大的压缩空间。在前面某一帧找到一个内容很接近的块，那么只要再加上运动矢量，就可以表示当前的块。



#### 整数离散余弦变换 DCT

​		整数离散余弦变换（Discrete Cosine Transform，DCT），将空间上的相关性变为频域上无关的数据然后进行量化，解决的是视觉冗余问题。



#### 量化

​		DCT变换并没有进行压缩，压缩需要后面一步的支持——量化。

​		量化基本决定了视频的码率，视频的码率又从一定程度上决定了视频的质量。



#### 熵编码

​		视频编码中真正实现“压缩”的步骤，主要去除信息熵冗余。而前面说的去除空间、时间、视觉冗余，其实都是为这一步做准备的。

​		视频编码常用的有两种：变长编码（哈夫曼编码）、算术编码。H.264 最后将结果进行熵编码，分为`上下文自适应的变长编码（Context-based Adaptive Variable-Length Coding，CAVLC）`与`上下文自适应的二进制算术编码（Context-based Adaptive Binary Arithmetic Coding，CABAC）`。

​		
