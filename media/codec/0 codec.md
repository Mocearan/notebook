# Codec

---

​		对音频或视频进行编码最重要目的就是**为了进行数据压缩，以此来降低数据传输和存储的成本**。

​		对信息进行压缩，可以从这几个方面着手：

- 1）**信源包含的符号出现概率的非均匀性，使得信源是可以被压缩的。**熵编码就利用信源的统计特性进行码率压缩的编码方式。比如著名的哈夫曼编码（也是熵编码的一种），就是当信源中各符号的出现概率都一样时编码效率最低。
- 2）**信源的相关性，使得信源是可以被压缩的。**比如信息 A 和信息 B 的相关性，使得我们可以由信息 A 加残差 D（D = A - B） 来推导信息 B，这样只编码 A 和 D 来实现压缩，这就是所谓的差分编码技术。
- 3）**人的感知对不同信源的敏感度不一样，使得信源是可以被压缩的。**对人感知不敏感的信息进行部分或全部忽略来实现压缩。

## 参考

[实时音视频开发理论必备：如何省流量？视频高度压缩背后的预测技术-实时音视频/专项技术区 - 即时通讯开发者社区! (52im.net)](http://www.52im.net/thread-3581-1-1.html)

## 音频编码

![img](https://pics7.baidu.com/feed/e61190ef76c6a7ef01ae77147e8fff5df2de66fe.jpeg@f_auto?token=84e5eea3d1eeafb271fb080a8692422e)

- `PCM`，无压缩。一种将模拟信号的数字化方法，无损编码。
  - PCM 是音频原始数据的基础格式

- `WAV (Waveform Audio File Format)`: 无压缩。提供高质量的音频数据，但文件较大。
  - 有多种实现方式，但是都不会进行压缩操作。
  - 其中一种实现就是在 PCM 数据格式的前面加上 44 字节，分别用来描述 PCM 的采样率、声道数、数据格式等信息。
  - 音质非常好，大量软件都支持。

- `MP3 (MPEG Audio Layer III)`: 最普遍的音频压缩格式，以较小的文件大小提供合理的声音质量。
  - 有损压缩。音质在 128 Kbps 以上表现还不错，压缩比比较高，大量软件和硬件都支持，兼容性好。

- `AAC (Advanced Audio Coding)`: 与`MP3`相比，它提供更好的音质和压缩率，被广泛用于`Apple`设备。
  - 有损压缩。在小于 128 Kbps 的码率下表现优异，并且多用于视频中的音频编码。
  - AAC 在短视频和直播场景广泛使用。

- `FLAC (Free Lossless Audio Codec)`: 无损压缩的音频格式，可以在不损失任何数据的情况下减小文件大小。
- `OGG (Ogg Vorbis)`: 一种开源的音频压缩格式，通常提供比MP3更好的压缩率。
- `OPUS`，有损压缩。可以用比 MP3 更小的码率实现比 MP3 更好的音质，高中低码率下均有良好的表现，兼容性不够好，流媒体特性不支持。
  - 适用于语音聊天的音频消息场景。




### **时域冗余**

​		音频信号时域上的冗余主要表现为下面几个方面：

- **幅度分布的非均匀性**：统计表明，在大多数类型的音频信号中，小幅度样值出现的概率比大幅度样值出现的概率要高。
  - 人的语音中，间歇、停顿等出现了大量的低电平样值；
  - 实际讲话的功率电平也趋向于出现在编码范围的较低电平端。
- **样值之间的相关性**：对语音波形的分析表明，相邻样值之间存在很强的相关性。
  - 当采样频率为 8k Hz 时，相邻样值之间的相关系数大于 0.85。
  - 如果进一步提高采样频率，则相邻样值之间的相关性将更强。
  - 因此，根据较强的维相关性，可以利用差分编码技术进行有效的数据压缩。
- **信号周期之间的相关性**：虽然音频信号分布于 20-20k Hz 的频带范围，但在特定的瞬间，某一声音却往往只是该频带内的少数频率成分在起作用。
  - 当声音中只存在少数几个频率时，就会像某些振荡波形一样，在周期与周期之间存在着一定的相关性。
  - 利用音频信号周期之间的相关性进行压缩的编码器，比仅仅利用邻近样值间的相关性的编码器效果好，但要复杂得多。
- **静止系数**：两个人之间打电话，平均每人讲话时间为通话时间的一半，并且在这一半的通话过程中也会出现间歇停顿。
  - 分析表明，话音间隙使全双工话路的典型效率约为 40% (或称静止系数为 0.6)。
  - 显然，话音间隔本身就是一种冗余，若能正确检测出这些静止段，可以进行压缩。
- **长时自相关性**：
  - 统计样值、周期间的一些相关性时，在 20 ms 时间间隔内进行统计的称为短时自相关函数。
  - 如果在较长的时间间隔（如几十秒）内进行统计时，则称为长时自相关函数。
  - 长时统计表明，当采样频率为 8k Hz 时，相邻的样值之间的平均相关系数可高达 0.9。
  - 这样的相关性也可以进行压缩。



### 频域冗余

- **长时功率谱密度的非均匀性**：长时功率谱密度函数，其功率谱呈现明显的非平坦性。
  - 从统计的观点看，这意味着没有充分利用给定的频段，或者说存在固有的冗余度。
  - 功率谱的高频成分能量较低。
- **语音特有的短时功率谱密度**：语音信号的短时功率谱，在某些频率上出现峰值，而在另一些频率上出现谷值。
  - 这些峰值频率，也就是能量较大的频率，通常称其为共振峰频率。共振峰频率不止一个，最主要的是前三个，由它们决定不同的语音特征。
  - 另外，整个功率谱也是随频率的增加而递减的。更重要的是整个功率谱的细节以基音频率为基础，形成了高次谐波结构。



### 听觉冗余

​	充分利用人类听觉的生理和心理特性对音频信号感知的影响。利用人耳的频率特性灵敏度以及掩蔽效应，可以压缩数字音频的数据量。

- 可以**将会被掩蔽的信号分量在传输之前就去除**，因为这部分信号即使传输了也不会被听见。
- 可以**不理会可能被掩蔽的量化噪声**。
- 可以**将人耳不敏感的频率信号在数字化之前滤除**，如语音信号只保留 300-3400 Hz 的信号。

​		人耳的掩蔽效应包括下面几种：

- **最小可闻阈值**：一个频率的声音能量小于某个阈值之后，人耳就会听不到。
- **频率掩蔽效应**：当有能量较大的声音出现的时候，该声音频率附近的其它频率的人耳可听阈值会提高很多，这样就会导致人耳听不到这些频率低于阈值的信号，即这些信号被掩蔽。

- **时域掩蔽效应**：当强音信号和弱音信号同时出现时，可能会发生前掩蔽、同时掩蔽、后掩蔽。
  - 前掩蔽是指人耳在听到强信号之前的短暂时间内，已经存在的弱信号会被掩蔽而听不到。
  - 同时掩蔽是指当强信号与弱信号同时存在时，弱信号会被强信号所掩蔽而听不到。
  - 后掩蔽是指当强信号消失后，需经过较长的一段时间才能重新听见弱信号。
  - 这些被掩蔽的弱信号即可视为冗余信号。

![图片](https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSueh8rjibvrKYLZ7jWN4IUkSdMSic13Ofgg3wg9ZelwcXBHibC4Qee9tVlvkwEJrjj8T7zufkoezFdibqiaQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

![图片](https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSueh8rjibvrKYLZ7jWN4IUkSdMIsYdHfVoGaOn26466aws6Tnr3TSMGRGYhI6zyTAlKRCJibqcKBQbKGA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

## 视频编码

​		编码其实就是压缩，就是要去除冗余信息。

​		通常有2种方法：一是压缩分辨率，去除重复多余的信息；二是质量压缩，去掉一些人感知不敏感的信息。

​		视频的冗余信息：

1. 空间冗余，即相邻的像素往往很相似。
2. 时间冗余，即相邻的帧的内容往往很相似。
3. 视觉冗余，即人眼感知不敏感的信息。

![在这里插入图片描述](https://img-blog.csdnimg.cn/499580daf9ae4caf9c37223d6a7b6a4d.png#pic_center#pic_center)



### 编码标准发展

- ITU-T是专门做音视频的组织
- ISO是专门做各种标准规范的

​		ITU-T是最先研发了音视频通话的，最先研究出了H261，后来发布H262,H263，指导后来的H视频编解码器，这是ITU-T的H26x系列。ISO也研发了MPEG-1、MPEG-2、MPEG-3、MPEG-4标准，对应H26x系列。

​		再1998年双方合作，在第一版H264的基础上双方进行共同研发，发布了后来的更成熟的H264，作为后来的结晶，这一结晶在ITU-T组织中依然称为H264，但是在ISO组织中称为MPEG4-avc，这只是在不同组织中的称呼名字。

​		随着社会的进步，广泛的出现了4K、8K视频，这对于H264来说已经存在明显不足了，所以两个组织又一起合作在H264的基础上研发了H265.达到更高压缩的同时实现画面更清晰H265编解码技术在ITU-T组织中称为H265，在ISO组织中称为HEVC。

​		Google后来推出了VP8、VP9的编解码器，VP8,VP9分别和H264、H265做对应竞争。

​		Microsoft推出了VC-1。

​		国产自主标准：AVS/AVS+/AVS2，只是仅仅用于机顶盒，广播电视，其他领域并没有用到。但是现在的广播电视也已经废弃了AVS标准了用了其他更优良的标准。

![img](https://pic1.zhimg.com/80/v2-9f48db588dff3457c2924fde6290c404_720w.webp)



### 视频编码流程

- 原始视频信号采集：视频信号通过摄像头等设备捕获，形成未压缩的原始视频数据

- 颜色空间转换：通常将原始视频数据从RGB色彩空间转换为YUV色彩空间

  - Y代表亮度信息（Luminance），U和V代表色度信息（Chrominance）
  - 这种转换有助于减少文件大小，因为人眼对亮度的敏感度远高于色度
  - 在YUV色彩空间中，色度信息（U和V）的视觉重要性低于亮度信息（Y）
    - 可以使用4:2:0或4:2:2等降采样方式
    - 大幅减少要处理的数据，尤其对于高分辨率视频，降低色度分辨率可以显著提升压缩效率

- 帧分割

  - 帧分割和选择是帮助编码器管理帧的信息量
    - I帧：关键帧，采用帧内压缩技术。
    - P帧：前向参考帧，只参考前面已经处理的帧。采用帧间压缩技术。
    - B帧：双向参考帧，既参考面帧，又参考后面的帧。采用帧间压缩技术。
  - 编码器会分析和选择关键帧间的P帧和B帧，以向观众提供最佳的图像质量，并在维持高效压缩的同时稳定视频流

- 去除时间和空间冗余：

  - 帧内预测压缩：利用像素之间的相关性，使用如离散余弦变换（DCT）等方法将空间域信号转换到频率域，通过去除高频信息（人眼不易察觉的细节）来减少数据量。

    - 整数离散余弦变换：高频信息通常会被量化。

      - 量化的过程会将较小的部分（常为高频信息）简化到较低的比特位，丢弃那些人眼不敏感的信息。

      > 解决的是视觉冗余问题。利用傅里叶变换把复杂波形变换成许多正弦波，在频率上压缩没有一致性的波。

  - 帧间预测压缩：分析视频序列中的帧，编码器只存储关键帧和与关键帧的差异。

    - 运动补偿：运动补偿是通过先前的局部图像来预测、补偿当前的局部图像，它是减少帧序列冗余信息的有效方法。
    - 运动表示：不同区域的图像需要使用不同的运动矢量来描述运动信息。
    - 运动估计：运动估计是从视频序列中抽取运动信息的一整套技术。

    - 视频在一段连续时间内的多张照片在画面整体上其实没有太大变化，针对这段时间内相同的数据可以进行重复度的压缩。


- 量化：通过量化将频率域的数值进行近似，从而丢弃一些细节信息。

  - 量化程度越高，压缩率越大
  - 但会导致更显著的图像质量损失。
  - 量化涉及使用一个量化矩阵，对频率域中的DCT系数进行简化。

    - 这些矩阵是根据视频的内容和人眼的视觉感知特性设计的，常见的量化矩阵会对高频分量采用较大数值，从而在不显著影响画质的情况下，丢弃信息。


- 熵编码：CABAC压缩，无损压缩。对量化后的数据进行进一步的压缩，以减小位流大小。

  > 这是真正的编码环节，将前面3步处理得到的数据使用编码算法编码为最终的码流。


  - 霍夫曼编码通过分析各个符号在数据流中出现的频率，生成不同长度的编码。

    - 频繁出现的符号使用短编码，不常出现的符号使用长编码，使得整体的编码长度最小化。
  - 算术编码是将整个消息视为一个连续的数字范围，根据字符概率分布动态缩小范围。

    - 与霍夫曼编码相比，算术编码通常能达到更高的压缩率，因为它能够以更细粒度的方式对数据进行编码。
  - 编码的熵编码数据流可以与其他信息（如时间戳、帧信息等）一起组合形成输出数据

- 生成编码流：将处理后的数据组合形成压缩后的视频文件。


  - 常见的视频编码标准有H.264、H.265（HEVC）、VP9等。



### 编码压缩

#### 划分宏块

​		信源编码器将图像划分为宏块。

- 在H.264中的宏块大小是固定的16x16
- 在H.265中宏块的大小是可变的，最小8x8最大64x64。

#### 帧内预测

##### 空间冗余

​		利用一幅图像中像素之间的关联关系来去除冗余信息。

​		一幅图像中相邻像素的亮度和色度信息是比较接近的，并且亮度和色度信息也是逐渐变化的，不太会出现突变。也就是说，图像具有空间相关性。利用这种相关性，视频压缩就可以去除空间冗余信息。

> ​		比如渐变色，我们并不需要指定整个图像全部像素数据，而只是记录开头和结束以及中间变化的颜色，加上渐变位置以及渐变方向。
>
> ​		 而视频也是利用了类似的方法去除冗余信息，叫做帧内预测，即帧内预测通过利用已经编码的相邻像素的值来预测待编码的像素值，最后达到减少空间冗余的目的。

##### 残差预测

​		帧内预测的整体思路是将一帧图片分成若干宏块， 利用其中已经某些块来预测尚其他块，实际值和预测值之间的差别叫做残差。宏块可以预测相邻的宏块。

​		实际上真正编码的是残差数据，因为残差一般比较小，所以对残差编码比对实际数据编码会小很多。

​		H.264帧内预测中亮度块和色度块是分开独立进行预测的，其中默认是亮度块16x16像素，色度块8x8像素。画面信息较为平坦的地方一般使用16x16，在细节复杂的复方为了提高质量可以在宏块的基础上使用更小的子块来描述，子块的大小可以是8x16､16x8､8x8､4x8､8x4､4x4，非常的灵活。

​		4x4的块预测模式有9种，分为8个方向模式和一个DC模式：

![在这里插入图片描述](https://img-blog.csdnimg.cn/ef82f326340946f7bb440e2be1ec9942.png#pic_center#pic_center)

​		16x16和8x8的宏块预测模式一样，都是有4种帧内预测模式：

![在这里插入图片描述](https://img-blog.csdnimg.cn/18894e749aed45428322175bae70ee4c.png#pic_center#pic_center)

​		每一个宏块只能用一种预测模式，选择预测模式的具体算法很复杂，大概思路就是对于每一个块或者子块，我们可以得到预测块，再用实际待编码的块减去预测块就可以得到残差块。然后在不同场景下根据不同的算法对残差块进行计算得到最优的预测模式。







#### 帧间预测

##### 时间冗余

​		一个视频中，一般前后两帧图像往往变化比较小，这就是视频的时间相关性。而视频一般往往一秒会播放20-30帧，所以存在大量重复的图像数据，所以会有巨大的压缩空间。在前面某一帧找到一个内容很接近的块，那么只要再加上运动矢量，就可以表示当前的块。

##### 运动估计

​		寻找当前编码的块在已编码图像中的最佳对应块，就是在所参考的帧中找到与当前块相减残差最小的块。

​		运动估计的关键在于找到最佳的参考块来预测当前块，主要有两种算法：

- 全局搜索算法
  - 把搜索区域内所有的像素块逐个与当前宏块进行比较，查找具有最小匹配误差的一个像素块为匹配块。
  - 优点是可以从预测帧中选择出最准确的预测块，为全局最优结果，预测精度很准
  - 每确定一个预测块都需要对预测帧中的所有块做运算，算法复杂度高，搜索范围大，增加了视频压缩时间
  - 极少使用
- 快速搜索算法
  - 按照一定的数学规则进行匹配块的搜索。这一方法的好处是速度快，坏处是可能只能得到次最佳的匹配块。
  - 三步搜索算法
  - 菱形搜索算法

##### DPB

​		Decoded Picture Buffer，帧间预测需要参考编码好的帧，所以需要缓存队列缓存编码好的再解码重建的帧 来给后续编码的帧作为参考帧。

> ​		那为什么不直接拿原始宏块而要专门重新解码编码好的宏块做为参考呢？
> ​		关键点在于为了和解码流程保持一致的参考宏块，因为编码出来的宏块和解码重建的宏块并非完全一致的，所以如果帧间预测在编码端和解码器端参考帧不一致，就会出错。

​		比如B帧需要前后参考帧，所以需要2个缓存队列：

![在这里插入图片描述](https://img-blog.csdnimg.cn/24aa17b49a1941aba4490a2d71032bed.png#pic_center#pic_center)



#### 整数离散余弦变换 DCT

​		整数离散余弦变换（Discrete Cosine Transform，DCT），将空间上的相关性变为频域上无关的数据然后进行量化，解决的是视觉冗余问题。

​		通过傅里叶变换将复杂波形图变换成多个正弦波，他们之间的频率不同，振幅也不同。如果它们在频率上没有一致性那么我们就可以对他进行压缩处理。

##### 图像频率

​		整数离散余弦变换（Discrete Cosine Transform，DCT）。图像的频率是指灰度值变化剧烈程度的指标，是灰度在平面空间上的梯度。图像的低频是轮廓，高频是噪声和细节。

​		低频就是颜色缓慢地变化，也就是灰度缓慢地变化，就代表着那是连续渐变的一块区域，这部分就是低频。也就是边缘以内的内容为低频，而边缘内的内容就是图像的大部分信息，即图像的大致概貌和轮廓，是图像的近似信息。

​		高频就是频率变化快。图像色块边缘的灰度值变化快，就对应着频率高，即高频显示影像边缘。图像的细节处也是属于灰度值急剧变化的区域，正是因为灰度值的急剧变化，才会出现细节。

​		另外噪声（即噪点） 也是这样，在一个像素所在的位置，之所以是噪点，就是因为它与正常的点颜色不一样了，也就是说该像素点灰度值明显不一样了，也就是灰度有快速地变化了，所以是高频部分，因此有噪声在高频这么一说。

##### DCT理论依据

​		人眼的视觉敏感度是有限的，有的时候我们去除了一部分高频信息之后，人眼看上去感觉区别并不大。这就是视觉冗余。

​		先将图片通过 DCT 变换到频域，然后再去除一些高频信息。这样我 们就可以减少信息量，从而达到压缩的目的。

​		最后效果为在变换后的块中，左上角的系数往往比较大，越靠近右下角的系数越小，这是就是因为高频系数一般比较小的缘故，而低频分量一般比较大。

![在这里插入图片描述](https://img-blog.csdnimg.cn/baa105766b0b49338674b9d5ab36a3c8.png#pic_center#pic_center)



#### 量化

​		DCT变换并没有进行压缩，压缩需要后面一步的支持——量化。

​		量化基本决定了视频的码率，视频的码率又从一定程度上决定了视频的质量。

​		量化值QP越大则量化的粒度越高，压缩率越大，码率更小，视频质量越低，呈现出来就是马赛克比较大，画面不细腻，画面比较模糊。反之，压缩率低，码率大，质量高，画面细腻，细节丰富。

![在这里插入图片描述](https://img-blog.csdnimg.cn/7c5894d5fc62474e9ea611e5116c61cb.png#pic_center#pic_center)

> 最后效果为大部分系数都变为0了，这就是通过量化去除高频分量的结果，右下角部分基本都为0。



#### CABAC压缩

​		视频编码中真正实现“压缩”的步骤，主要去除信息熵冗余。而前面说的去除空间、时间、视觉冗余，其实都是为这一步做准备的。

​		CABAC压缩属于**无损压缩**，编码的目的是从概率的角度再做一次压缩，编码的过程主要分为二值化，上下文建模，二进制算术编码。

> 无损压缩技术大家最熟悉的可能就是哈夫曼编码了，给高频的词一个短码，给低频词一个长码从而达到数据压缩的目的。MPEG-2中使用的VLC就是这种算法。
> CABAC也是给高频数据短码，给低频数据长码。同时还会根据上下文相关性进行压缩，这种方式又比VLC高效很多。

##### 二值化

​		二值化就是将像素点的值根据一定的算法，将像素分别修改为0，或255，即获取图像的灰度图，或者通俗些讲就是图像的黑白图。

​		而此处的“二值化”可以暂且理解为，将数值二进制化的一个过程，当然不是简单的将十进制转换为二进制。

​		经过二值化之后，CABAC 就已经把待编码的语法元素按照一定的规则转换为只用“0”和“1”的二进制流，称为比特流。

##### 上下文建模

​		待编码数据具有上下文相关性，利用已编码数据提供的上下文信息，为待编码的数据选择合适的概率模型，这就是上下文建模。通过对上下文模型的构建，基本概率模型能够适应随视频图像而改变的统计特性，降低数据之间的冗余度，并减少运算开支。

> ​		H.264/AVC 标准将一个 Slice 可能出现的数据划分为 399 个上下文模型，每个模型均有自己的上下文序号，命名为 CtxIdx，每个不同的字符依据对应的上下文模型，来索引自身的概率查找表。即收到字符后，先找到字符对应的上下文模型的序号 CtxIdx，然后根据 CtxIdx 找到其对应的概率查找表。 详细的步骤如下：
>
> 1. 确定当前的字符对应的上下文模型的区间，H264 标准中的表9-1描述了相应的对应关系。
> 2. 按照不同的法则，在第1步中得到的区间中最终确定的上下文模型个的CtxIdx。

![在这里插入图片描述](https://img-blog.csdnimg.cn/img_convert/93d5aa7ea074ddad3a2d0e0344d42bc8.webp?x-oss-process=image/format,png#pic_center)





##### 二进制算术编码

​		通过上下文建模找到的概率模型的概率估计方法构成了一个自适应二进制算术编码器。概率估计是在前一次上下文建模阶段更新后的概率估计。在对每个二进制数值编码过后，概率估计的值相应的也会根据刚刚编码的二进制符号进行调整。

​		二进制算术编码是算术编码的特殊情况，其原理与一般算术编码一样。不同的是，二进制算术编码序列只有“0”和“1”两种符号，所涉及的概率也只有P(0)和P(1)。





### 帧类型

​		对于帧内预测和帧间预测技术的不同应用产生了不同的帧类型。

- I帧：关键帧，采用帧内压缩技术。
- P帧：向前参考帧。采用帧间压缩和帧内技术。
- B帧：双向参考帧。采用帧间和帧内压缩技术。

> P、B帧同时包含帧间帧内预测，所以宏块同样也有划分I、P、B宏块，I宏块用来做帧内预测，P宏块用来做向前参考帧的预测，B宏块用来做双向参考帧预测。I帧仅包含I宏块，P帧包含P宏块和I宏块，B帧包含B宏块和I宏块。

#### I帧

​		关键帧

- 帧内编码，数据量大
- 周期性插入图像序列中，频率可由编码器指定
- I帧不需要考虑运动矢量
  - I帧压缩可去掉视频的空间冗余信息
  - P帧和B帧是为了去掉时间冗余信息。
- 通常是每个GOP的第一个帧
  - GOP，MPEG所使用的一种视频压缩技术，表示组成一段视频的一组图片
  - 经过适度地压缩，作为随机访问的参考点，可以当成静态图像
    - I帧压缩可以得到6:1的压缩比而不会产生任何可觉察的模糊现象。
  - I帧可以单独解码出一张完整的图片
    - 质量直接影响到同组中以后各帧的质量
  - 参考帧可以参考I帧的信息来解码出一张完整的图片

#### P帧

​		前向预测参考帧（predictive-frame）。需要参考其前面的一个I帧或者P帧来解码成一张完整的视频画面。

​		充分去除图像序列中此帧之前已编码帧的时间冗余信息，压缩编码图像。

#### B帧

​		双向预测内插参考帧（bi-directional interpolated prediction frame），B帧则需要参考其前一个I帧或者P帧及其后面的一个P帧来生成一张完整的视频画面。

​		既考虑源图像序列前面的已编码帧，又顾及源图像序列后面的已编码帧之间的时间冗余信息，来压缩传输数据量的编码图像，也称为双向预测帧。

​		不过正是由于需要参考后面的P帧，所以B帧虽然提高了压缩率，但是也带来了编码延迟问题（需要等后面一帧编码好才能编码）。

#### IDR帧

​		在H264的概念中有一个帧称为IDR帧。

​		因为H264采用了多帧预测，所以I帧之后的P帧有可能会参考I帧之前的帧。这就使得在随机访问的时候不能以找到I帧作为参考条件清理缓冲区。因为即便找到I帧，I帧之后的帧还是有可能因为参考I帧之前的帧而解析不出来。

​		IDR帧就是一种特殊的I帧，即这一帧之后的所有参考帧只会参考到这个IDR帧，而不会再参考前面的帧。

​		在解码器中，一旦收到一个IDR帧，就会立即清理参考帧缓冲区，并将IDR帧作为被参考的帧。



#### tips

​		在提高视频质量的技巧中，还有个技巧是多使用B帧。

​		一般来说，I的压缩率是7（与JPEG差不多）, P是20, B可以达到50，可见使用B帧能节省大量空间，节省出来的空间可以用来更多地保存I帧，这样就能在相同的码率下提供更好的画质。

​		



### GOP

​		GOP（Group Of Picture），表示视频中一个独立播放的图片组。两个I帧之间是一个图像序列，在一个图像序列中只有一个I帧且为首帧。

​		GOP是利用分组的思想，组间周期性的进行一次帧内预测，保证整体场景的刷新；组内通过帧间预测大大降低冗余信息。

​		通常在为编码器设置参数的时候，必须要设置`gop_size`的值，其代表的是两个I帧之间的帧数目。

- 一个GOP中容量最大的帧就是I帧
  - `gop_size`设置得越小，整个画面的质量就会越好。
- 解码端必须从接收到的第一个I帧开始才可以正确解码出原始图像，否则会无法正确解码。
- 根据不同的业务场景，适当地设置`gop_size`的大小，以得到更高质量的视频。
- 但是过多的P、B帧会影响编码的效率
  - 为了防止未加载完跳转卡顿时间长等问题，一般设置GOP为帧率的4-5倍，保证4-5秒必有I帧
  - 直播流一般禁止B帧，有利于直播的流畅

- 还会影响seek操作的响应速度

![在这里插入图片描述](https://img-blog.csdnimg.cn/img_convert/2d11ae3d85b2bd5b0bb18da7a68cad87.png#pic_center)

​	

### PTS / DTS

​		由于B帧的引入，会导致一个现象，就是编码的帧顺序和播放的帧顺序会不一致,所以也衍生了两个时间戳，DTS（Decoding Time Stamp）和 PTS（Presentation Time Stamp）。顾名思义，前者是解码的时间，后者是显示的时间。

![在这里插入图片描述](https://img-blog.csdnimg.cn/0248ca664ff24d4ea3638735b97e34c3.png#pic_center#pic_center)

- DTS（Decoding Time Stamp），解码时间戳，主要用于视频的解码。
  - 表示该压缩包应该在什么时候被解码
  - 解码的时间戳

- PTS（Presentation Time Stamp），显示（表示）时间戳，主要用于在解码阶段进行视频的同步和输出。
  - 视频的一帧图像什么时候显示给用户，取决于它的PTS
  - 真正录制和播放的时间戳

​		在没有B帧的情况下，DTS和PTS的输出顺序是一样的，因为没有延迟编码。而对于有B-frame的视频，I-frame的PTS依然等于DTS，P-frame的PTS>DTS，B-frame的PTS<DTS。

> - 若视频没有B-frame，则I和P都是解码后即刻显示。
> - 若视频含有B-frame，则I是解码后即刻显示，P是先解码后显示，B是后解码先显示。（B和P的先、后是相对的）。



