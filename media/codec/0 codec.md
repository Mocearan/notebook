# Codec

---



## 参考

[实时音视频开发理论必备：如何省流量？视频高度压缩背后的预测技术-实时音视频/专项技术区 - 即时通讯开发者社区! (52im.net)](http://www.52im.net/thread-3581-1-1.html)

## 音频编码

![img](https://pics7.baidu.com/feed/e61190ef76c6a7ef01ae77147e8fff5df2de66fe.jpeg@f_auto?token=84e5eea3d1eeafb271fb080a8692422e)

- `MP3 (MPEG Audio Layer III)`: 最普遍的音频压缩格式，以较小的文件大小提供合理的声音质量。
- `AAC (Advanced Audio Coding)`: 与MP3相比，它提供更好的音质和压缩率，被广泛用于Apple设备。
- `WAV (Waveform Audio File Format)`: 一种未压缩的音频格式，提供高质量的音频数据，但文件较大。
- `FLAC (Free Lossless Audio Codec)`: 无损压缩的音频格式，可以在不损失任何数据的情况下减小文件大小。
- `OGG (Ogg Vorbis)`: 一种开源的音频压缩格式，通常提供比MP3更好的压缩率。



## 视频编码

​		编码其实就是压缩，就是要去除冗余信息。

​		通常有2种方法：一是压缩分辨率，去除重复多余的信息；二是质量压缩，去掉一些人感知不敏感的信息。

​		视频的冗余信息：

1. 空间冗余，即相邻的像素往往很相似。
2. 时间冗余，即相邻的帧的内容往往很相似。
3. 视觉冗余，即人眼感知不敏感的信息。

![在这里插入图片描述](https://img-blog.csdnimg.cn/499580daf9ae4caf9c37223d6a7b6a4d.png#pic_center#pic_center)



### 编码标准发展

- ITU-T是专门做音视频的组织
- ISO是专门做各种标准规范的

​		ITU-T是最先研发了音视频通话的，最先研究出了H261，后来发布H262,H263，指导后来的H视频编解码器，这是ITU-T的H26x系列。ISO也研发了MPEG-1、MPEG-2、MPEG-3、MPEG-4标准，对应H26x系列。

​		再1998年双方合作，在第一版H264的基础上双方进行共同研发，发布了后来的更成熟的H264，作为后来的结晶，这一结晶在ITU-T组织中依然称为H264，但是在ISO组织中称为MPEG4-avc，这只是在不同组织中的称呼名字。

​		随着社会的进步，广泛的出现了4K、8K视频，这对于H264来说已经存在明显不足了，所以两个组织又一起合作在H264的基础上研发了H265.达到更高压缩的同时实现画面更清晰H265编解码技术在ITU-T组织中称为H265，在ISO组织中称为HEVC。

​		Google后来推出了VP8、VP9的编解码器，VP8,VP9分别和H264、H265做对应竞争。

​		Microsoft推出了VC-1。

​		国产自主标准：AVS/AVS+/AVS2，只是仅仅用于机顶盒，广播电视，其他领域并没有用到。但是现在的广播电视也已经废弃了AVS标准了用了其他更优良的标准。

![img](https://pic1.zhimg.com/80/v2-9f48db588dff3457c2924fde6290c404_720w.webp)



### 视频编码流程

- 原始视频信号采集：视频信号通过摄像头等设备捕获，形成未压缩的原始视频数据

- 颜色空间转换：通常将原始视频数据从RGB色彩空间转换为YUV色彩空间

  - Y代表亮度信息（Luminance），U和V代表色度信息（Chrominance）
  - 这种转换有助于减少文件大小，因为人眼对亮度的敏感度远高于色度
  - 在YUV色彩空间中，色度信息（U和V）的视觉重要性低于亮度信息（Y）
    - 可以使用4:2:0或4:2:2等降采样方式
    - 大幅减少要处理的数据，尤其对于高分辨率视频，降低色度分辨率可以显著提升压缩效率

- 帧分割

  - 帧分割和选择是帮助编码器管理帧的信息量
    - I帧：关键帧，采用帧内压缩技术。
    - P帧：前向参考帧，只参考前面已经处理的帧。采用帧间压缩技术。
    - B帧：双向参考帧，既参考面帧，又参考后面的帧。采用帧间压缩技术。
  - 编码器会分析和选择关键帧间的P帧和B帧，以向观众提供最佳的图像质量，并在维持高效压缩的同时稳定视频流

- 去除时间和空间冗余：

  - 帧内预测压缩：利用像素之间的相关性，使用如离散余弦变换（DCT）等方法将空间域信号转换到频率域，通过去除高频信息（人眼不易察觉的细节）来减少数据量。

    - 整数离散余弦变换：高频信息通常会被量化。

      - 量化的过程会将较小的部分（常为高频信息）简化到较低的比特位，丢弃那些人眼不敏感的信息。

      > 解决的是视觉冗余问题。利用傅里叶变换把复杂波形变换成许多正弦波，在频率上压缩没有一致性的波。

  - 帧间预测压缩：分析视频序列中的帧，编码器只存储关键帧和与关键帧的差异。

    - 运动补偿：运动补偿是通过先前的局部图像来预测、补偿当前的局部图像，它是减少帧序列冗余信息的有效方法。
    - 运动表示：不同区域的图像需要使用不同的运动矢量来描述运动信息。
    - 运动估计：运动估计是从视频序列中抽取运动信息的一整套技术。

    - 视频在一段连续时间内的多张照片在画面整体上其实没有太大变化，针对这段时间内相同的数据可以进行重复度的压缩。


- 量化：通过量化将频率域的数值进行近似，从而丢弃一些细节信息。

  - 量化程度越高，压缩率越大
  - 但会导致更显著的图像质量损失。
  - 量化涉及使用一个量化矩阵，对频率域中的DCT系数进行简化。

    - 这些矩阵是根据视频的内容和人眼的视觉感知特性设计的，常见的量化矩阵会对高频分量采用较大数值，从而在不显著影响画质的情况下，丢弃信息。


- 熵编码：CABAC压缩，无损压缩。对量化后的数据进行进一步的压缩，以减小位流大小。

  > 这是真正的编码环节，将前面3步处理得到的数据使用编码算法编码为最终的码流。


  - 霍夫曼编码通过分析各个符号在数据流中出现的频率，生成不同长度的编码。

    - 频繁出现的符号使用短编码，不常出现的符号使用长编码，使得整体的编码长度最小化。
  - 算术编码是将整个消息视为一个连续的数字范围，根据字符概率分布动态缩小范围。

    - 与霍夫曼编码相比，算术编码通常能达到更高的压缩率，因为它能够以更细粒度的方式对数据进行编码。
  - 编码的熵编码数据流可以与其他信息（如时间戳、帧信息等）一起组合形成输出数据

- 生成编码流：将处理后的数据组合形成压缩后的视频文件。


  - 常见的视频编码标准有H.264、H.265（HEVC）、VP9等。



### 编码压缩

#### 划分宏块

​		信源编码器将图像划分为宏块。

- 在H.264中的宏块大小是固定的16x16
- 在H.265中宏块的大小是可变的，最小8x8最大64x64。

#### 帧内预测

##### 空间冗余

​		利用一幅图像中像素之间的关联关系来去除冗余信息。

​		一幅图像中相邻像素的亮度和色度信息是比较接近的，并且亮度和色度信息也是逐渐变化的，不太会出现突变。也就是说，图像具有空间相关性。利用这种相关性，视频压缩就可以去除空间冗余信息。

> ​		比如渐变色，我们并不需要指定整个图像全部像素数据，而只是记录开头和结束以及中间变化的颜色，加上渐变位置以及渐变方向。
>
> ​		 而视频也是利用了类似的方法去除冗余信息，叫做帧内预测，即帧内预测通过利用已经编码的相邻像素的值来预测待编码的像素值，最后达到减少空间冗余的目的。

##### 残差预测

​		帧内预测的整体思路是将一帧图片分成若干宏块， 利用其中已经某些块来预测尚其他块，实际值和预测值之间的差别叫做残差。宏块可以预测相邻的宏块。

​		实际上真正编码的是残差数据，因为残差一般比较小，所以对残差编码比对实际数据编码会小很多。

​		H.264帧内预测中亮度块和色度块是分开独立进行预测的，其中默认是亮度块16x16像素，色度块8x8像素。画面信息较为平坦的地方一般使用16x16，在细节复杂的复方为了提高质量可以在宏块的基础上使用更小的子块来描述，子块的大小可以是8x16､16x8､8x8､4x8､8x4､4x4，非常的灵活。

​		4x4的块预测模式有9种，分为8个方向模式和一个DC模式：

![在这里插入图片描述](https://img-blog.csdnimg.cn/ef82f326340946f7bb440e2be1ec9942.png#pic_center#pic_center)

​		16x16和8x8的宏块预测模式一样，都是有4种帧内预测模式：

![在这里插入图片描述](https://img-blog.csdnimg.cn/18894e749aed45428322175bae70ee4c.png#pic_center#pic_center)

​		每一个宏块只能用一种预测模式，选择预测模式的具体算法很复杂，大概思路就是对于每一个块或者子块，我们可以得到预测块，再用实际待编码的块减去预测块就可以得到残差块。然后在不同场景下根据不同的算法对残差块进行计算得到最优的预测模式。







#### 帧间预测

##### 时间冗余

​		一个视频中，一般前后两帧图像往往变化比较小，这就是视频的时间相关性。而视频一般往往一秒会播放20-30帧，所以存在大量重复的图像数据，所以会有巨大的压缩空间。在前面某一帧找到一个内容很接近的块，那么只要再加上运动矢量，就可以表示当前的块。

##### 运动估计

​		寻找当前编码的块在已编码图像中的最佳对应块，就是在所参考的帧中找到与当前块相减残差最小的块。

​		运动估计的关键在于找到最佳的参考块来预测当前块，主要有两种算法：

- 全局搜索算法
  - 把搜索区域内所有的像素块逐个与当前宏块进行比较，查找具有最小匹配误差的一个像素块为匹配块。
  - 优点是可以从预测帧中选择出最准确的预测块，为全局最优结果，预测精度很准
  - 每确定一个预测块都需要对预测帧中的所有块做运算，算法复杂度高，搜索范围大，增加了视频压缩时间
  - 极少使用
- 快速搜索算法
  - 按照一定的数学规则进行匹配块的搜索。这一方法的好处是速度快，坏处是可能只能得到次最佳的匹配块。
  - 三步搜索算法
  - 菱形搜索算法

##### DPB

​		Decoded Picture Buffer，帧间预测需要参考编码好的帧，所以需要缓存队列缓存编码好的再解码重建的帧 来给后续编码的帧作为参考帧。

> ​		那为什么不直接拿原始宏块而要专门重新解码编码好的宏块做为参考呢？
> ​		关键点在于为了和解码流程保持一致的参考宏块，因为编码出来的宏块和解码重建的宏块并非完全一致的，所以如果帧间预测在编码端和解码器端参考帧不一致，就会出错。

​		比如B帧需要前后参考帧，所以需要2个缓存队列：

![在这里插入图片描述](https://img-blog.csdnimg.cn/24aa17b49a1941aba4490a2d71032bed.png#pic_center#pic_center)



#### 整数离散余弦变换 DCT

​		整数离散余弦变换（Discrete Cosine Transform，DCT），将空间上的相关性变为频域上无关的数据然后进行量化，解决的是视觉冗余问题。

​		通过傅里叶变换将复杂波形图变换成多个正弦波，他们之间的频率不同，振幅也不同。如果它们在频率上没有一致性那么我们就可以对他进行压缩处理。

##### 图像频率

​		整数离散余弦变换（Discrete Cosine Transform，DCT）。图像的频率是指灰度值变化剧烈程度的指标，是灰度在平面空间上的梯度。图像的低频是轮廓，高频是噪声和细节。

​		低频就是颜色缓慢地变化，也就是灰度缓慢地变化，就代表着那是连续渐变的一块区域，这部分就是低频。也就是边缘以内的内容为低频，而边缘内的内容就是图像的大部分信息，即图像的大致概貌和轮廓，是图像的近似信息。

​		高频就是频率变化快。图像色块边缘的灰度值变化快，就对应着频率高，即高频显示影像边缘。图像的细节处也是属于灰度值急剧变化的区域，正是因为灰度值的急剧变化，才会出现细节。

​		另外噪声（即噪点） 也是这样，在一个像素所在的位置，之所以是噪点，就是因为它与正常的点颜色不一样了，也就是说该像素点灰度值明显不一样了，也就是灰度有快速地变化了，所以是高频部分，因此有噪声在高频这么一说。

##### DCT理论依据

​		人眼的视觉敏感度是有限的，有的时候我们去除了一部分高频信息之后，人眼看上去感觉区别并不大。这就是视觉冗余。

​		先将图片通过 DCT 变换到频域，然后再去除一些高频信息。这样我 们就可以减少信息量，从而达到压缩的目的。

​		最后效果为在变换后的块中，左上角的系数往往比较大，越靠近右下角的系数越小，这是就是因为高频系数一般比较小的缘故，而低频分量一般比较大。

![在这里插入图片描述](https://img-blog.csdnimg.cn/baa105766b0b49338674b9d5ab36a3c8.png#pic_center#pic_center)



#### 量化

​		DCT变换并没有进行压缩，压缩需要后面一步的支持——量化。

​		量化基本决定了视频的码率，视频的码率又从一定程度上决定了视频的质量。

​		量化值QP越大则量化的粒度越高，压缩率越大，码率更小，视频质量越低，呈现出来就是马赛克比较大，画面不细腻，画面比较模糊。反之，压缩率低，码率大，质量高，画面细腻，细节丰富。

![在这里插入图片描述](https://img-blog.csdnimg.cn/7c5894d5fc62474e9ea611e5116c61cb.png#pic_center#pic_center)

> 最后效果为大部分系数都变为0了，这就是通过量化去除高频分量的结果，右下角部分基本都为0。



#### CABAC压缩

​		视频编码中真正实现“压缩”的步骤，主要去除信息熵冗余。而前面说的去除空间、时间、视觉冗余，其实都是为这一步做准备的。

​		CABAC压缩属于**无损压缩**，编码的目的是从概率的角度再做一次压缩，编码的过程主要分为二值化，上下文建模，二进制算术编码。

> 无损压缩技术大家最熟悉的可能就是哈夫曼编码了，给高频的词一个短码，给低频词一个长码从而达到数据压缩的目的。MPEG-2中使用的VLC就是这种算法。
> CABAC也是给高频数据短码，给低频数据长码。同时还会根据上下文相关性进行压缩，这种方式又比VLC高效很多。

##### 二值化

​		二值化就是将像素点的值根据一定的算法，将像素分别修改为0，或255，即获取图像的灰度图，或者通俗些讲就是图像的黑白图。

​		而此处的“二值化”可以暂且理解为，将数值二进制化的一个过程，当然不是简单的将十进制转换为二进制。

​		经过二值化之后，CABAC 就已经把待编码的语法元素按照一定的规则转换为只用“0”和“1”的二进制流，称为比特流。

##### 上下文建模

​		待编码数据具有上下文相关性，利用已编码数据提供的上下文信息，为待编码的数据选择合适的概率模型，这就是上下文建模。通过对上下文模型的构建，基本概率模型能够适应随视频图像而改变的统计特性，降低数据之间的冗余度，并减少运算开支。

> ​		H.264/AVC 标准将一个 Slice 可能出现的数据划分为 399 个上下文模型，每个模型均有自己的上下文序号，命名为 CtxIdx，每个不同的字符依据对应的上下文模型，来索引自身的概率查找表。即收到字符后，先找到字符对应的上下文模型的序号 CtxIdx，然后根据 CtxIdx 找到其对应的概率查找表。 详细的步骤如下：
>
> 1. 确定当前的字符对应的上下文模型的区间，H264 标准中的表9-1描述了相应的对应关系。
> 2. 按照不同的法则，在第1步中得到的区间中最终确定的上下文模型个的CtxIdx。

![在这里插入图片描述](https://img-blog.csdnimg.cn/img_convert/93d5aa7ea074ddad3a2d0e0344d42bc8.webp?x-oss-process=image/format,png#pic_center)





##### 二进制算术编码

​		通过上下文建模找到的概率模型的概率估计方法构成了一个自适应二进制算术编码器。概率估计是在前一次上下文建模阶段更新后的概率估计。在对每个二进制数值编码过后，概率估计的值相应的也会根据刚刚编码的二进制符号进行调整。

​		二进制算术编码是算术编码的特殊情况，其原理与一般算术编码一样。不同的是，二进制算术编码序列只有“0”和“1”两种符号，所涉及的概率也只有P(0)和P(1)。





### 帧类型

​		对于帧内预测和帧间预测技术的不同应用产生了不同的帧类型。

- I帧：关键帧，采用帧内压缩技术。
- P帧：向前参考帧。采用帧间压缩和帧内技术。
- B帧：双向参考帧。采用帧间和帧内压缩技术。

> P、B帧同时包含帧间帧内预测，所以宏块同样也有划分I、P、B宏块，I宏块用来做帧内预测，P宏块用来做向前参考帧的预测，B宏块用来做双向参考帧预测。I帧仅包含I宏块，P帧包含P宏块和I宏块，B帧包含B宏块和I宏块。

#### I帧

​		关键帧

- 帧内编码，数据量大
- 周期性插入图像序列中，频率可由编码器指定
- I帧不需要考虑运动矢量
  - I帧压缩可去掉视频的空间冗余信息
  - P帧和B帧是为了去掉时间冗余信息。
- 通常是每个GOP的第一个帧
  - GOP，MPEG所使用的一种视频压缩技术，表示组成一段视频的一组图片
  - 经过适度地压缩，作为随机访问的参考点，可以当成静态图像
    - I帧压缩可以得到6:1的压缩比而不会产生任何可觉察的模糊现象。
  - I帧可以单独解码出一张完整的图片
    - 质量直接影响到同组中以后各帧的质量
  - 参考帧可以参考I帧的信息来解码出一张完整的图片

#### P帧

​		前向预测参考帧（predictive-frame）。需要参考其前面的一个I帧或者P帧来解码成一张完整的视频画面。

​		充分去除图像序列中此帧之前已编码帧的时间冗余信息，压缩编码图像。

#### B帧

​		双向预测内插参考帧（bi-directional interpolated prediction frame），B帧则需要参考其前一个I帧或者P帧及其后面的一个P帧来生成一张完整的视频画面。

​		既考虑源图像序列前面的已编码帧，又顾及源图像序列后面的已编码帧之间的时间冗余信息，来压缩传输数据量的编码图像，也称为双向预测帧。

​		不过正是由于需要参考后面的P帧，所以B帧虽然提高了压缩率，但是也带来了编码延迟问题（需要等后面一帧编码好才能编码）。

#### IDR帧

​		在H264的概念中有一个帧称为IDR帧。

​		因为H264采用了多帧预测，所以I帧之后的P帧有可能会参考I帧之前的帧。这就使得在随机访问的时候不能以找到I帧作为参考条件清理缓冲区。因为即便找到I帧，I帧之后的帧还是有可能因为参考I帧之前的帧而解析不出来。

​		IDR帧就是一种特殊的I帧，即这一帧之后的所有参考帧只会参考到这个IDR帧，而不会再参考前面的帧。

​		在解码器中，一旦收到一个IDR帧，就会立即清理参考帧缓冲区，并将IDR帧作为被参考的帧。



#### tips

​		在提高视频质量的技巧中，还有个技巧是多使用B帧。

​		一般来说，I的压缩率是7（与JPEG差不多）, P是20, B可以达到50，可见使用B帧能节省大量空间，节省出来的空间可以用来更多地保存I帧，这样就能在相同的码率下提供更好的画质。

​		



### GOP

​		GOP（Group Of Picture），表示视频中一个独立播放的图片组。两个I帧之间是一个图像序列，在一个图像序列中只有一个I帧且为首帧。

​		GOP是利用分组的思想，组间周期性的进行一次帧内预测，保证整体场景的刷新；组内通过帧间预测大大降低冗余信息。

​		通常在为编码器设置参数的时候，必须要设置`gop_size`的值，其代表的是两个I帧之间的帧数目。

- 一个GOP中容量最大的帧就是I帧
  - `gop_size`设置得越小，整个画面的质量就会越好。
- 解码端必须从接收到的第一个I帧开始才可以正确解码出原始图像，否则会无法正确解码。
- 根据不同的业务场景，适当地设置`gop_size`的大小，以得到更高质量的视频。
- 但是过多的P、B帧会影响编码的效率
  - 为了防止未加载完跳转卡顿时间长等问题，一般设置GOP为帧率的4-5倍，保证4-5秒必有I帧
  - 直播流一般禁止B帧，有利于直播的流畅

- 还会影响seek操作的响应速度

![在这里插入图片描述](https://img-blog.csdnimg.cn/img_convert/2d11ae3d85b2bd5b0bb18da7a68cad87.png#pic_center)

​	

### PTS / DTS

​		由于B帧的引入，会导致一个现象，就是编码的帧顺序和播放的帧顺序会不一致,所以也衍生了两个时间戳，DTS（Decoding Time Stamp）和 PTS（Presentation Time Stamp）。顾名思义，前者是解码的时间，后者是显示的时间。

![在这里插入图片描述](https://img-blog.csdnimg.cn/0248ca664ff24d4ea3638735b97e34c3.png#pic_center#pic_center)

- DTS（Decoding Time Stamp），解码时间戳，主要用于视频的解码。
  - 表示该压缩包应该在什么时候被解码
  - 解码的时间戳

- PTS（Presentation Time Stamp），显示（表示）时间戳，主要用于在解码阶段进行视频的同步和输出。
  - 视频的一帧图像什么时候显示给用户，取决于它的PTS
  - 真正录制和播放的时间戳

​		在没有B帧的情况下，DTS和PTS的输出顺序是一样的，因为没有延迟编码。而对于有B-frame的视频，I-frame的PTS依然等于DTS，P-frame的PTS>DTS，B-frame的PTS<DTS。

> - 若视频没有B-frame，则I和P都是解码后即刻显示。
> - 若视频含有B-frame，则I是解码后即刻显示，P是先解码后显示，B是后解码先显示。（B和P的先、后是相对的）。



