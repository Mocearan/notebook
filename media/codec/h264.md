# H264

​		`H.264`由`ITU-T`视频编码专家组（`VCEG`）和`ISO/IEC`动态图像专家组（`MPEG`）联合组成的联合视频组（`JVT，Joint Video Team`）提出的高度压缩数字视频编解码器)标准。

---

​		ISO针对视频指定了标准：`Motion JPEG`即`MPEG`（动态JPEG编码）。同时也是`MPEG-4`第十部分，通常被称之为`H.264/AVC`明确的说明它两方面的开发者。

> 或`AVC/H.264`或者`H.264/MPEG-4 AVC`或`MPEG-4/H.264 AVC`

- 对单幅图像进行编码
- 利用图像序列的相关性原则去除冗余，大大提高视频压缩比
  - 减少网络传输对网络带宽的占用

​		H.264创造了多参考帧、多块类型、整数变换、帧内预测等新的压缩技术，使用了更精细的分像素运动矢量（1/4、1/8）和新一代的环路滤波器，这使得压缩性能得到大大提高，系统也变得更加完善。H264在H263的基础上增加了如下压缩技术

- 双向运动补偿 
- 以小块进行的可变块运动补偿 
- 四分之一像素运动补偿 
- 环路滤波器 
- 变长编码 
- 加权预测 
- 可伸缩视频编码 
- 多视点编码等

​		H264编码器实际上有两个功能分层的任务：

- `VCL`：视频编码层，用于实际压缩编码采集到的视频数据
- `NAL`：网络抽象层，为了便于存储和传输，将`VCL`数据封装为`NAL`数据单元

  - 负责把网络视频流进行打包和传送

    > 对于开发来说，VCL层不怎么需要去关心




## 参考

[视频编解码_取次花丛懒回顾的博客-CSDN博客](https://yinwenjie.blog.csdn.net/category_1914693.html)

[先进视频压缩编码(Advanced Video Coding, H.264/AVC)_取次花丛懒回顾的博客-CSDN博客](https://blog.csdn.net/shaqoneal/category_9267755.html)

[H.264 : Advanced video coding for generic audiovisual services](https://www.itu.int/rec/T-REC-H.264)

[H.264 NALU详解_h264 nalu-CSDN博客](https://blog.csdn.net/weixin_39399492/article/details/133165018?csdn_share_tail={"type"%3A"blog"%2C"rType"%3A"article"%2C"rId"%3A"133165018"%2C"source"%3A"weixin_39399492"})

[分类:x264 - 懒人李冰 (lazybing.github.io)](https://lazybing.github.io/blog/categories/x264/)



1. 图书 《视频编码全角度详解》
2. 图书 《新一代视频压缩编码标准 — H.264/AVC》
3. 李超-H264基本原理(https://zhuanlan.zhihu.com/p/31056455)
4. 深入浅出理解视频编码H264结构(https://philm.gitbook.io/philm-ios-wiki/mei-zhou-yue-du/shen-ru-qian-chu-li-jie-shi-pin-bian-ma-h264-jie-gou)
5. 视频和视频帧：H264编码格式整理(https://zhuanlan.zhihu.com/p/71928833)
6. H264编码总结(https://www.jianshu.com/p/0c296b05ef2a)
7. VCL & NAL (H.264/AVC)(https://www.jianshu.com/p/eeecb0eb2c6e)



## 标准

​		H.264标准各主要部分有

- Access Unit delimiter（访问单元分割符）
- SEI（附加增强信息）
- primary coded picture（基本图像编码）
- Redundant Coded Picture（冗余图像编码）
- Instantaneous Decoding Refresh（IDR，即时解码刷新）
- Hypothetical Reference Decoder（HRD，假想参考解码）
- Hypothetical Stream Scheduler（HSS，假想码流调度器）



## 概念

### 句法元素分层

​		句法元素可以分为『序列』、『图像』、『片』、『宏块』、『子宏块』五个层次。

<img src="https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSuejJrgRTLgovpyFlfffh6IAqMjicbCH1zMOz0o26774DvFLSskGjeib1jaEhYQLs7ssWZGQ9TicBcib5HQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom: 50%;" />

​		 H.264 中，分层结构取消了序列层和图像层，将原本属于序列和图像**头部**的大部分句法元素游离出来形成序列和图像两级**参数集**，其余的部分则放入片层。

> 参数集是独立的，可以被多次重发或者采用特殊技术加以保护。参数集与参数集之外的句法元素处于不同信道中，这是 H.264 的一个建议，我们可以使用更安全但成本更昂贵的通道来传输参数集。

<img src="https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSuejJrgRTLgovpyFlfffh6IAqfiaiavzTlgibpFiaoyzVXDVBT9BxoZsw8NhprCZv6bNicM4KG9bcVGBPW2w/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom: 33%;" />



### 软硬件编解码

- 软编/软解: CPU 处理
  - 调节能力比较强，通过参数调整可以在同一码率下编码出清晰度更高的视频
  - 兼容性更好，可以适配所有设备
  - 性能可能比较差，不如硬编速度快、功耗低
- 硬编/硬解: 使用显卡 GPU、专用 SDP 等其它芯片硬件处理

​		移动应用大部分业务场景采用的编码策略是：手机端尽量采用硬编编码出一路高清的视频，将高清视频发送给服务器，由服务器再进行软编转码为多路码率的视频，再通过 CDN 分发给观看端。

​		另外，安卓的一些低端机可能由于硬件问题对硬编支持不完善，这时候可以使用软编，或者硬编出错的情况可以切换为软编来兜底。当然有时候，对于一些性能优越的高端机型或者编码时长不多的业务场景也可以优先用软编，例如录制 15 秒短视频的场景，首先时间比较短并且机器性能高不怕 CPU 消耗，这样相同码率可以再提高清晰度。

​		大部分的应用场景的解码策略则主要采用硬解，用软解作为兜底。此外，对于一些硬解不支持的编码类型，可以使用软解，比如有的机型不支持 H.265 解码，则只能使用软解。



### 序列

​		序列可以理解为有相同特点的一段图像数据。

​		一段时间内相邻的图像的像素、亮度与色温的差别通常很小。没必要对一段时间内的每一幅图像都进行完整一帧的编码，而是可以选取这段时间的第一帧图像进行完整编码，而下一幅图像只记录与第一帧完整编码图像的像素、亮度与色温等特征的**差别**即可，以此类推循环下去。



### 帧类型

​		一幅视频图像编码后的数据叫做一帧，一帧由一个片（slice）或多个片组成，一个片由一个或多个宏块（MB）组成，一个宏块由 `16x16` 的 YUV 数据组成。**宏块是 H.264 编码的基本单位**。

​		 对于帧内预测和帧间预测技术的不同应用产生了不同的帧类型。

- I帧：关键帧，采用帧内压缩技术。
- P帧：向前参考帧。采用帧间和帧内压缩技术。
- B帧：双向参考帧。采用帧间和帧内压缩技术。

> P、B帧同时包含帧间帧内预测，所以宏块同样也有划分I、P、B宏块。
>
> I宏块用来做帧内预测，P宏块用来做向前参考帧的预测，B宏块用来做双向参考帧预测。
>
> I帧仅包含I宏块，P帧包含P宏块和I宏块，B帧包含B宏块和I宏块。

#### **I 帧**

​		帧内编码图像帧，不参考其他图像帧，只利用本帧的信息进行编码。

​		**I 帧的特点：**

- 它是一个全帧压缩编码帧，将全帧图像信息进行压缩编码及传输；
  - 帧内编码，数据量大
  - I帧压缩可去掉视频的空间冗余信息
    - I帧压缩可以得到6:1的压缩比而不会产生任何可觉察的模糊现象
    - P帧和B帧是为了去掉时间冗余信息
  - 经过适度地压缩，作为随机访问的参考点，可以当成静态图像
- 解码时仅用 I 帧的数据就可重构完整图像；
- I 帧描述了图像背景和运动主体的详情；
- I 帧不需要参考其他画面而生成，不需要考虑运动矢量
- I 帧是 P 帧和 B 帧的被参考帧，其质量直接影响到同组中以后各帧的质量；
  - I帧可以单独解码出一张完整的图片，质量直接影响到同组中以后各帧的质量
  - 参考帧可以参考I帧的信息来解码出一张完整的图片
- 一般地，I 帧是图像组 GOP 的基础帧（第一帧），在一组中只有一个 I 帧；
  - 周期性插入图像序列中，频率可由编码器指定
  - 通常是每个GOP的第一个帧
- I 帧所占数据的信息量比较大。



​		**I 帧编码流程：**

- 进行帧内预测，决定所采用的帧内预测模式；
- 当前像素值减去预测值，得到残差；
- 对残差进行变换和量化；
- 变长编码和算术编码；
- 重构图像并滤波，得到的图像作为其它帧的参考帧。



#### **P 帧**

​		预测编码图像帧，利用之前的 I 帧或 P 帧，采用运动预测的方式进行帧间预测编码。

​		充分去除图像序列中此帧之前已编码帧的时间冗余信息，压缩编码图像。

​		P 帧的预测与重构：

- P 帧是以 I 帧为参考帧，在 I 帧中找出 P 帧『某点』的预测值和运动矢量，取预测差值和运动矢量一起传送。
- 在接收端根据运动矢量从 I 帧中找出 P 帧『某点』的预测值并与差值相加以得到 P 帧『某点』样值，从而可得到完整的 P 帧。

​		P 帧特点：

- P 帧是 I 帧后面相隔 1-2 帧的编码帧；
- P 帧采用运动补偿的方法传送它与前面的 I 或 P 帧的差值及运动矢量（预测误差）；
- P 帧属于前向预测的帧间压缩技术，不能单独解码，需要参考前面的I帧或P帧
- P 帧可以是其后面 P 帧的参考帧，也可以是其前后的 B 帧的参考帧；
- 由于 P 帧是参考帧，它可能造成解码错误的扩散；
  - 如果其前面帧有丢失，会导致花屏。
- 由于是差值传送，P 帧的压缩比较高。

​		P 帧编码的基本流程：

- 进行运动估计，计算采用帧间编码模式的率失真函数值。P 帧只参考前面的帧；
- 进行帧内预测，选取率失真函数值最小的帧内模式与帧间模式比较，确定采用哪种编码模式；
- 计算实际值和预测值的差值；
- 对残差进行变换和量化；
- 若编码，如果是帧间编码模式，编码运动矢量。



#### **B 帧**

​		双向预测内插参考帧（bi-directional interpolated prediction frame），提供最高的压缩比，B帧则需要参考其前一个I帧或者P帧及其后面的一个P帧来生成一张完整的视频画面。采用运动预测的方式进行帧间双向预测编码。

​		由于需要参考后面的P帧，所以B帧虽然提高了压缩率，但是也带来了编码延迟问题（需要等后面一帧编码好才能编码）。

​		B 帧的预测与重构：

- B 帧以前面的 I 或 P 帧和后面的 P 帧为参考帧，找出 B 帧『某点』的预测值和两个运动矢量，并取预测差值和运动矢量传送。
- 接收端根据运动矢量在两个参考帧中找出预测值并与差值求和，得到 B 帧『某点』样值，从而可得到完整的 B 帧。

​		B 帧特点：

- B 帧是由前面的 I 或 P 帧和后面的 P 帧来进行预测的；
- B 帧传送的是它与前面的 I 或 P 帧和后面的 P 帧之间的预测误差及运动矢量；
- B 帧是双向预测编码帧；
- B 帧压缩比最高，因为它只反映两参考帧间运动主体的变化情况，预测比较准确；
- B 帧不是参考帧，不会造成解码错误的扩散。

​		B 帧编码的基本流程：

- 进行运动估计，计算采用帧间编码模式的率失真函数值。B 帧可参考后面的帧；
- 进行帧内预测，选取率失真函数值最小的帧内模式与帧间模式比较，确定采用哪种编码模式；
- 计算实际值和预测值的差值；
- 对残差进行变换和量化；
- 若编码，如果是帧间编码模式，编码运动矢量。

> ​		在提高视频质量的技巧中，还有个技巧是多使用B帧。
>
> ​		一般来说，I的压缩率是7（与JPEG差不多）, P是20, B可以达到50，可见使用B帧能节省大量空间，节省出来的空间可以用来更多地保存I帧，这样就能在相同的码率下提供更好的画质。
>
> ​		但很多场景下为了解码的即时性，不使用B帧。比如安防领域。
>
> ​		在`baseline`编码规格下，无B帧；在`main profile`规格下一般有B帧，通常来说B帧参与编码会提高压缩率，降低帧大小，但是会增加编解码复杂性。



#### IDR帧

​		**Instantaneous Decoder Refresh，是 I 帧的一种。IDR 帧的作用是立刻刷新，重新算一个新的序列开始编码，使错误不致传播。**I 帧有被跨帧参考的可能，但 IDR 帧不会。

> 比如：
>
> ```
> IDR1 P2 B3 B4 P5 B6 B7 I8 B9 B10 P11 B12 B13 P14 B15 B16
> ```
>
> 这里的 B9 可以跨过 I8 去参考 P7。
>
> ```
> IDR1 P2 B3 B4 P5 B6 B7 IDR8 B9 B10 P11 B12 B13 P14 B15 B16
> ```
>
> 这里的 B9 就不可以参考 IDR8 前面的帧。

​		引入 IDR 帧是为了解码的重同步，当解码器解码到 IDR 帧时，立即将参考帧队列清空，将已解码的数据全部输出或抛弃，重新查找参数集，开始一个新的序列。

​		这样，如果前一个序列出现错误，在这里可以获得重新同步的机会，不会将错误传导下去。IDR 帧之后的帧永远不会使用 IDR 帧之前的帧来解码。

> ​		因为H264采用了多帧预测，所以I帧之后的P帧有可能会参考I帧之前的帧。这就使得在随机访问的时候不能以找到I帧作为参考条件清理缓冲区。因为即便找到I帧，I帧之后的帧还是有可能因为参考I帧之前的帧而解析不出来。
>
> ​		IDR帧就是一种特殊的I帧，即这一帧之后的所有参考帧只会参考到这个IDR帧，而不会再参考前面的帧。
>
> ​		在解码器中，一旦收到一个IDR帧，就会立即清理参考帧缓冲区，并将IDR帧作为被参考的帧。

​		IDR 帧有如下特性：

- IDR 帧一定是 I 帧，严格来说 I 帧不一定是 IDR 帧（但一般 I 帧就是 IDR 帧）；
- 对于 IDR 帧来说，在 IDR 帧之后的所有帧都不能引用任何 IDR 帧之前的帧的内容。与此相反，对于普通的 I 帧来说，位于其之后的 B 和 P 帧可以引用位于普通 I 帧之前的 I 帧（普通 I 帧有被跨帧参考的可能）；
- 播放器永远可以从一个 IDR 帧播放，因为在它之后没有任何帧引用之前的帧。因此，视频开头的 I 帧一定是 IDR 帧；一个封闭类 GOP 的开头的 I 帧也一定是 IDR 帧。

> I帧和IDR帧都是使用帧内预测的，是同一个东西。
>
> 在编码和解码中为了方便，把首个I帧和其他I帧区别开，所以才把首个I帧叫IDR帧，方便控制编码和解码的流程。
>
> ​	<img src="https://img-blog.csdnimg.cn/dd2f694073544d74931dd4b9839b324a.png" alt="在这里插入图片描述" style="zoom: 80%;" />
>
> <img src="https://img-blog.csdnimg.cn/52b2b2e01e314ced9dd9dd5ccaf9f06b.png" alt="在这里插入图片描述"  />

​		

​	

### 率失真函数

​		有损压缩算法，性能由**编码输出的比特率**和**失真**共同决定。

- **编码的目的**：就是在保证一定视频质量的条件下尽量减少编码比特率，或在一定编码比特率限制条件下尽量地减小编码失真。
- **编码器的工作**：根据以上率失真准则找到最佳编码参数。
- **信息论中率失真概念**：在允许一定程度失真的条件下，能够把信源信息压缩到什么程度，即最少需要多少比特数才能描述信源。由此得到率失真函数：`R(D) = min I(X, Y)`，它给出了限定失真条件下信息压缩允许的下界。但其在视频编码中难以应用，因为各种概率和条件概率未知，只能作为理论值。
- **视频编码中的率失真曲线**：为了研究视频码率与视频质量的平衡。由于系统性，不能达到理论上的 R(D) 值，只能由不同的编码参数（如 QP 和选择的模式）得到有限的 (R, D) 可操作点，形成凸包络。
- **视频编码中的率失真优化（RDO）**：遍历所有的参数候选模式对视频进行编码，满足码率限制的失真最小的一组参数集作为最优的视频编码参数。每一层级都找出，最终使整体系统性能最优。这里假设了无相关性的独立优化，如相关性较强则共同优化。



### PTS / DTS

​				由于B帧的引入，会导致编码的帧顺序和播放的帧顺序会不一致，所以也衍生了两个时间戳，DTS（Decoding Time Stamp）和 PTS（Presentation Time Stamp）。

- DTS（Decoding Time Stamp）：即解码时间戳，这个时间戳的意义在于告诉播放器该在什么时候解码这一帧的数据。
- PTS（Presentation Time Stamp）：即显示时间戳，这个时间戳用来告诉播放器该在什么时候显示这一帧的数据。

<img src="https://raw.githubusercontent.com/Mocearan/picgo-server/main/0248ca664ff24d4ea3638735b97e34c3.png" alt="在这里插入图片描述" style="zoom: 67%;" />

​		DTS、PTS 是用于指导播放端的行为，但它们是在编码的时候由编码器生成的。

​		在没有B帧的情况下，DTS和PTS的输出顺序是一样的，因为没有延迟编码。而对于有B-frame的视频，I-frame的PTS依然等于DTS，P-frame的PTS>DTS，B-frame的PTS<DTS。

> - 若视频没有B-frame，则I和P都是解码后即刻显示。
> - 若视频含有B-frame，则I是解码后即刻显示，P是先解码后显示，B是后解码先显示。（B和P的先、后是相对的）。



### GOP

​		GOP（Group Of Picture），表示视频中一个独立播放的图片组。它指的是视频编码序列中两个 I 帧之间的图像序列。

​		H.264 使用的是封闭 GOP（Closed GOP），即在一个 GOP 中所有帧的解码不依赖该 GOP 外的其他帧，除了第一帧必须是 I 帧，其他帧可以是 P 帧或 B 帧。

> GOP 由 I 帧开始，到下一个 I 帧之前的帧结束。严格意义上讲，这个 I 帧是一个 IDR 帧。
>
> GOP是利用分组的思想，组间周期性的进行一次帧内预测，保证整体场景的刷新；组内通过帧间预测大大降低冗余信息。

​		通常在为编码器设置参数的时候，必须要设置``的值，其代表的是两个I帧之间的帧数目。

​		![图片](https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSuejJrgRTLgovpyFlfffh6IAqB7kmKYEzQEezuneeHmBrOGMicTSiamCy4R01ftkMmYNQRkb1tO8jbbIg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

> 上图中是一个 `gop_size`为 15 帧的例子，如果视频的帧率是 15 fps，那么这个 GOP 就是 1s 时长。

​		关键帧的间隔调节会影响 GOP 的长度，进而影响到读取 GOP 的速度，为防止运动变化，一个 GOP 组内帧数不宜取多。如果关键帧的间隔设置过大的话（GOP 长度过大），在必须用到关键帧的场合就可能被迫使用 B/P 帧来代替，这就会降低画面质量。

- 一个GOP中容量最大的帧就是I帧
  - `gop_size`设置得越小，整个画面的质量就会越好。
- 解码端必须从接收到的第一个I帧开始才可以正确解码出原始图像，否则会无法正确解码。
- 根据不同的业务场景，适当地设置`gop_size`的大小，以得到更高质量的视频。
- 但是过多的P、B帧会影响编码的效率
  - 为了防止未加载完跳转卡顿时间长等问题，一般设置GOP为帧率的4-5倍，保证4-5秒必有I帧
  - 直播流一般禁止B帧，有利于直播的流畅

- 还会影响seek操作的响应速度

![在这里插入图片描述](https://raw.githubusercontent.com/Mocearan/picgo-server/main/2d11ae3d85b2bd5b0bb18da7a68cad87.png)



### 压缩方式

​		H.264 采用的核心算法是『帧内压缩』和『帧间压缩』，帧内压缩是生成 I 帧的算法，帧间压缩是生成 B 帧和 P 帧的算法。

- 帧内压缩也称为空间压缩

  - 当压缩一帧图像时，仅考虑本帧的数据而不考虑相邻帧之间的冗余信息，这实际上与静态图像压缩类似。
  - 帧内一般采用有损压缩算法，由于帧内压缩是编码一个完整的图像，所以可以独立的解码、显示。
  - 帧内压缩一般达不到很高的压缩率，跟编码 JPEG 差不多。

- 帧间压缩也称为时间压缩

  - 它通过比较时间轴上不同帧之间的数据进行压缩。
  - 帧间压缩一般是无损的。
  - 帧差值算法是一种典型的时间压缩法，它通过比较本帧与相邻帧之间的差异，仅记录本帧与其相邻帧的差值，这样可以大大减少数据量。

  > 帧间压缩的原理是：相邻几帧的数据有很大的相关性，或者说前后两帧信息变化很小的特点。
  >
  > 也即连续的视频其相邻帧之间具有冗余信息，根据这一特性，压缩相邻帧之间的冗余量就可以进一步提高压缩量，减小压缩比。

​		

​		编码压缩的步骤大致如下：

- 分组，也就是将一系列变换不大的图像归为一个组，也就是一个序列，也就是 GOP；
- 定义帧，将每组的图像帧归分为 I 帧、P 帧和 B 帧三种类型；
- 预测帧，以 I 帧做为基础帧，以 I 帧预测 P 帧，再由 I 帧和 P 帧预测 B 帧；
- 数据传输，最后将 I 帧数据与预测的差值信息进行存储和传输。



## 分层结构：VCL / NAL

​		H.264 的主要目标是为了有高的视频压缩比和良好的网络亲和性，为了达成这两个目标，H.264 的解决方案是将系统框架分为两个层面：『视频编码层面（VCL）』和『网络抽象层面（NAL）』。

- **视频编码层（VCL）**，是对视频编码核心算法过程、子宏块、宏块、片等概念的定义。
  - 这层主要是为了尽可能的独立于网络来高效的对视频内容进行编码。
  - 编码完成后，输出的数据是 `SODB（String Of Data Bits）`。
- **网络适配层（NAL）**，是对图像序列、图像等片级别以上的概念的定义。
  - 这层负责将 `VCL `产生的比特字符串适配到各种各样的网络和多元环境中。
  - 该层将 `VCL `层输出的 `SODB `数据打包成` RBSP（Raw Byte Sequence Payload）`。
    - `SODB `是编码后的原始数据，`RBSP `是在原始编码数据后面添加了结尾比特，一个比特 1 和若干个比特 0，用于字节对齐。
  - 然后再在 `RBSP `头部加上` NAL Header` 来组成一个一个的 `NAL` 单元。



###  VCL

​		视频编码层，包括核心压缩引擎和块，宏块和片的语法级别定义。设计目标是对视频原始数据进行压缩，不考虑存储传输要解决的封装问题。

​		H.264的码流分层结构：

- 序列（GOP）
- 图片（Picture）
- 切片（Slice）
- 宏块（Macroblock）
- 子块（Subblock）

> ​		从 H.261 到 H.263 视频编码标准中，将码流的结构划分为四个层次：
>
> - 图像层（picture layer）
> - 块组层（GOB layer）
> - 宏块层（macroblock layer）
> - 块层（block layer）
>
> <img src="https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSuejJrgRTLgovpyFlfffh6IAqbWQoJb1X2ILm0l3UTX2j6m2How72PEhKibhXqbLns67Fb3rOdxsTWpg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom: 80%;" />
>
> <img src="https://img-blog.csdnimg.cn/direct/df235230a9c149bb850d2f883d0d4e06.png" alt="在这里插入图片描述" style="zoom: 33%;" />



![图片](https://ask.qcloudimg.com/http-save/3985899/3c4324fb058cd434c1e8c541e7f3bf14.webp)

> **macroblock 宏块:**
>
> ​		宏块是视频信息的主要承载者，因为它包含着每一个像素的亮度和色度信息。视频解码最主要的工作则是提供高效的方式从码流中获得宏块中的像素阵列。
>
> ​		一个宏块由一个 16×16 亮度像素和附加的一个8×8 Cb和一个 8×8 Cr 彩色像素块组成。每个图象中，若干宏块被排列成片的形式。
>
> <img src="https://img-blog.csdnimg.cn/d63d8ec0acb44b659c46b3a6955c20c6.png#pic_center" alt="在这里插入图片描述" style="zoom:50%;" />

​		

​		

#### 编码流程

​		通过摄像头采集到的视频帧，被送到 H.264 编码器的缓冲区中。（帧率假使为30）

- 第一步：逐帧划分宏块
  - 划分好宏块后，计算宏块的像素值
- 第二步：逐帧划分子块
  - 对比较平坦的图像使用 16x16 大小的宏块。
    - 但为了更高的压缩率，还可以在 16x16 的宏块上更划分出更小的子块。
    - 子块的大小可以是 8x16､ 16x8､ 8x8､ 4x8､ 8x4､ 4x4非常的灵活
  - 再经过帧内压缩，可以得到更高效的数据
- 第三步：帧分组
  - 分组，相关帧通过预测的方法来压缩数据
  - 编码器会按顺序，每次取出两幅相邻的帧进行宏块比较，计算两帧的相似度
  - 一组帧中，经过编码后，只保留第一帧的完整数据，其它帧都参考上一帧计算出来
    - 称第一帧为` I `帧，其它帧我们称为 `P/B` 帧
  - 编码后的数据帧组称为 `GOP`
- 第四步：帧间压缩（运动估计与补偿）
  - 计算帧组内物体的运动矢量
  - 去除帧间相同部分，得到补偿数据
  - 只需要将补偿数据进行压缩保存，以后在解码时就可以恢复原图
- 第五步：帧内压缩
  - 去除一幅图像中人眼不敏感的数据
  - H.264的帧内压缩与JPEG相似
    - 一幅图像被划分好宏块后，对每个宏块可以进行 9 种模式的预测
    - 找出与原图最接近的一种预测模式
    - 将原始图像与帧内预测后的图像相减，得到残差值
    - 将之前得到的预测模式信息一起保存起来，这样我们就可以在解码时恢复原图
- 第六步：对残差数据做DCT
  - 将残差数据做整数离散余弦变换，去掉数据的相关性，进一步压缩数据
- 第七步：CABAC压缩
  - 无损压缩技术
  - 最熟悉的可能就是哈夫曼编码了，给高频的词一个短码，给低频词一个长码从而达到数据压缩的目的
  - CABAC也是给高频数据短码，给低频数据长码。同时还会根据上下文相关性进行压缩，这种方式又比VLC高效很多

<img src="https://img-blog.csdnimg.cn/img_convert/efbfb431d6d8abffa80f45fc02c3541d.webp?x-oss-process=image/format,png#pic_center" alt="在这里插入图片描述" style="zoom:50%;" />



> 一个典型的视频编码器。在进行当前信号编码时，
>
> 1. 编码器首先会产生对当前信号做预测的信号，称作**预测信号**（Predicted Signal），
>    1. 预测的方式可以是时间上的**帧间预测**（Inter Prediction），亦即使用先前帧的信号做预测
>    2. 或是空间上的**帧内预测**（Intra Prediction），亦即使用同一张帧之中相邻像素的信号做预测。
> 2. 得到预测信号后，编码器会将当前信号与预测信号相减得到**残差信号**（Residual Signal），并只对残差信号进行编码，如此一来，可以去除一部分时间上或是空间上的冗余信息。
> 3. 接着，编码器并不会直接对残差信号进行编码，而是先将残差信号经过**变换**（通常为离散余弦变换）然后**量化**以进一步去除空间上和感知上的冗余信息。
> 4. 量化后得到的量化系数会再透过**熵编码**，去除统计上的冗余信息。
>
> ![图片](https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSuejJrgRTLgovpyFlfffh6IAqh0rDJCUic7oUKCqqDO4gicd1JaDd4KJEnnmYPibFRDkBl3yjibome6hbfA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)
>
> <img src="https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSuejJrgRTLgovpyFlfffh6IAqdia4COZmpadM8iaJr3k1ABPDqJ5Cia7zqicWiapjkhHdXyXUBUS9O05HeBg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1" alt="图片" style="zoom:67%;" />

#### 帧内预测

​		图像中相邻元素的亮度和色度信息是渐变的，也就是说，图像具有空间相关性。利用这种相关性，视频压缩就可以通过预测去除空间冗余信息。

​		对一个像素 X 进行编码：

- 找到它临近的像素作为参考像素 `X’`
- 根据` X’ `预测得到对像素 `X` 的预测值 `Xp`
- 用` X` 减去 `Xp` 得到二者的残差 `D`
  - 并用这个残差` D` 代替 `X `进行编码，起到节省码率的作用
- 最后，用预测值 `Xp `和残差 `D` 相加得到` X’` 用于下一个像素的预测

##### 像素估计

​		比如渐变色，我们并不需要指定整个图像全部像素数据，而只是记录开头和结束以及中间变化的颜色，加上渐变位置以及渐变方向。

​		帧内预测通过利用已经编码的相邻像素的值来预测待编码的像素值，最后达到减少空间冗余的目的。

##### 残差估计

​		帧内预测的整体思路是将一帧图片分成若干宏块， 利用其中已经某些块来预测尚其他块，实际值和预测值之间的差别叫做残差。宏块可以预测相邻的宏块。

​		实际上真正编码的是残差数据，因为残差一般比较小，所以对残差编码比对实际数据编码会小很多。



##### 分块编码

​		在实际编码中，我们固然可以按像素为单位进行预测，但这样效率比较低。

​		所以在 H.264 标准中提出按照块为单位进行计算。一个宏块是 16x16 像素，它可以分成子块，最小是 4x4 的，这样能大大提高计算速度。

​		H.264帧内预测中亮度块和色度块是分开独立进行预测的，其中默认是亮度块16x16像素，色度块8x8像素（4:2:0采样）。

> 4:2:0 采样格式的色度宏块的长和宽都是亮度宏块的一半

- 画面信息较为平坦的地方一般使用16x16
- 在细节复杂的地方为了提高质量可以在宏块的基础上使用更小的子块来描述
  - 子块的大小可以是8x16､16x8､8x8､4x8､8x4､4x4，非常的灵活

​		在帧内预测模式中，预测块是基于已编码重建的块和当前块形成的。对亮度像素而言，预测块用于 4×4 子块或者 16×16 宏块的相关操作。

- 4×4 亮度子块有 9 种可选预测模式，独立预测每一个 4×4 亮度子块，适用于带有大量细节的图像编码；

- 16×16 亮度块有 4 种预测模式，预测整个 16×16 亮度块，适用于平坦区域图像编码；

- 色度块也有 4 种预测模式，类似于 16×16 亮度块预测模式。

- 编码器通常选择使预测块和编码块之间差异最小的预测模式

  > ​		每一个宏块只能用一种预测模式，选择预测模式的具体算法很复杂，大概思路就是：
  >
  > - 对于每一个块或者子块，我们可以得到预测块
  > - 再用实际待编码的块减去预测块就可以得到残差块
  > - 然后在不同场景下根据不同的算法对残差块进行计算得到最优的预测模式

>  4x4的块预测模式有9种，分为8个方向模式和一个DC模式：
>
> ![在这里插入图片描述](https://raw.githubusercontent.com/Mocearan/picgo-server/main/ef82f326340946f7bb440e2be1ec9942.png)
>
> 16x16和8x8的宏块预测模式一样，都是有4种帧内预测模式：
>
> ![在这里插入图片描述](https://img-blog.csdnimg.cn/18894e749aed45428322175bae70ee4c.png#pic_center#pic_center)



#### 帧间预测

##### 运动估计

​		寻找当前编码的块在已编码图像中的最佳对应块，就是在所参考的帧中找到与当前块相减残差最小的块。

​		运动估计的关键在于找到最佳的参考块来预测当前块，主要有两种算法：

- 全局搜索算法
  - 把搜索区域内所有的像素块逐个与当前宏块进行比较，查找具有最小匹配误差的一个像素块为匹配块。
  - 优点是可以从预测帧中选择出最准确的预测块，为全局最优结果，预测精度很准
  - 每确定一个预测块都需要对预测帧中的所有块做运算，算法复杂度高，搜索范围大，增加了视频压缩时间
  - 极少使用
- 快速搜索算法
  - 按照一定的数学规则进行匹配块的搜索。这一方法的好处是速度快，坏处是可能只能得到次最佳的匹配块。
  - 三步搜索算法
  - 菱形搜索算法



###### DPB

​		Decoded Picture Buffer，帧间预测需要参考编码好的帧，所以需要缓存队列缓存编码好的再解码重建的帧 来给后续编码的帧作为参考帧。

> ​		那为什么不直接拿原始宏块而要专门重新解码编码好的宏块做为参考呢？
> ​		关键点在于为了和解码流程保持一致的参考宏块，因为编码出来的宏块和解码重建的宏块并非完全一致的，所以如果帧间预测在编码端和解码器端参考帧不一致，就会出错。

​		比如B帧需要前后参考帧，所以需要2个缓存队列：

<img src="https://raw.githubusercontent.com/Mocearan/picgo-server/main/24aa17b49a1941aba4490a2d71032bed.png" alt="在这里插入图片描述" style="zoom: 67%;" />



​		



##### 分块编码

​		H.264 帧间预测是利用已编码视频帧/场和基于块的运动补偿的预测模式。与以往标准帧间预测的区别在于块尺寸范围更广（从 16×16 到 4×4）、亚像素运动矢量的使用（亮度采用 1/4 像素精度 MV）及多参考帧的运用等等。

- 每个宏块（16×16 像素）可以 4 种方式分割：一个 16×16，两个 16×8，两个 8×16，四个 8×8。其运动补偿也相应有四种。
- 而 8×8 模式的每个子块还可以四种方式分割：一个 8×8，两个 4×8 或两个 8×4 及 4 个 4×4。
- 这些分割和子块大大提高了各宏块之间的关联性。
- 这种分割下的运动补偿则称为树状结构运动补偿。

> 每个分割或子宏块都有一个独立的运动补偿。
>
> 每个 MV 必须被编码、传输，分割的选择也需编码到压缩比特流中。
>
> - 对大的分割尺寸而言， MV 选择和分割类型只需少量的比特，但运动补偿残差在多细节区域能量将非常高。
> - 小尺寸分割运动补偿残差能量低，但需要较多的比特表征 MV 和分割选择。
> - 分割尺寸的选择影响了压缩性能。
> - 整体而言，大的分割尺寸适合平坦区域，而小尺寸适合多细节区域。

​		宏块的色度成分（Cr 和 Cb）则为相应亮度的一半（水平和垂直各一半）。

- 色度块采用和亮度块同样的分割模式，只是尺寸减半（水平和垂直方向都减半）。

  > 例如，8×16 的亮度块相应色度块尺寸为 4×8，8×4 亮度块相应色度块尺寸为 4×2 等等。

- 色度块的 MV 也是通过相应亮度 MV 水平和垂直分量减半而得。



#### 变换

​		平坦区域和内容缓慢变化区域占据一幅图像的大部分，而细节区域和内容突变区域则占小部分。也可以说，图像中直流和低频区占大部分，高频区占小部分。这样，空间域的图像变换到频域或所谓的变换域，会产生相关性很小的一些变换系数，并可对其进行压缩编码，即所谓的变换编码。

##### 整数离散余弦变换 DCT

​		整数离散余弦变换（Discrete Cosine Transform，DCT），将空间上的相关性变为频域上无关的数据然后进行量化，解决的是视觉冗余问题。

​		通过傅里叶变换将复杂波形图变换成多个正弦波，他们之间的频率不同，振幅也不同。如果它们在频率上没有一致性那么我们就可以对他进行压缩处理。

##### 图像频率

​		图像的频率是指灰度值变化剧烈程度的指标，是灰度在平面空间上的梯度。图像的低频是轮廓，高频是噪声和细节。

​		低频就是颜色缓慢地变化，也就是灰度缓慢地变化，就代表着那是连续渐变的一块区域，这部分就是低频。也就是边缘以内的内容为低频，而边缘内的内容就是图像的大部分信息，即图像的大致概貌和轮廓，是图像的近似信息。

​		高频就是频率变化快。图像色块边缘的灰度值变化快，就对应着频率高，即高频显示影像边缘。图像的细节处也是属于灰度值急剧变化的区域，正是因为灰度值的急剧变化，才会出现细节。

​		另外噪声（即噪点） 也是这样，在一个像素所在的位置，之所以是噪点，就是因为它与正常的点颜色不一样了，也就是说该像素点灰度值明显不一样了，也就是灰度有快速地变化了，所以是高频部分，因此有噪声在高频这么一说。

##### DCT理论依据

​		人眼的视觉敏感度是有限的，有的时候我们去除了一部分高频信息之后，人眼看上去感觉区别并不大。这就是视觉冗余。

​		先将图片通过 DCT 变换到频域，然后再去除一些高频信息。这样我 们就可以减少信息量，从而达到压缩的目的。

​		最后效果为在变换后的块中，左上角的系数往往比较大，越靠近右下角的系数越小，这是就是因为高频系数一般比较小的缘故，而低频分量一般比较大。

![在这里插入图片描述](https://raw.githubusercontent.com/Mocearan/picgo-server/main/baa105766b0b49338674b9d5ab36a3c8.png)



#### 量化

​		DCT变换并没有进行压缩，压缩需要后面一步的支持——量化。

​		量化基本决定了视频的码率，视频的码率又从一定程度上决定了视频的质量。

​		量化值QP越大则量化的粒度越高，压缩率越大，码率更小，视频质量越低，呈现出来就是马赛克比较大，画面不细腻，画面比较模糊。反之，压缩率低，码率大，质量高，画面细腻，细节丰富。

![在这里插入图片描述](https://raw.githubusercontent.com/Mocearan/picgo-server/main/7c5894d5fc62474e9ea611e5116c61cb.png)

> 最后效果为大部分系数都变为0了，这就是通过量化去除高频分量的结果，右下角部分基本都为0。

​		在图像编码中，变换编码和量化从原理上讲是两个独立的过程。但在 H.264 中，将两个过程中的乘法合二为一，并进一步采用整数运算，减少编解码的运算量，提高图像压缩的实时性。

​		H.264 对图像或预测残差采用了 4×4 整数离散余弦变换（DCT）技术，避免了以往标准中使用的通用 8×8 离散余弦变 换逆变换经常出现的失配问题。量化过程根据图像的动态范围大小确定量化参数，既保留图像必要的细节，又减少码流。



#### 熵编码

​		视频编码中真正实现“压缩”的步骤，主要去除信息熵冗余。而前面说的去除空间、时间、视觉冗余，其实都是为这一步做准备的。

> - 熵的大小与信源的概率模型有着密切的关系，各个符号出现的概率不同，信源的熵也不同。
>   - 当信源中各事件是等概率分布时，熵具有极大值。
> - 信源的熵与其可能达到的最大值之间的差值反映了该信源所含有的冗余度。
>   - 信源的冗余度越小，即每个符号所独立携带的信息量越大，那么传送相同的信息量所需要的序列长度越短，符号位越少。
>
> 因此，数据压缩的一个基本的途径是去除信源的符号之间的相关性，尽可能地使序列成为无记忆的，即前一符号的出现不影响以后任何一个符号出现的概率。

​		利用信源的统计特性进行码率压缩的编码就称为熵编码，也叫统计编码。

​		熵编码是无损压缩编码方法，它生成的码流可以经解码无失真地恢复出原数据。熵编码是建立在随机过程的统计特性基础上的。

​		视频编码常用的有两种：变长编码（哈夫曼编码）、算术编码。H.264 最后将结果进行熵编码，分为`上下文自适应的变长编码（Context-based Adaptive Variable-Length Coding，CAVLC）`与`上下文自适应的二进制算术编码（Context-based Adaptive Binary Arithmetic Coding，CABAC）`。



##### CAVLC 上下文自适应的变长编码

​		通过根据已编码句法元素的情况动态调整编码中使用的码表，取得了极高的压缩比。CAVLC 用于亮度和色度残差数据的编码。残差经过变换量化后的数据表现出如下特性：4×4 块数据经过预测、变换、量化后，非零系数主要集中在低频部分，而高频系数大部分是零；量化后的数据经过 zig-zag 扫描，DC 系数附近的非零系数值较大，而高频位置上的非零系数值大部分是 +1 和 -1；相邻的 4×4 块的非零系数的数目是相关的。CAVLC 充分利用残差经过整数变换、量化后数据的特性进行压缩，进一步减少数据中的冗余信息，为 H.264 卓越的编码效率奠定了基础。



##### CABAC 上下文自适应的二进制算术编码

​		CABAC压缩属于**无损压缩**，编码的目的是从概率的角度再做一次压缩。

​		编码的过程主要分为：

- 二值化
- 上下文建模
- 二进制算术编码

> 无损压缩技术最熟悉的可能就是哈夫曼编码（变长编码）了，给高频的词一个短码，给低频词一个长码从而达到数据压缩的目的。MPEG-2中使用的VLC就是这种算法。
> CABAC也是给高频数据短码，给低频数据长码。同时还会根据上下文相关性进行压缩，这种方式又比VLC高效很多。

###### 算术编码

​		思想是用 0 到 1 的区间上的一个数来表示一个字符输入流，它的本质是为整个输入流分配一个码字，而不是给输入流中的每个字符分别指定码字。算术编码是用区间递进的方法来为输入流寻找这个码字的，它从于第一个符号确定的初始区间（0 到 1）开始，逐个字符地读入输入流，在每一个新的字符出现后递归地划分当前区间，划分的根据是各个字符的概率，将当前区间按照各个字符的概率划分成若干子区间，将当前字符对应的子 2 区间取出，作为处理下一个字符时的当前区间。到处理完最后一个字符后，得到了最终区间，在最终区间中任意挑选一个数作为输出。解码器按照和编码相同的方法和步骤工作，不同的是作为逆过程，解码器每划分一个子区间就得到输入流中的一个字符。在实际过程中，输入流中字符的概率分布是动态改变的，这需要维护一个概率表去记录概率变化的信息。在作递进计算时，通过对概率表中的值估计当前字符的概率，当前字符处理后，需要重新刷新概率表。这个过程表现为对输入流字符的自适应。编码器和解码器按照同样的方法估计和刷新 概率表，从而保证编码后的码流能够顺利解码。

​		用哈夫曼编码（变长编码），必须为所有可能的长度为 N 的序列设计和存储码书，这样做的复杂度随 N 呈指数增长。用算术编码则不需要预先为每个可能的信源序列指定码书。而是每当所确定区间的下限和上限有公共最高有效位时，就可以连续地得到比特。编码序列的长度可以和信源的长度一样长。因此，实际上，算术编码可以更接近熵率。

​		算术编码的另一个优点是可以简单地通过更新符号概率表来实现对信源统计特性的自适应。通过对不同上下文用不同的概率表也可以容易地实现条件编码。对于哈夫曼编码，则不得不基于更新的概率表重新设计码书，或对不同的上下文设计多个码表。

​		由于较高的编码效率和易于自适应，只要所涉及的计算量是能接受的，无疑算术编码比哈夫曼编码是一种更好的选择。



###### 二值化

​		二值化就是将像素点的值根据一定的算法，将像素分别修改为0，或255，即获取图像的灰度图，或者通俗些讲就是图像的黑白图。

​		而此处的“二值化”可以暂且理解为，将数值二进制化的一个过程，当然不是简单的将十进制转换为二进制。

​		经过二值化之后，CABAC 就已经把待编码的语法元素按照一定的规则转换为只用“0”和“1”的二进制流，称为比特流。

> 指数哥伦布熵编码：指数哥伦布编码就是CABAC的一种二值化处理的方法。
>
> ​		https://blog.csdn.net/u012188065/article/details/53590641/
>
> ​		https://www.zzsin.com/article/golomb.html
>
> ​		[H.264---指数哥伦布编码 - 知乎](https://zhuanlan.zhihu.com/p/628870070)



###### 上下文建模

​		待编码数据具有上下文相关性，利用已编码数据提供的上下文信息，为待编码的数据选择合适的概率模型，这就是上下文建模。通过对上下文模型的构建，基本概率模型能够适应随视频图像而改变的统计特性，降低数据之间的冗余度，并减少运算开支。

> ​		H.264/AVC 标准将一个 Slice 可能出现的数据划分为 399 个上下文模型，每个模型均有自己的上下文序号，命名为 CtxIdx，每个不同的字符依据对应的上下文模型，来索引自身的概率查找表。即收到字符后，先找到字符对应的上下文模型的序号 CtxIdx，然后根据 CtxIdx 找到其对应的概率查找表。 详细的步骤如下：
>
> 1. 确定当前的字符对应的上下文模型的区间，H264 标准中的表9-1描述了相应的对应关系。
> 2. 按照不同的法则，在第1步中得到的区间中最终确定的上下文模型个的CtxIdx。

![在这里插入图片描述](https://raw.githubusercontent.com/Mocearan/picgo-server/main/93d5aa7ea074ddad3a2d0e0344d42bc8.webp)





###### 二进制算术编码

​		通过上下文建模找到的概率模型的概率估计方法构成了一个自适应二进制算术编码器。概率估计是在前一次上下文建模阶段更新后的概率估计。在对每个二进制数值编码过后，概率估计的值相应的也会根据刚刚编码的二进制符号进行调整。

​		二进制算术编码是算术编码的特殊情况，其原理与一般算术编码一样。不同的是，二进制算术编码序列只有“0”和“1”两种符号，所涉及的概率也只有P(0)和P(1)。





### NALU

​		`H.264`的编码帧序列包括一系列的`NAL`单元，每个`NAL`单元包含一个`RBSP`

- 单元的信息头定义了`RBSP`单元的类型
- `NAL`单元其余部分为`RBSP`数据
- `NALU `内不一定是`VCL`数据切片， `NALU `还有可能装载着其他用作描述视频的信息(`SPS/PPS`)



#### 码流结构

​		H.264 原始码流（又称为裸流），是由一个接一个的 NAL 单元组成的（NAL Header 加上 `RBSP `组成一个 NAL 单元）。

​		通常来说，一个原始的H.264 NALU 单元常由三部分组成

​			` [AnnexB StartCode]/[frame length] [NALU Header] [NALU Payload]`

- `AnnectB StartCode ` 或 `frame length` 是H264封装部分打上的封装头
  - 在数据流中分辨每个 NAL 的起始和终止
  - 如果以`AnnexB`格式封装，则添加`StartCode`；如果以`AVCC`格式封装，则添加`frame length`
- `NALU Header`是为网络传输打上的传输头
- `NALU Payload`在分割数据时，





#### 封装格式

![图片](https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSuejJrgRTLgovpyFlfffh6IAqCPobPU2DZ3rLMIWbtribRg59qEF60pYcicuVXoZ5lgxSZibooXVFKJxYQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

​		h264的封装格式有两种`annex-b`和`avcc`

> - 编码后的视频数据和音频数据，分别按照编码的格式封装。
>   - 比如`AAC`也有自己的封装格式
> - 然后再和其他信息一起复合封装为一个容器文件如`ps/ts/mp4`。
>
> 这种结构化的分层封装方式使得多媒体内容在不同环境下都能得到有效的管理和播放。

​		H.264有两种封装，二者都以`NAL`作为基本封装单位。为了节省码流，`H.264` 没有另外在 `NAL `的头部设立表示起始的句法元素。但是如果编码数据是储存在介质（如 DVD 光盘）上，由于 `NAL `是依次紧密排列，解码器将无法在数据流中分辨每个 NAL 的起始和终止，所以必须要有另外的机制来解决这个问题。于是有了`AnnexB`和`AVCC`两种封装格式。

##### `AnnexB `

​		将 H.264 视频数据以 NAL 单元的形式进行封装，适合实时传输和容错。

​		在每个 `NAL` 前添加**起始码**：`0x000001`。这就是我们常说的 **Annex-b 码流格式**。

-  通过`startcode：0x00 00 00 01`来标识一个`NAL`单元的开始
   -  `0x00000001`标识下一个`nalu`的开始和上一个`nalu`的结束
      -  解码器检测每个起始码，作为一个`NAL`的起始标识，当检测到下一个起始码时，当前NAL结束。
   -  如果该`NALU`对应帧的起始`slice`则用4位字节`0x00 00 00 01`，否则用3位字节`0x00 00 01`
      -  一帧可能被切分为多个`slice`传输
-  `SPS`和`PPS`是在`ES`中，由`nalu`负载的单独的数据包
   - `nalu header->nal_unit_type=7`时，nalu payload中是SPS
   - `nalu header->nal_unit_type=8`时，nalu payload中是PPS
   - 这种格式下`SPS`、`PPS`通常放在关键帧之前
-  对于编码出来的码流，一般都是`annex-b`方式

![图片](https://ask.qcloudimg.com/http-save/3985899/034446e6065ac9b24f1944e7922baa56.webp)



```c
nal_unit( NumBytesInNALunit ) {
	forbidden_zero_bit
    nal_ref_idc
    nal_unit_type

    NumBytesInRBSP = 0
    for( i = 1; i < NumBytesInNALunit; i++ ) {
        if( i + 2 < NumBytesInNALunit && next_bits( 24 ) = = 0x000003 ) {
            rbsp_byte[ NumBytesInRBSP++ ]
            rbsp_byte[ NumBytesInRBSP++ ]
            i += 2
            emulation_prevention_three_byte /* equal to 0x03 */
        } else
             rbsp_byte[ NumBytesInRBSP++ ]
    }
}
```





##### `AVCC`

​		mp4、mkv模式，以更高效的方式存储视频，便于随机访问和播放。

- 没有`startcode`，用1-4个字节加在`nalu`前面，表示`nalu`的长度，表示字节的个数需要单独指定
  - 即每个`nalu`前4个字节是这个`frame`的长度
- `SPS`和`PPS`以及其它信息被封装在`container`的`extradata`中
  - 这种格式下`SPS/PPS`的存放位置和帧数据无关
- `avcc`这种方式在mp4格式中常见



#### NALU Header

![图片](https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSuejJrgRTLgovpyFlfffh6IAqbuBEATIofQYm0ibND3QbdKf7PGcGWvoLKr0poVn1KRpqQD6icRQbWpWw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

​		NAL 单元由` NAL Header` 和 `RBSP `构成。

##### `NAL Header` 结构

```c
/*
0 1   3			8
-----------------
|F|NRI|  Type	|
-----------------
*/
```

- `F (forbidden_zero_bit)`， 屏蔽位，`1bit`

  - 正常状态下应该为`0`，如果`1`应该舍弃
    - 在 H.264 规范中规定了这位必须初始为 `0`
    - 当网络发现`NAL`单元有比特错误时可设置该比特为`1`，以便接收方纠错或丢掉该单元

- `NRI (nal_ref_idc)`， 标识当前NALU的重要性等级，`2 bit`

  - 取值` 00/01/10/11` ( 0-3)
  - 值越大标识当前NALU越重要，如果取 `00`则可以丢弃
  - H.264 规定如果当前 NAL 是属于参考帧的片，或是序列参数集，或是图像参数集这些重要的数据单位时，必须大于 0
    - 但在大于 0 时具体该取何值，却没有进一步规定，通信双方可以灵活地制定策略。

- `Type`，数据类型（`nal_unit_type`），`5 bit`

  - 取值 `0 ~ 31`

    - `0` 没有定义

    - `1~23`单个 NAL 单元包

      - 0：未规定

      - 1：非IDR图像中不采用数据划分的片段

      - 2：非IDR图像中A类数据划分片段

      - 3：非IDR图像中B类数据划分片段

      - 4：非IDR图像中C类数据划分片段
      - `nal_unit_type=5` 时，表示当前 NAL 是 IDR 图像的一个片
        - 在这种情况下，IDR 图像中的每个片的 `nal_unit_type` 都应该等于 5

        - 注意 `IDR `图像不能使用片分区

      - 6：补充增强信息 (SEI)

      - 7：序列参数集

      - 8：图像参数集

      - 9：分割符

      - 10：序列结束符

      - 11：流结束符

      - 12：填充数据

      - 13 – 23：保留

      > ```
      > 0x67 (0 11 00111) SPS		非常重要     		type = 7
      > 0x68 (0 11 01000) PPS		非常重要     		type = 8
      > 0x65 (0 11 00101) IDR  		关键帧  非常重要	  type = 5
      > 0x61 (0 10 00001) I帧      	重要             	 type = 1
      > 0x41 (0 10 00001) P帧      	重要             	 type = 1
      > 0x01 (0 00 00001) B帧      	不重要           	type = 1
      > 0x06 (0 00 00110) SEI      	不重要           	 type = 6
      > ```

    - `24~31`由外部应用使用，用在RTP H264负载类型头或其他外部应用中，说明负载不是一个单独完整的`NALU`包

      - 24	STAP-A（单一时间组合包模式 A，用于一个 RTP 包荷载多个 NALU）
      - 25	STAP-B（单一时间组合包模式 B）

      - 26	MTAP16（多个时间的组合包模式 A）

      - 27	MTAP24（多个时间的组合包模式 B）

      - 28	FU-A（分片模式 A，用于将单个 NALU 分到多个 RTP 包）

      - 29	FU-B（分片模式 B）
      - 30-31 没有定义


> ![在这里插入图片描述](https://raw.githubusercontent.com/Mocearan/picgo-server/main/24108af7d6274f40a70c81715a52246d.png)
>
> 图中划分即分区(slice)



##### `nalu type`

​		H.264码流的`NALU`包不仅是视频数据包，还有相关的编码信息包。

- 码流中第一个`NALU`是`SPS`，第二个`NALU`是`PPS`。内容都是编码器写入的。
- 解码时，解码器要先收`SPS / PPS`来初始化解码器
  - 如果码流中没有`SPS / PPS`解码器无法解析码流数据
  - 如果编码参数改变，则还需要传递一组新的``SPS/PPS``

​		在标准文档中，是用三列表格描述`SPS/PPS`：

- 第一列，写的是语法元素和语法规则；

- 第二列，写的是分类信息。

- 第三列，写的是该行语法元素的描述信息，就是这个元素采用什么编码方式，占用多少空间，又被称作描述子

  - `u(n)`：无符号整数，n bit长度
  - `ue(v)`：无符号指数哥伦布熵编码
  - `se(v)`：有符号指数哥伦布熵编码

  > - `ue(v)`或`se(v)`说明对应字段的数据经过编码，读到数据之后需要先解码，然后才能获得真实的数据。
  > - 如果第三列是`u(8)`，则说明此字段没有经过编码，读取的数据就是原始数据。

> `SPS`和`PPS`中主要使用指数哥伦布熵编码算法。

![在这里插入图片描述](https://img-blog.csdnimg.cn/4ff50a5d9a5341e5ad7df9cb93b3cbc2.png#pic_center)

![在这里插入图片描述](https://img-blog.csdnimg.cn/direct/b847fc0fb6d34bb49787d11f9ef7f4ca.png)

![图片](https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSuejJrgRTLgovpyFlfffh6IAqQt6fgdwVDSBAoSMgu6pHBkChMP66fEdmMyIb6kCt0E3HjBeT4kDKtg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1)

###### `SPS ` 序列参数集

​		Sequence Paramater Set，对应的是针对一段连续编码视频序列的参数。

​		包含 帧数、POC的约束、参考帧数目、解码图像尺寸和帧场编码模式选择标识等信息。

​		SPS 中的信息至关重要，如果其中的数据丢失，解码过程就可能失败。SPS 和 PPS 通常作为解码器的初始化参数。一般情况，SPS 和 PPS 所在的 NAL 单元位于整个码流的起始位置，但是在某些场景下，在码率中间也可能出现这两种结构：

- 解码器要在码流中间开始解码。比如，直播流。
- 编码器在编码过程中改变了码率的参数。比如，图像的分辨率。

​		[H.264 SPS、PPS详解_sps pps-CSDN博客](https://blog.csdn.net/weixin_39399492/article/details/133165059)

​		SPS 其中的关键参数包括：

- `profile_idc`: 表示当前 H.264 码流的编码档次。其中部分档次：

- - 基础档次：BaselineProfile (`profile_idc` 值为 66)
  - 主要档次：MainProfile (`profile_idc` 值为 77)
  - 扩展档次：ExtentedProfile (`profile_idc` 值为 88)

- `level_idc`，表示当前码流的编码等级。编码的等级定义了某种条件下的最大视频分辨率、最大视频帧率等参数。

- `seq_parameter_set_id`，表示当前的序列参数集的 id。通过该 id 值，图像参数集 PPS 可以引用其关联的 SPS 中的参数。

- `log2_max_frame_num_minus4`，用于计算 `MaxFrameNum` 的值。计算公式为 `MaxFrameNum = 2 ^ (log2_max_frame_num_minus4 + 4)`。变量 `MaxFrameNum` 表示 `frame_num` 的最大值，`frame_num` 标识所属图像的解码顺序，在解码过程中它也是一个非常重要的变量。值得注意的是 `frame_num` 是循环计数的，即当它到达 `MaxFrameNum` 后又从 0 重新开始新一轮的计数。解码器必须要有机制检测这种循环，不然会引起类似千年虫的问题，在图像的顺序上造成混乱。

- `pic_order_cnt_type`，指明了 POC(Picture Order Count) 的编码方法，POC 标识图像的播放顺序。由于 H.264 使用了 B 帧预测，使得图像的解码顺序并不一定等于播放顺序，但它们之间存在一定的映射关系。POC 可以由 frame-num 通过映射关系计算得来，也可以索性由编码器显式地传送。H.264 中一共定义了三种 POC 的编码方法，这个句法元素就是用来通知解码器该用哪种方法来计算 POC。

- `log2_max_pic_order_cnt_lsb_minus4`，用于计算 `MaxPicOrderCntLsb` 的值。计算公式为 `MaxPicOrderCntLsb = 2 ^ (log2_max_pic_order_cnt_lsb_minus4 + 4)`。`MaxPicOrderCntLsb` 表示 POC 的最大值，该变量在 `pic_order_cnt_type = 0` 时使用。

- `num_ref_frames`，指定参考帧队列可能达到的最大长度，解码器依照这个句法元素的值开辟存储区，这个存储区用于存放已解码的参考帧，H.264 规定最多可用 16 个参考帧，本句法元素的值最大为 16。值得注意的是这个长度以帧为单位，如果在场模式下，应该相应地扩展一倍。

- `gaps_in_frame_num_value_allowed_flag`，这个句法元素等于 1 时，表示允许句法元素 `frame_num` 可以不连续。当传输信道堵塞严重时，编码器来不及将编码后的图像全部发出，这时允许丢弃若干帧图像。在正常情况下每一帧图像都有依次连续的 `frame_num` 值，解码器检查到如果 `frame_num` 不连续，便能确定有图像被编码器丢弃。这时，解码器必须启动错误掩藏的机制来近似地恢复这些图像，因为这些图像有可能被后续图像用作参考帧。当这个句法元素等于 0 时，表不允许 `frame_num` 不连续，即编码器在任何情况下都不能丢弃图像。这时，H.264 允许解码器可以不去检查 `frame_num` 的连续性以减少计算量。这种情况下如果依然发生 `frame_num` 不连续，表示在传输中发生丢包，解码器会通过其他机制检测到丢包的发生，然后启动错误掩藏的恢复图像。

- `pic_width_in_mbs_minus1`，本句法元素加 1 后指明图像宽度，以宏块为单位：`frame_width = 16 * (pic_width_in_mbs_minus1 + 1)`，宏块尺寸是 16x16。通过这个句法元素解码器可以计算得到亮度分量以像素为单位的图像宽度：`PicWidthInSamplesL = PicWidthInMbs * 16`，从而也可以得到色度分量以像素为单位的图像宽度：`PicWidthInSamplesC = PicWidthInMbs * 8`。以上变量 `PicWidthInSamplesL`、`PicWidthInSamplesC` 分别表示图像的亮度、色度分量以像素为单位的宽。**H.264 将图像的大小在 SPS 中定义，意味着可以在通信过程中随着 SPS 动态地改变图像的大小，甚至可以将传送的图像剪裁后输出。**

- `pic_height_in_map_units_minus1`，本句法元素加 1 后指明图像高度：`PicHeightInMapUnits = pic_height_in_map_units_minus1 + 1`，`PicSizeInMapUnits = PicWidthInMbs * PicHeightInMapUnits`。图像的高度的计算要比宽度的计算复杂，因为一个图像可以是帧也可以是场，从这个句法元素可以
  在帧模式和场模式下分别计算出出亮度、色度的高。值得注意的是，这里以 `map_unit` 为单位。

- `frame_mbs_only_flag`，本句法元素等于 0 时表示本序列中所有图像的编码模式都是帧，没有其他编码模式存在；本句法元素等于 1 时 ，表示本序列中图像的编码模式可能是帧，也可能是场或帧场自适应，某个图像具体是哪一种要由其他句法元素决定。结合 `map_unit` 的含义，这里给出上一个句法元素 `pic_height_in_map_units_minus1` 的进一步解析步骤：

- - 当 `frame_mbs_only_flag` 等于 1，`pic_height_in_map_units_minus1` 指的是一个 picture 中帧的高度；
  - 当 `frame_mbs_only_flag` 等于 0，`pic_height_in_map_units_minus1` 指的是一个 picture 中场的高度。
  - 所以可以得到如下以宏块为单位的图像高度：
  - `FrameHeightInMbs = ( 2 – frame_mbs_only_flag ) * PicHeightInMapUnits`。
  - `PictureHeightInMbs= ( 2 – frame_mbs_only_flag ) * PicHeightInMapUnits`。

###### `PPS ` 图像参数集

​		Picture Parameter Set，对应的是一个序列中某一副图像或者某几幅图像的参数。

​		包含 熵编码模式选择标识、片组数目、初始量化参数和去方块滤波系数调整标识等信息。

​		PPS 其中的关键参数包括：

- `pic_parameter_set_id`，表示当前 PPS 的 id，相关联的各片通过这个 id 来引用对应的 PPS 参数。

- `seq_parameter_set_id`，表示当前 PPS 引用的 SPS 的 id。

- `entropy_coding_mode_flag`，表示熵编码的选择，本句法元素为 0 时，表示熵编码使用 `CAVLC`，本句
  法元素为 1 时表示熵编码使用 `CABAC`。

- `pic_order_present_flag`，POC 的三种计算方法在片层还各需要用一些句法元素作为参数，本句法元素等于 1 时表示在片头会有句法元素表示这些参数；本句法元素等于 0 时，表示片头不会给出这些参数，这些参数使用默认值。

- `num_slice_groups_minus1`，本句法元素加 1 后表示图像中片组的个数。H.264 中没有专门的句法元素用于表示是否使用片组模式，当本句法元素等于 0 （即只有一个片组），表示不使用片组模式，后面也不会跟有用于计算片组映射的句法元素。

- `slice_group_map_type`，当 `num_slice_group_minus1` 大于 0，即使用片组模式时，本句法元素出现在码流中，用以表示片组分割类型。`map_units` 的定义：

- - 帧场自适应模式时，`map_units` 指的是宏块对；
  - 场模式时，`map_units` 指的是宏块；
  - 帧模式时，`map_units` 指的是与宏块对相类似的，上下两个连续宏块的组合体。
  - 当 `frame_mbs_only_flag` 等于 1 时，`map_units` 指的就是宏块；
  - 当 `frame_mbs_only_falg` 等于 0 时：

- `num_ref_idx_l0_active_minus1`，加 1 后表示目前参考帧队列的长度，即有多少个参考帧（包括短期和长期）。值得注意的是，当目前解码图像是场模式下，参考帧队列的长度应该是本句法元素再乘以 2，因为场模式下各帧必须被分解以场对形式存在。（这里所说的场模式包括图像的场及帧场自适应下的处于场模式的宏块对） 本句法元素的值有可能在片头被重载。**在序列参数集中有句法元素** **`num_ref_frames` 也是跟参考帧队列有关，它们的区别是 `num_ref_frames` 表示参考帧队列的最大值，解码器用它的值来分配内存空间；`num_ref_idx_l0_active_minus1` 表示在这个队列中当前实际的、已存在的参考帧数目，这从它的名字 active 中也可以看出来。**这个句法元素是 H.264 中最重要的句法元素之一，编码器要通知解码器某个运动矢量所指向的是哪个参考图像时，并不是直接传送该图像的编号，而是传送该图像在参考帧队列中的序号。这个序号并不是在码流中传送的，而是编码器和解码器同步地、用相同的方法将参考图像放入队列，从而获得一个序号。这个队列在每解一个图像，甚至是每个片后都会动态地更新。维护参考帧队列是编解码器十分重要的工作，而本句法元素是维护参考帧队列的重要依据。参考帧队列的复杂的维护机制是 H.264 重要也是很有特色的组成部分。

- `num_ref_idx_l1_active_minus1` 与上一个句法元素的语义一致，只是本句法元素用于 list1，而上一
  句法元素用于 list0。

- `constrained_intra_pred_flag`，在 P 和 B 片中，帧内编码的宏块的邻近宏块可能是采用的帧间编码。当本句法元素等于 1 时，表示帧内编码的宏块不能用帧间编码的宏块的像素作为自己的预测，即帧内编码的宏块只能用邻近帧内编码的宏块的像素作为自己的预测；而本句法元素等于 0 时，表示不存在这种限制。



###### `SEI` 补充增强信息

​		Supplemental Enhancement Information，属于码流范畴，它提供了向视频码流中加入额外信息的方法，是 H.264 标准的特性之一。

​		SEI的基本特征如下：

- 并非解码过程的必须选项；
- 可能对解码过程（容错、纠错）有帮助；
- 集成在视频码流中。

​		也就是说，视频编码器在输出视频码流的时候，可以不提供 SEI 信息。虽然在视频的传输过程、解封装、解码这些环节，都可能因为某种原因丢弃 SEI 内容，但在视频内容的生成端和传输过程中，是可以插入 SEI 信息的。这些插入的信息，和其他视频内容一同经过传输链路到达消费端。

​		SEI 是一种 NAL 单元类型。它的结构大致如下：

```
// H.264
0x06，n 个 FF 字节 + 1 个非 FF 字节，16 字节 UUID，userData，0x80 或 0x0080
```

- 开始码：H.264 中 SEI 的 NAL 单元类型是 0x06；H.264 中 SEI 的 NAL 单元类型是 0x4E、0x01。
- 自定义：SEI 除了开始的 NAL 单元类型字段外，还存在不同的子类型。H.264 中第 2 个字节或者 H.265 中第 3 个字节 0x05 表示后续是自定义数据。
- 负载长度：表示后续跟着的自定义数据长度，计算方法是：`n * 255 + XY`，也就是将数据长度减去 255，有多少个就写多少个 FF，剩下的如果不为 0，再写一个字节。
- 负载内容：负载内容是 UUID + payload content。UUID 固定 16 个字节，用于区分不同的业务。payload content 表示自定义数据。



###### `slice `切片

​		切片是为了限制传输误码的范围。编码后的一帧被切分为一个或多个片（slice）。每片包含整数个宏块，分片的目的是为了限制错误码的扩散和传输，使编码片相互间保持独立。

- 切片承载宏块，并被 `NALU `装载并进行网络传输的
- 每个片（slice）都应该是互相独立被传输的
  - 某片的预测（片内预测和片间预测）不能以其它片中的宏块（Macroblock）为参考图像

>  在以太网每个包大小是 1500 字节，而一帧往往会大于这个值。所以就需要用于按照一定格式，对 VCL 视像编码层输出的数据拆成多个包传输，并提供包头（header）等信息，以在不同速率的网络上传输或进行存储，所有的拆包和组包都是 NAL 层去处理的。
>
>  覆盖了所有片级以上的语法级别。

​		每个分片也包含着头和数据两部分：

1. 分片头中包含着分片类型、分片中的宏块类型、分片帧的数量、分片属于那个图像以及对应的帧的设置和参数等信息。
2. 分片数据中则是宏块，这里就是我们要找的存储像素数据的地方。

<img src="https://img-blog.csdnimg.cn/9099e938aba544f6b78a4a1d79abd8f9.png#pic_center" alt="在这里插入图片描述" style="zoom:33%;" />

<img src="https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSuejJrgRTLgovpyFlfffh6IAqU5sicceLjv1j8MjygrbxX7SVcppXdWJUdKfcXTwqNNkC7lrCkeZ8SWA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1" alt="图片" style="zoom:50%;" />

​		**切片（slice）类型跟宏块类型的关系**

> I片：只包 I宏块，I 宏块利用从当前片中已解码的像素作为参考进行帧内预测(不能取其它片中的已解码像素作为参考进行帧内预测)。
>
> P片：可包 P和I宏块，P 宏块利用前面已编码图像作为参考图象进行帧内预测，一个帧内编码的宏块可进一步作宏块的分割:即 16×16、16×8、8×16 或 8×8 亮度像素块(以及附带的彩色像素);如果选了 8×8 的子宏块，则可再分成各种子宏块的分割，其尺寸为 8×8、8×4、4×8 或 4×4 亮度像素块(以及附带的彩色像素)。 
>
> B片：可包 B和I宏块，B 宏块则利用双向的参考图象(当前和 来的已编码图象帧)进行帧内预测。 
>
> SP片(切换P)：用于不同编码流之间的切换，包含 P 和/或 I 宏块 
>
> SI片：扩展档次中必须具有的切换，它包 了一种特殊类型的编码宏块，叫做 SI 宏块，SI 也是扩展档次中的必备功能。

​		`Slice `中的关键参数包括：

- `slice_type`，表示当前片的类型。具体类型如下。其中，IDR 图像时，`slice_type` 等于 2、4、7、9。

![图片](https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSuejJrgRTLgovpyFlfffh6IAqhiaVVJtA8ONMEJeSJHgK4XWMmnsdgbdjE1How2chZhxpDvI501OCZAw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1)

- `pic_parameter_set_id`，表示引用的 PPS 的 id。
- `frame_num`，表示解码顺序。每个参考帧都有一个依次连续的 `frame_num` 作为它们的标识，这指明了各图像的解码顺序。但事实上非参考帧的片头也会出现 `frame_num`。只是当该个图像是参考帧时，它所携带的这个句法元素在解码时才有意义。H.264 对 `frame_num` 的值作了如下规定：当参数集中的句法元素 `gaps_in_frame_num_value_allowed_flag` 不为 1 时，每个图像的 `frame_num` 值是它前一个参考帧的 `frame_num` 值增加 1。

![图片](https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSuejJrgRTLgovpyFlfffh6IAq0Asq8Xpsvb9qpU0MY6SXNr45PWaLbV5rMhOUq6P2tNDDdYqgCtIYoQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1)

- `field_pic_flag`，这是在片层标识图像编码模式的唯一一个句法元素。所谓的编码模式是指的帧编码、场编码、帧场自适应编码。
- `idr_pic_id`，IDR 图像的标识。不同的 IDR 图像有不同的 `idr_pic_id` 值。值得注意的是，IDR 图像有不等价于 I 图像，只有在作为 IDR 图像的 I 帧才有这个句法元素，在场模式下，IDR 帧的两个场有相同的 `idr_pic_id` 值。`idr_pic_id` 的取值范围是 `[0，65535]`，和 `frame_num` 类似，当它的值超出这个范围时，它会以循环的方式重新开始计数。
- `pic_order_cnt_lsb`，在 POC 的第一种算法中本句法元素来计算 POC 值，在 POC 的第一种算法中是显式地传递 POC 的值，而其他两种算法是通过 `frame_num` 来映射 POC 的值。



#### NALU Payload

- `SODB `：`Stateless Object Data Bitstream`，数据比特串

  - 不包括额外的元数据或者控制信息
  - 是编码时生成的原始数据，即`VCL`数据
  - 直接传输编码的数据块，简化编码和解码过程

- `RBSP`：`Raw Byte Sequence Payload`。原始字节序列载荷

  - 在`SODB`的后面填加了结尾比特（`RBSP `trailing bits），一个bit“1”，若干bit “0”，以便字节对齐；

    <img src="https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSuejJrgRTLgovpyFlfffh6IAq2ibWZwKXeZkbQgic9dscdxhm3yAZFPLyzWATUQyXwAIfaib0ChBR81bGw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom: 67%;" />

  - `RBSP `通常对配对的 NAL 单元进行封装

    <img src="https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSuejJrgRTLgovpyFlfffh6IAqKebNib1ibS2jgcLQRGpPScdQUX8jRJLkIPhAibibSsh9j9S9ddrDVWCfBA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1" alt="图片" style="zoom: 67%;" />

    

- `EBSP`：`Encapsulation Byte Sequence Packets`，扩展字节序列载荷

  - 在`RBSP`基础上填加了防竞争字节（`0X03`）

    - 循环检测`RBSP`前三个字节，在出现字节竞争时在`NAL`内部冲突数据的第三字节前加入
    - 即，编码数据本身出现了`0x00 00 01 / 0x00 00 00 01`，就使用防竞争码方式让编码不会出现
      -  如果编码器遇到两个字节连续为`0`，`00 00`，就在插入一个字节的`0x03`
      -  解码时将`0x03`去掉，也称为脱壳操作
      -  数据加壳，而不是起始码加壳

  - 控制信息、码流结构

  - 通常会在视频信息传输或存储时使用


> 大量实验证明，NAL 内部经常会出现这样的字节序列。因为 `0x000001` 的情况是覆盖 `0x00000001` 的情况。
>
> 应该检测是否出现下表左侧中的四个字节序列。如果检测到这些序列存在，编码器将在最后一个字节前插入一个新的字节：`0x03`，从而使它们变成下表右侧的样子。当解码器在 NAL 内部检测到有 `0x000003` 的序列时，将把 `0x03` 抛弃，恢复原始数据。
>
> ```
> 0x000000 → 0x00000300
> 0x000001 → 0x00000301
> 0x000002 → 0x00000302
> 0x000003 → 0x00000303
> // 解码器恢复原始数据的方法是检测到 0x000003 就抛弃其中的 0x03，这样当出现原始数据为 0x000003 时会破坏数据，所以必须也应该给这个序列插入 0x03。
> ```
>
> 解码器在逐个字节地读一个 NAL 时并不同时对它解码，而是要通过起始码机制将整个 NAL 读进、计算出长度后再开始解码。

<img src="https://ask.qcloudimg.com/http-save/3985899/d9c48c08fc1cab3c5739ac7e2c6b2c44.webp" alt="图片" style="zoom: 67%;" />







#### 实例

![IDR](https://raw.githubusercontent.com/Mocearan/picgo-server/main/241d2a02f0b9601233f143be3da2fa19.png)

- `00 00 00 01 09`，其中00000001是帧起始位标识，09是nalu header，二进制为00001001，F(7位）为0标识非禁止，NRI（56位）为0标识可丢弃帧，type（04位）为9，表示分隔符，此帧可丢弃，表示分隔符
- `00000001 67`，同上面的分析，NALU头为67，二进制为01100111，F=0，NRI=3，type=7，帧类型为SPS帧，非常重要不可丢弃
- `00000001 68`，NALU头为68，二进制为01101000，F=0，NRI=3，type=8，帧类型为PPS帧，非常重要不可丢弃
- `00000001 06`，NALU头为06，二进制为00000110，F=0，NRI=0，type=6，帧类型为SEI，可丢弃
- `00000001 65`，NALU头为65，二进制为01100101，F=0，NRI=3，type=5，帧类型为I帧，非常重要不可丢弃

> 从上面的分析可以看出，IDR（SPS/PPS/I)帧通常一起出现，极少数编码单独出现I帧，但是IDR与I帧单独出现也符合规范。



## 负载模式

​		NALU负责网络层面的抽象，自然要考虑传输。大多数传输协议需要考虑荷载数量的问题，比如`RTP`协议。考虑到`MTU`，一般传输协议也很少单次发送`1500`字节以上的信息，考虑到各种头部，一般在`1400`字节左右。

​		而视频中码流大小差距很大，可能超过`1400`字节，也可能很小一次可以荷载多个。因此，在`NALU`的头部`type`字段中`24~29`描述了`NALU`包的负载模式。

- `1-23` 描述单一NALU包的类型
  - 0x67 (0 11 00111) SPS		非常重要     		type = 7
  - 0x68 (0 11 01000) PPS		非常重要     		type = 8
  - 0x65 (0 11 00101) IDR  		关键帧  非常重要	  type = 5
  - 0x61 (0 10 00001) I帧      	重要             	 type = 1
  - 0x41 (0 10 00001) P帧      	重要             	 type = 1
  - 0x01 (0 00 00001) B帧      	不重要           	type = 1
  - 0x06 (0 00 00110) SEI      	不重要           	 type = 6
- `24-27` 描述组合包
  - 24	STAP-A（单一时间组合包模式 A，用于一个 RTP 包荷载多个 NALU）
  - 25	STAP-B（单一时间组合包模式 B）

  - 26	MTAP16（多个时间的组合包模式 A）

  - 27	MTAP24（多个时间的组合包模式 B）
- `28-29` 描述分片包
  - 28	FU-A（分片模式 A，用于将单个 NALU 分到多个 RTP 包）
  - 29	FU-B（分片模式 B）



### 单NALU模式

​		一个RTP包荷载一个NALU。

​		`RTP Header + Nalu header + Nalu payload + RTP padding`

```
	  0               1               2               3
      0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |F|NRI|  type   |                                               |
      +-+-+-+-+-+-+-+-+                                               |
      |                                                               |
      |               Bytes 2..n of a Single NAL unit                 |
      |                                                               |
      |                               +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |                               :...OPTIONAL RTP padding        |
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
```



### 组合模式

[H264的RTP负载打包的数据包格式,分组,分片 - DoubleLi - 博客园 (cnblogs.com)](https://www.cnblogs.com/lidabo/p/7159586.html)

​		一个RTP包荷载多个NALU。需要在NALU header之外添加信息。很少使用，不细叙述。

`RTP header + STAP-A NAL header + [NALU size + NALU header + Nalu payload]... + RTP padding`

- 如果是STAP-B的话会多加入一个DON域，另外还有MTAP16、MTAP24，具体不介绍

```
       0               1               2               3
       0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |                          RTP Header                           |
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |STAP-A NAL HDR|         NALU 1 Size           | NALU 1 HDR    |
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |                         NALU 1 Data                           |
      :                                                               :
      +               +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |               | NALU 2 Size                   | NALU 2 HDR    |
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |                         NALU 2 Data                           |
      :                                                               :
      |                               +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |                               :...OPTIONAL RTP padding        |
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
```



### 分片模式

​		一个RTP包只能负载一个NALU的部分，需要使用`FU-A`模式。

​		`FU-A`包：`RTP header + FU indicator + FU header + FU payload + RTP padding`

​		`FU-B`包：`RTP header + FU indicator + FU header + DON + FU payload + RTP padding`

```c
       0               1               2               3
       0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |                          RTP Header                           |
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      | FU indicator  |   FU header   |                               |
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+                               |
      |                                                               |
      |                         FU payload                            |
      |                                                               |
      |                               +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
      |                               :...OPTIONAL RTP padding        |
      +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
```



- `FU indicator`，`1 byte`
  - `F`, `1 bit`，同`NALU F`
  - `NRI`，`1 bit`，同`NALU NRI`
  - `type`需要设置为 `28/29`，指示当前包的分包模式
    - `28`，`FU-A`
    - `29`，`FU-B`
- `FU header`，`1byte`
  - `S`：start 标记位，当该位为 1 时表示 NALU 的第一个分片
  - `E`：end 标记位，当该位为 1 时表示 NALU 的最后一个分片
  - `R`：保留位，接收者可以忽略该位。
  - `Type`：实际完整`NALU `的 `Type `类型（1-23）
- `DON`，`2 byte`
  - FU-B时多2字节的DON（解码顺序号）


>  NALU 分片到多个 RTP 包，不同 RTP 的` FU indicator` 是完全一样的，`FU header` 只有 `S`，`E `位有所区别。



> ​	`7C`开头是分片NALU，后面一般为`85/05/45`
>
> - `7C 85`，转化为65并加入包头
> - `7C 45`，直接去除
> - `7C 05`，直接去除









## parser

[H264Analysis/H264Analysis_02/H264Analysis/nalu.h at master · Gosivn/H264Analysis (github.com)](https://github.com/Gosivn/H264Analysis/blob/master/H264Analysis_02/H264Analysis/nalu.h)

[从零实现一个h264解码器（一）-腾讯云开发者社区-腾讯云 (tencent.com)](https://cloud.tencent.com/developer/article/1960566)

[h264bitstream/h264_sei.h at master · aizvorski/h264bitstream (github.com)](https://github.com/aizvorski/h264bitstream/blob/master/h264_sei.h)

[SimpleH264Analyzer/SimpleH264Analyzer/SimpleH264Analyzer/Macroblock.cpp at master · yinwenjie/SimpleH264Analyzer (github.com)](https://github.com/yinwenjie/SimpleH264Analyzer/blob/master/SimpleH264Analyzer/SimpleH264Analyzer/Macroblock.cpp)

[最简单的 H.264 视频码流解析程序_h264码流分析程序-CSDN博客](https://blog.csdn.net/ProgramNovice/article/details/137258394)

[simplest_mediadata_test:samples to handling multimedia data - GitCode](https://gitcode.com/leixiaohua1020/simplest_mediadata_test/blob/master/simplest_mediadata_test/simplest_mediadata_h264.cpp)

[视音频数据处理入门：H.264视频码流解析_视频码流分析-CSDN博客](https://blog.csdn.net/leixiaohua1020/article/details/50534369)

[自己动手写 H.264 解码器-ZigZagSin (zzsin.com)](https://www.zzsin.com/catalog/write_avc_decoder.html)