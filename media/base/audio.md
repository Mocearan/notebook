# Audio

---

​		声音是一种由物体振动引发的物理现象，物体的振动使其四周空气的压强产生变化，这种忽强忽弱变化以波的形式向四周传播，当被人耳所接收时，我们就听见了声音。



## 参考

[《详解音频编解码的原理、演进和应用选型等 - 知乎 (zhihu.com) 》](https://zhuanlan.zhihu.com/p/55218899)



## 声音的物理性质

- 音质：声音的质量，经过编码压缩后的音频信号保真度，由音量、音高（音频）和音色组成。

  - 音频的强度，指的是发出物体的振动的幅度。相同频率，振幅越大，声音越大。
  - 音高（音频）:*声音的音调，即音频频率或每秒变化次数。
  - 音色：音频泛音，又称为音品，不同声音表现在波形方面与众不同的特性。

- 声波：声音以波的形式振动（震动）传播，可以用波的分析手法来分析声音

  - 频率：音阶， 频率越高，波长越短，穿透性越差，衰减越快。

    > 人耳范围`20Hz~20KHz`，对`3kHz~4kH`z最为敏感


  - 振幅：响度，能量大小的反映，常用分贝描述。

    > 在声压级较高时，听觉的频率特性会变得较为均匀。频率范围较宽的音乐，其声压以80～90dB为最佳，超过90dB将会损害人耳（105dB为人耳极限）


  - 波形：音色，不同音色是因为不同介质产生的波形不同。声波的函数表示。


  - 介质

    - 发声介质
    - 传播介质

    > 吸音主要是解决声音反射而产生的嘈杂感，录音棚
    >
    > 隔音主要是解决声音的透射而降低主体空间内的吵闹感，KTV

- 回声

  ​	声音在传播过程中遇到障碍物会反弹回来，再次被我们听到。

  ​	两种声音传到我们的耳朵里的时差小于80毫秒，我们就无法区分开这两种声音。

- 共鸣

  ​	声波能量引起另一物体振动，从而以同样的频率产生声音。

- 声音的存储：

  - 机械录音（以留声机、机械唱片为代表）
  - 光学录音（以电影胶片为代表）
  - 磁性录音（以磁带录音为代表）等**模拟**录音方式
  - 直到二十世纪七、八十年代逐渐开始进入了**数字**录音（数字音频）的时代



## 数字音频基本概念

- 采样：某时刻声音的采集样本

  - 样本需要经过数字住哪换才能存储为样本数据

  - 因为采样是离散的，所以虽然声音是连续变化的，但计算机中的声音表示是均匀离散的样本

- 采样频率：每秒钟采样的点的个数

  - 根据[奈奎斯特定理](https://baike.baidu.com/item/采样定理/8599843?fromtitle=奈奎斯特采样定理&fromid=11173466&fr=aladdin)：当采样频率大于信号中最高频率的2倍时，采样后的数字信号能够完整保留原始信号的信息。

  - 22000 (22k) Hz      无线广播

  - 44100 (44.1k)Hz     CD音质
  - 48000 (48k) Hz       数字电视，DVD
  - 96000 (96k) Hz       蓝光，高清DVD
  - 192000(192k) Hz    蓝光，高清DVD

- 采样精度（采样深度，位深）：每个样本的存储大小，常用的大小为8bit， 16bit，24bit

  - 一般为`16bit`，常用的也有`8bit / 24bit`
  - 位深越大，声色的还原度越高

- 通道数：声音在录制或播放时，在**不同空间位置采集**或回放的相互独立音频信号。

  - **声道数指在录音时的音源数量**或者在播放时的扬声器数量不同声道数对应不同声道布局。
  - 每个通道单独进行采样
  - 多个声道的采样数据一般按声道连续间隔排列
    - `123 123 123 123`
  - 常见的声道布局有单声道(mono)、立体声道(stereo)、四声环绕、5.1声道
    - 左前 - Front Left 、右前 - Front Right、中置 - Center、LFE - Low Frequency Effect、左侧 - Side Left、 右侧 - Side Right、左后 - Back Left、右后 - Back Right
    - 单声道：只有一个声道，优点数据量小，amr_nb和amr_wb默认为单声道，缺点是缺乏对声音位置定位。
    - 立体声道：一般为两个声道，由左声道、右声道组成，改善对声音位置定位的状况。
    - 四声环绕：由前左、前右、后左、后右组成，形成立体环绕。
      - 4.1声道是在四声环绕基础上，增加一个低音。
    - 5.1声道：在4.1基础上，增加一个中场声道，杜比AC3就是采用5.1声道，也就是影院宣传的杜比音效。

  ![img](https://raw.githubusercontent.com/Mocearan/picgo-server/main/be242605450822d66c6cbf6a85b90923.png)

- 音频帧：一次编码会将若干个采样打包在一起，作为一个编码单元

  > 音视频文件播放时，为了音视频同步，程序需要根据每帧的播放时间戳进行有序播放。但是每个音频采样的时间间隔太小了，所以将一组采样打包为音频帧，匹配每帧图像的显示长度。
  >
  > ![img](https://pics4.baidu.com/feed/5882b2b7d0a20cf475b97840cd5ef43dadaf99e3.png@f_auto?token=15695ec22005ceadd75ec77b87ddf719)

  - MP3通常是1152个采样点作为一个编码单元
  - AAC通常是1024个采样点作为一个编码单元。

- 帧长：帧时长，每帧播放持续的时间。每帧持续时间(秒) = 每帧采样点数 / 采样频率（HZ）。

  - 帧长也可以指压缩后每帧的数据长度。
  - 帧长 = 每帧采样数 / 采样频率 （ 48K，1152个采样点，帧长 = 1152 / 48000 = 0.024s）

  > MP3 48k，1152个采样点，每帧则为1152/48000=0.024 秒=24毫秒。

- PTS：播放时间戳

- 比特率：每秒采集的bit数，单位为：bps（Bit Per Second）

  - 间接衡量声音质量的一个标准。
  - 没有压缩的音频数据的比特率 = 采样频率 * 采样精度 * 通道数。
    - `44100 * 16 * 2 = 1411200 bit/s`
  - PCM数据比特率 = 采样大小 x 采样率 x 声道数

- 码率： 压缩后的音频数据的比特率

  - 码率越大，压缩效率越低，音质越好，压缩后数据越大。 
  - 码率 = 音频文件大小/时长。
  - 常见的码率：
    - 96kbps：FM质量。
    - 128-160kbps：一般质量音频。
    - 192kbps： CD质量。
    - 256-320Kbps：高质量音频。

- 采样格式

  - 打包模式和平面模式（交错模式与非交错模式）
    - 打包模式（交错模式）：指数据以连续帧的方式存放。
      - 首先记录帧1的左声道样本和右声道样本，再开始帧2的记录，以此类推
      - `L1R1 L2R2 L3R3 ...`

    - 平面模式（非交错模式）：指先记录一个周期内所有帧的左声道样本，再记录右声道样本
      - `L1L2L3... R1R2R3...`

  - 大端存储和小端存储
  - 有符号和无符号
  - 整型与浮点型
  - 存储精度：`8 / 16 / 32 / 64`




## 声音的采集

### 模数转换

​		将物理的声音转为电模拟信号

- 声波压缩麦克风中的碳膜发生振动
- 碳膜振动接触下方电极
- 接触时长和频率域声波的振幅和频率有关
- 完成声波信号到电信号的转换
- 再经过放大电路处理，可以进行采样量化处理



### 采样量化

​		在幅度轴上对信号进行数字化，得到音频原始数据。按照以下指标进行数字采样：

- 采样大小（位深）
  
- 采样率
- 声道数
- 格式

  ```c
  enum AVSampleFormat {
      AV_SAMPLE_FMT_NONE = -1,
      AV_SAMPLE_FMT_U8,          // unsigned 8 bits
      AV_SAMPLE_FMT_S16,         // signed 16 bits
      AV_SAMPLE_FMT_S32,         // signed 32 bits
      AV_SAMPLE_FMT_FLT,         // float
      AV_SAMPLE_FMT_DBL,         // double
   
      AV_SAMPLE_FMT_U8P,         // unsigned 8 bits, planar
      AV_SAMPLE_FMT_S16P,        // signed 16 bits, planar
      AV_SAMPLE_FMT_S32P,        // signed 32 bits, planar
      AV_SAMPLE_FMT_FLTP,        // float, planar
      AV_SAMPLE_FMT_DBLP,        // double, planar
      AV_SAMPLE_FMT_S64,         // signed 64 bits
      AV_SAMPLE_FMT_S64P,        // signed 64 bits, planar
   
      AV_SAMPLE_FMT_NB           // Number of sample formats
  };
  ```

  

### 数字音频编制

​		按照一定的格式记录采样和量化后的数字数据，比如顺序存储或压缩存储。编制后的二进制数据即表示从模拟信号得到数字信号的音频原始数据。

> ​		通常所说的音频的裸数据格式就是脉冲编码调制（Pulse Code Modulation, PCM）数据。

​		

#### PCM

​		脉冲编码调制，是纯粹的数字音频数据，PCM是一种线性采样方法，它将音频信号在时间上均匀地分成小片段，并在每个时间片段内对信号的振幅进行采样。

​		经过`AudioRecord`和`MediaRecorder`采集的数据就是PCM数据，只是模拟到数字的转换，没有压缩和封装。常用文件拓展为`.pcm / .raw`

​		PCM数据一般需要以下几个概念：

1. **采样率（Sample Rate）**：采样率是指每秒采样的样本数。它以赫兹（Hz）为单位表示，常见的采样率包括44.1 kHz（用于CD音频）、48 kHz（用于DVD和数字电视）、96 kHz（用于高分辨率音频）等。更高的采样率可以捕获更多音频细节，但也需要更多的存储空间和处理能力。
2. **量化位深度（Bit Depth）**：量化位深度表示每个样本的振幅级别数。常见的位深度包括16位、24位和32位。较高的位深度能够提供更大的动态范围，使音频质量更高，但也需要更多的存储空间。
3. **声道数（Channels）**：声道数表示音频信号中独立的音轨数。单声道通常用于单声源音频，如语音记录，而立体声和多声道音频用于音乐和电影等应用。常见的声道配置包括单声道、立体声（2声道）、5.1声道、7.1声道等。
4. 样本（Sample）：样本是在特定时间点上对模拟音频信号的振幅进行的测量。采样率决定了样本的数量。
5. 位宽（Bit Width）：位宽是每个样本的位数，通常与量化位深度相同。位宽决定了每个样本的数字表示精度。

​		linux上可以使用`aplay`处理和播放PCM音频，`aplay` 是 ALSA (Advanced [Linux](https://link.csdn.net/?target=https%3A%2F%2Fgitcode.com%2Fopenharmony%2Fkernel_linux_config%2Foverview%3Flogin%3Dfrom_csdn) Sound Architecture) 的一部分，可以用于播放PCM格式的音频文件。

> ### ALSA（Advanced [Linux](https://link.csdn.net/?target=https%3A%2F%2Fgitcode.com%2Fopenharmony%2Fkernel_linux_config%2Foverview%3Flogin%3Dfrom_csdn) Sound Architecture）：
>
> [Linux](https://link.csdn.net/?target=https%3A%2F%2Fgitcode.com%2Fopenharmony%2Fkernel_linux_config%2Foverview%3Flogin%3Dfrom_csdn)[操作系统](https://link.csdn.net/?target=https%3A%2F%2Fgitcode.com%2Fopenharmony%2Fkernel_linux_config%2Foverview%3Flogin%3Dfrom_csdn)上的音频架构，用于处理音频输入和输出。它是[Linux](https://link.csdn.net/?target=https%3A%2F%2Fgitcode.com%2Fopenharmony%2Fkernel_linux_config%2Foverview%3Flogin%3Dfrom_csdn)内核的一部分，并提供了一种标准的音频接口，用于访问计算机的音频硬件和驱动程序。ALSA的主要目标是提供高质量的音频支持，并在[Linux](https://link.csdn.net/?target=https%3A%2F%2Fgitcode.com%2Fopenharmony%2Fkernel_linux_config%2Foverview%3Flogin%3Dfrom_csdn)系统中实现低延迟和高性能的音频处理。
>
> 以下是ALSA的一些主要特点和组成部分：
>
> 1. **驱动程序**：ALSA包括一系列驱动程序，用于支持各种音频硬件设备，如声卡、USB音频接口等。这些驱动程序允许[Linux](https://link.csdn.net/?target=https%3A%2F%2Fgitcode.com%2Fopenharmony%2Fkernel_linux_config%2Foverview%3Flogin%3Dfrom_csdn)系统与音频设备进行通信。
> 2. **音频库**：ALSA提供了音频应用程序开发所需的库，包括C库（libasound）和Python绑定。这些库允许开发人员创建和管理音频应用程序，包括音频播放器、录音应用、音频编辑工具等。
> 3. **用户空间工具**：ALSA附带了一些实用的用户空间工具，用于配置和管理音频设置，例如`alsamixer`和`aplay`。
> 4. **插件架构**：ALSA具有插件架构，允许开发人员创建和使用插件来执行各种音频处理任务，如混音、音频格式转换等。这增强了ALSA的灵活性和可扩展性。
> 5. **低延迟性能**：ALSA旨在提供低延迟和高性能的音频处理，这对于音频专业人士、音频编程和音乐制作应用非常重要。
> 6. **跨平台支持**：虽然ALSA最初是为[Linux](https://link.csdn.net/?target=https%3A%2F%2Fgitcode.com%2Fopenharmony%2Fkernel_linux_config%2Foverview%3Flogin%3Dfrom_csdn)设计的，但它也被移植到其他Unix-like[操作系统](https://link.csdn.net/?target=https%3A%2F%2Fgitcode.com%2Fopenharmony%2Fkernel_linux_config%2Foverview%3Flogin%3Dfrom_csdn)，因此可以在一些BSD系统上找到。
> 7. **支持多声道音频**：ALSA支持多声道音频处理，使其适用于多媒体应用和音频制作工作流程。

[adpcm编解码原理及其代码实现-CSDN博客](https://blog.csdn.net/littlezls/article/details/83501580)



## 音频编码

​		 将音频采样数据（**PCM** ）压缩成音频码流，从而降低音频的数据量。

- 有损压缩：利用人耳遮蔽效应，消除采样数据中的冗余信息

  - 消除冗余信息：人耳不能感知的冗余信号，包括人耳听觉范围之外的音频信号以及被掩蔽掉的音频信号等。

  - 解压后的数据不能完全复原，压缩比越小，丢失的信息越多，信号还原后的失真就会越大。

- 无损压缩

  ​	解压后的数据可以完全复原，单纯进行数据的压缩。

  - 熵编码
    - 哈夫曼编码
    - 算术编码
    - 香农编码


```text
音频编码过程

---> 时域转频域变换-----> 量化编码 -----> 比特流格式化------> 比特流
 |-> 心理声学模型----------↑       辅助数据---↑
```



### 人耳掩蔽效应

​		人耳掩蔽效应：数字音频压缩编码采取去除声音信号中冗余成分的方法来实现。

> ​		所谓冗余成分指的是音频中不能被人耳感知到的信号，它们对确定声音的音色，音调等信息没有任何的帮助。
>
> ​		冗余信号包含人耳听觉范围外的音频信号以及被掩蔽掉的音频信号等。

- 人耳所能察觉的声音信号的频率范围为20Hz～20KHz，除此之外的其它频率人耳无法察觉，都可视为冗余信号。
- 此外，根据人耳听觉的生理和心理声学现象，当一个强音信号与一个弱音信号同时存在时，弱音信号将被强音信号所掩蔽而听不见，这样弱音信号就可以视为冗余信号而不用传送。

​		这就是人耳听觉的掩蔽效应，主要表现在频谱掩蔽效应和时域掩蔽效应。

- 频域遮蔽：多个频率叠加的复合声音中，通过傅里叶变换等手段，去除掉被主频率遮蔽掉的声源信息。

  > 一个频率的声音能量小于某个阈值后，人耳就会听不到。当有另外能量较大的声音出现时， 该声音频率附近的阈值会提高很多。

  ![img](https://raw.githubusercontent.com/Mocearan/picgo-server/main/36d5bfe6593b870a11830ab4f23b4a27.png)

- 时域遮蔽：主频率前后一定时间范围内，声音强度呈梯度下降的被主频率声源所屏蔽。

  > 当强音信号和弱音信号同时出现时，还存在时域掩蔽效应。即两者发生时间很接近的时候，也会发生掩蔽效应。
  > 时域掩蔽效应可以分成三种：前掩蔽，同时掩蔽，后掩蔽。前掩蔽是指人耳在听到强信号之前的短暂时间内，已经存在的弱信号会被掩蔽而听不到。同时掩蔽是指当强信号与弱信号同时存在时，弱信号会被强信号所掩蔽而听不到。后掩蔽是指当强信号消失后，需经过较长的一段时间才能重新听见弱信号，称为后掩蔽。这些被掩蔽的弱信号即可视为冗余信号。
  
  ![img](https://raw.githubusercontent.com/Mocearan/picgo-server/main/ed045450cae2097feaead33ce78fe374.png)













### MP3

​		MP3（ **MPEG-1 or MPEG-2 Audio Layer III**）是一种有损的音频编码方式，旨在在尽量减少文件大小的同时保持较好的音质。

​		其中一种实现为`LAME`编码，使用`LAME`编码的中高码率的MP3文件，听感上非常接近源`WAV`文件，不同的应用场景下，应该调整合适的参数以达到最好的效果。

> 将原始音频信号进行数字化并进行压缩。它通过去除人耳不易察觉的音频信息来降低文件大小，从而实现音频数据的高效存储。

- 音质在128Kbit/s以上表现还不错
- 压缩比较高，大量软件和硬件都支持，兼容性好
- 使用与高比特率下对兼容性有要求的音乐欣赏





### AAC

​		**AAC**，英文全称 **Advanced Audio Coding**，是由 **Fraunhofer IIS**、杜比实验室、**AT&T**、**Sony** 等公司共同开发。是新一代的音频有损压缩技术，MP3的继任者。

​		分为ADIF格式和ADTS格式。

- ADIF格式：Audio DataInterchange Format
  - 特征是可以确定的找到这个音频数据的开始，只能从头开始解码，不能在音频数据流中间开始
  - 常用在磁盘文件中。
- ADTS格式：Audio Data Transport Stream
  - 特征是每一帧都有一个同步字，所以可以再音频流的任何位置开始解码，类似于数据流格式。

> http://www.p23.nl/projects/aac-header/







### Ogg编码

​		Ogg是一种非常有潜力的编码，在各种码率下都有比较优秀的表现，尤其是在中低码率场景下，音质好，且免费。

​		Ogg有着非常出色的算法，可以用更小的码率达到更好音质，128Kbit/s的Ogg比192Kbit/s甚至更高码率的MP3还要出色。但目前没有媒体服务软件支持，因此基于Ogg的数字广播还无法实现。

- 可以用比MP3更小的码率实现比MP3更好的音质，高中低码率下均有良好的表现，兼容性不够好，流媒体特性不支持。.
- 适用场合：语音聊天的音频消息场景



### 各个音频编码对比

![image-20240225192246401](https://raw.githubusercontent.com/Mocearan/picgo-server/main/image-20240225192246401.png)

![image-20240225192432266](https://raw.githubusercontent.com/Mocearan/picgo-server/main/image-20240225192432266.png)



## 音频封装格式

[音频编码格式介绍_ram音频格式-CSDN博客](https://blog.csdn.net/littlezls/article/details/135862140)

### WAV

​		`WAV`是一种封装格式。

​		它能够支持多种音频编码类型，但最常用的情况下是在未压缩的`PCM`数据格式的前面加上44字节，分别用来描述PCM的采样率、声道数、数据格式等信息。

- 音质好
- 大量软件支持
- 适用于多媒体开发中的中间文件、保存音乐和音效素材
- 存储的声音质量非常高，但文件尺寸较大。

### MP3

​		虽然MP3是编码格式，但通常文件扩展名为`.mp3`的文件的确也是一种**音频封装格式**。

​		因为它们不仅包含编码后的音频流，还可能包含一些元数据（如艺术家、歌曲名、专辑信息等）。

​		在实际应用中，MP3文件同时扮演编码和封装的角色。



### AAC



## 音频重采样

​		将音频三元组：位深、采样率和通道数，当前的值转换成另外一组值。

- 设备采集的音频数据与编码器要求的输入数据不一致。
- 样神奇要求的音频数据与要播放的音频数据不一致。
- 更方便运算
  - 回音消除中，将多声道变为单声道进行计算


​		是否需要重采样：

- 了解音频设备的参数
- 查看ffmpeg源码中对各平台不同编码器的实现

​		重采样的步骤：

- 创建采样上下文
- 设置参数
- 初始化重采样
- 进行重采样



## 音频处理

音频分析是指对音频信号进行测量、分析和评估，以获取其特性或质量信息。常见的音频分析技术包括频谱分析、动态分析、清晰度分析等。



## 音频合成

音频合成是指通过声音合成技术，创造新的声音或音乐。常见的音频合成技术包括采样合成、波形合成、算法合成等。



## 其他音频技术

​		音频基础知识还包括音频处理技术，如音频采集、音频数据传输、音频-视频同步、音频效果与编辑、语音编码/解码、文-语转换、音乐合成、语音增强、噪声抑制，回声消除、麦克风阵列、解混响、声源定位、盲源分离、语音识别与理解、合成等。

[语音信号处理 - 深蓝学院 - 专注人工智能与自动驾驶的学习平台 (shenlanxueyuan.com)](https://www.shenlanxueyuan.com/course/728)

[基于RNN的音频降噪算法 (附完整C代码)_音频降噪算法 附完整c代码-CSDN博客](https://blog.csdn.net/littlezls/article/details/111616843)

[音频降噪算法 附完整C代码-CSDN博客](https://blog.csdn.net/littlezls/article/details/111615545)
