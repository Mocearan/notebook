# Audio

---

​		声音由物体振动引发的声波。振动使介质压强产生变化，以波的形式向四周传播。

​		当被人耳或其他声波接收设备接收时，通过相应的处理就可以听到或记录声音。



## 参考

[《详解音频编解码的原理、演进和应用选型等 - 知乎 (zhihu.com) 》](https://zhuanlan.zhihu.com/p/55218899)



## 声音的物理性质

### 声音三要素

- 音频的强度，指的是发出物体的振动的幅度。

  - 响度，能量大小的反映，常用分贝描述。
  - 相同频率，振幅越大，声音越大。

  > 在声压级较高时，听觉的频率特性会变得较为均匀。
  >
  > 频率范围较宽的音乐，其声压以80～90dB为最佳，超过90dB将会损害人耳（105dB为人耳极限）

- 音色：音频泛音，又称为音品，不同声音表现在波形方面与众不同的特性。

  - 不同音色是因为不同介质产生的波形不同。
  - 声波的函数表示。

- 音高（音频）: 声音的音调，即音频频率或每秒变化次数

  - 一种振动的波峰波谷的变化周期



### 其他性质

- 音质：声音的质量，经过编码压缩后的音频信号保真度，由音量、音高（音频）和音色组成。

- 声波：声音以波的形式振动（震动）传播，可以用波的分析手法来分析声音

  - 频率：音阶， 频率越高，波长越短，穿透性越差，衰减越快。

    > 人耳范围`20Hz~20KHz`，对`3kHz~4kH`z最为敏感
    
  - 可以用介质压强随时间的变化来记录波形图

  - 一般声音是由多种振动进行叠加的复杂波形

    - 波形可以由多个频率、不同振幅和相位的简单正弦波复合叠加得到的
    - 对于复合波形，通过进行傅里叶变换，可以将其拆解还原到每个频率上单一的正弦波结构
      - 这样在单一结构的时间-振幅波形图上，形成一个三维的立体模型，第三个维度是频率
      - 时域观测是通过时间-振幅波形观察一组波形
      - 频域观测是通过频率-振幅波形观察一组波形

    ![图片](https://mmbiz.qpic.cn/mmbiz_jpg/gUnqKPeSuejpah0puRls8pDUcdVTJ8TBW2guPZibc5bibnS6qjmiar5Owy433ZgJlbE4FCulRwGjJhu7WoU1uOybw/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

  - 分析复杂的叠加波形图，通过频谱图，在时域和频域两方面进行分析

    - 频谱图是在三维立体波形上进行切片，以横坐标为频率，纵坐标为幅值的图形。
    - 它表示的是一个静态的时间点上，各频率正弦波的幅值大小的分布状况。

    

    ![图片](https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSuejpah0puRls8pDUcdVTJ8TBWsAPSBM5dukSLFMvu53KoX0UNicrA0UBiciaWpUGpbIeN73He6J1zjh5w/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

    > 这里的频谱图是一个三维图，其中横轴是时间，纵轴是频率（这里用了音调表示，比如 A5(880) 对应的频率是 880Hz），颜色亮度表示响度。所以频谱图相对于波形图，是包含有更多信息的，唯一的缺点就是无法表示整体音量的大小，所以一般和波形配合使用来辨别声音特征。


  - 介质

    
    - 发声介质
    
    
    - 传播介质
    

> 吸音主要是解决声音反射而产生的嘈杂感，录音棚
>
> 隔音主要是解决声音的透射而降低主体空间内的吵闹感，KTV


- 回声

  ​	声音在传播过程中遇到障碍物会反弹回来，再次被我们听到。

  ​	两种声音传到我们的耳朵里的时差小于80毫秒，我们就无法区分开这两种声音。

- 共鸣

  ​	声波能量引起另一物体振动，从而以同样的频率产生声音。

- 声音的存储：

  - 机械录音（以留声机、机械唱片为代表）
  - 光学录音（以电影胶片为代表）
  - 磁性录音（以磁带录音为代表）等**模拟**录音方式
  - 直到二十世纪七、八十年代逐渐开始进入了**数字**录音（数字音频）的时代

### 声音的数学描述

#### 响度的数学描述

​		**响度**是反映人耳感受到的声音强弱的**主观心理量**，根据它可以把声音排成由轻到响的序列。

- **声能**是声音在介质中传播时，使媒介附加的能量。

  - 声波是质点偏离平衡位置的振动，因此声能定义为质点振动动能和质点偏离平衡位置所具有的势能的总和

- **声强**是单位时间内通过垂直于声波传播方向的单位面积的平均声能

  - 人耳允许的声强范围为 `0.000000000001~1 W/m²`，这个范围太大。

  - 此外，心理物理学的研究表明，人对声音强弱的感觉并不是与声强成正比，而是与其对数成正比的，所以我们引入『声强级』来表示声强。

    - **声强级（Sound Intensity Level，SIL\**）\****，是以 10-12 W/m² 为参考值，任一声强与其比值的对数乘以 10 记为声强级，单位是『分贝(dB)』。

      ​		$$L_I = 10\lg\frac{I}{I_0}$$

      - $L_I$，表示声强级（dB）
      - $I$ ，表示声强（W/m²）
      - $I_0$ ，表示基准声强的常量，值为  W/m²

- **声压**是指声波通过媒质时，由振动所产生的压强改变量，单位是『牛顿每平方米(N/m²)』或『帕斯卡(Pa)』，用 P 表示声压

  - **由于人耳表现为压力敏感组织，又因为压力或压强具有相对容易进行实地测量的特点，所以目前实际中更多是使用声压来代表声波的振幅表现。**

  - 声音在空气中传播时，物体的振动带动周围空气的振动，形成了疏密相间的波动，所以压力变化增量是正负交替的。

  - 通常取声压的均方根值，称为**有效声压**。

  - 人对声音的强弱的感觉是与声压的对数成正比，所以我们引入『声压级』表示声压。

    - **声压级（Sound Pressure Level，SPL）**，是以 2×10-5 N/m² 为参考值，任一声压与其比值的对数乘以 20 记为声压级，单位也是『分贝(dB)』。

      ​		$$L-P = 20\lg\frac{P}{P_0}$$

      - $L_P$，表示声压级（dB）
      - $P$ ，表示声压（N/m² 或 Pa）
      - $P_0$ ，表示基准声压的常量，值为  $2 \times 10^{-5}$ Pa

  - 声压与声强的关系：在自由声场中，某处的声强与该处声压的平方成正比，与介质密度与声速的乘积成反比。

    ​		$$I = \frac{P^2}{\rho c}$$

    - $P$, 表示有效声压（N/m²）
    - $\rho$，表示介质密度（kg/m³）
    -  $c$，表示介质中的声速（m/s）
      -  $\rho c$ ，体现了介质的特性阻抗，20℃ 的空气为 415N·s/m³

- 把 1000 Hz 纯音的这个声压级规定为该频率纯音的**响度级**。响度级的单位为『方(Phon)』。

  - 人耳对声音的感觉，与声压有关，但也不是只与声压有关，还和频率有关。声压级相同，频率不同的声音，听起来响度也不同。
  - **响度级既考虑了声音的物理效应，又考虑了人耳的听觉生理效应，表示人耳对声音的主观评价。**

- **我们日常所说的分贝指的是声压级。*

#### 音色的数学描述

​		现实中声音的波形绝大多数都不是简单的正弦波，而是一种复杂的波。这种复杂的波形可以分解为一系列的正弦波。

- 这些正弦波中有**基频** f0，它对应声音的**基音**
- 还有与 f0 成整数倍关系的**谐波**：f1、f2、f3、f4 等，它们对应声音的**泛音**
- 它们的振幅有特定的比例。这种特定的比例，赋予每种声音特色，这就是**音色**
  - 如果没有谐波成分，单纯的基频正弦信号是毫无音乐感的
  - 因此，乐器乐音的频率范围包括基频和谐波

> 声音音调的高低是由基音对应的基频决定的。这就是为什么同唱一个音调，不同人的音色截然不同的根本原因：他们只是基频相同，谐波是截然不同的。

#### 音调的数学描述

​		**音调**是人耳对声音高低的主观感受。音调对应的客观评价尺度是声波的『频率』。音调的高低是由振动频率决定的，两者成正相关关系。

​		**频率**的计量我们比较熟悉，单位是『赫兹(Hz)』。那么音调是怎么计量呢？一种计量法是将音调的单位称为『美(mel)』，取频率 1000 Hz、声压级为 40 dB 的纯音的音调作标准，称为 1000 mel。

​		乐音（复音）的音调更复杂些，一般可认为主要由基音的频率来决定。

- 在 500 Hz 以下，音调和频率基本上近乎成线性关系，但是对于中高频则成对数关系
- 两个音符之间若频率相差整数倍，则听起来非常相似。因此，我们将这些音放在同一个『音调集合』中。**两个音符间若相差一倍的频率，则我们称两者之间相差一个八度。**
- 现在的标准调音音调 440 赫兹名为 A4，往上高八度则为 A5，继续向上可无限延伸；至于 A4 往下，则为 A3、A2 等。
- 传统上，由于历史原因，八度的数字标注由 C 音符开始，结束于 B：C、D、E、F、G、A、B（按此顺序则音调循序而上）。

> 有时我们也会在音名旁加上变音记号，如升号和降号。这些符号代表将原音升高或降低半音，在**十二平均律**（现在最广泛使用的调音法）中则是将原频率乘或除以 2(1/12)=1.0594 倍，即升高 n 个半音就将原频率乘 2(n/12) 倍，降低 n 个半音则乘 2(-n/12) 倍。升音符号为 `♯`，降音符号则为 `♭`。它们通常写在音名之后，如 `F♯` 表示升 F，而 `B♭` 表示降 B。其它的变音符号如重升或重降（将原音升高或降低一个全音，即两个半音），在传统乐理中也会用到。在等音音程（enharmonicity）的情况下，我们可以利用变音记号把同一个音调记成不同的音符。举例而言，把 B 升半音成为 `B♯`，其实就与 C 同音。不过，在删去这些异名同音的情况后，完整的半音音阶在原来的七个音上添加了五个音调集合，且任两个相邻的音调集合都相差半音。
>
> ![图片](https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSueiatZnXKgq7a4hqjicvFicn6ich9z8kJ3jibG0Um213R8s1HMmO8stmHswQ3rcInlhggB4C7yH5870FGeg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)
>
> 注意，7 个全音只有 5 个半音。E 和 F 之间，B 和 C 之间是没有半音的。详细来讲，就是一个八度之间有 12 个半音。其中 7 个（CDEFGAB）叫**自然音**，另外 5 个叫**变化音**。自然音之间一般是隔着两个半音（相隔两个半音可以叫距离为一个全音），也有部分自然音之间（E 和 F，B 和 C）只隔一个半音。

![image-20250416140923030](https://raw.githubusercontent.com/Mocearan/picgo-server/main/image-20250416140923030.png)



## 模拟音频

​		对声音进行数字化，首先要使用特定的设备对声音进行采集，比如麦克风就是常见的声音采集设备。

> ​		麦克风里面有一层碳膜，非常薄而且十分敏感。声音是一种纵波，会压缩空气也会压缩这层碳膜，碳膜在受到挤压时也会发出振动，在碳膜的下方就是一个电极，碳膜在振动的时候会接触电极，接触时间的长短和频率与声波的振动幅度和频率有关，这样就完成了声音信号到电信号的转换。之后再经过放大电路处理，就可以实施后面的采样、量化处理了。
>
> ​		这个过程是将声音信号转化为连续变化的**模拟电信号**。后续提到的放大电路处理仍然是在模拟信号阶段，而采样和量化（将模拟信号转换为数字信号的过程）是在之后进行的。

​		为了在数字媒体内表示这些波形，需要对波形进行**采样**，其采样率需要满足可以表示的声音的最高频率；同时还需要存储足够的**位深**，以表示声音样本中波形的适当振幅。

- 声音处理设备重建频率的能力称为其**频率响应**
- 创造适当响度和柔度的能力称为其**动态范围**
- 这些术语通常统称为声音设备的**保真度**。最简单的编码方式可以利用这两个基本元素重建声音，同时还能够高效地存储和传输数据。

## 数字音频

​		声音的数字化过程是将模拟信号（连续时间信号）转化为数字信号（离散时间信号）的过程，也称为模数转换。包括 3 个步骤：

- **采样（Sampling）**：以固定时间间隔（采样率）对连续的模拟信号进行取样，获取离散的信号值。
  - 样本需要经过数字转换才能存储为样本数据
  - 因为采样是离散的，所以虽然声音是连续变化的，但计算机中的声音表示是均匀离散的样本
  - 采样率需满足奈奎斯特-香农采样定理（采样频率至少为信号最高频率的2倍），以避免信息丢失
  - **采样率**：每秒采样的次数（如44.1kHz表示每秒采样44100次）。
- **量化（Quantization）**：将采样的连续幅值离散化为有限的数字级别（如用8位或16位表示），每个样本被映射到一个最接近的量化级别。
  - **量化位深**：表示每个样本的精度（如16位表示每个样本有2^16个量化级别）。
- **编码（Encoding）**：将量化后的值转换为二进制数字信号，生成可供数字系统处理的数字数据。
  - **信噪比**：衡量转换过程中噪声对信号的影响。
  - 这里的编码是指量化后的模拟信号样本转换为二进制数字格式的步骤，目的是将量化后的离散数据映射为数字系统可识别的二进制代码，以便存储。**这和音频压缩编码的编码不是一回事**



<img src="https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSuegcib3ev1nZLjb5aHzJpvb24ZwUmxpjgQcbKPhOa6HYgFSUh4ZtpkSFlVYGY7HqMllqLfICp01NXicA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom: 33%;" />

​		经过数字化处理后的数字音频包含如下三要素：

- **采样率**：每秒钟采样的点的个数

  - 根据[奈奎斯特定理](https://baike.baidu.com/item/采样定理/8599843?fromtitle=奈奎斯特采样定理&fromid=11173466&fr=aladdin)：当采样频率大于信号中最高频率的2倍时，采样后的数字信号能够完整保留原始信号的信息

    > 如果一个信号是带限的（即它的傅立叶变换在某一有限频带范围以外均为零），并且它的样本取得足够密（相对于信号中的最高频率而言），那么这些样本值就能唯一地用来表征这一信号，并且能从这些样本中把信号完全恢复出来。为了不失真地恢复模拟信号，采样频率应该不小于模拟信号频谱中最高频率的 2 倍。一般实际应用中保证采样频率为信号最高频率的 2.56～4 倍。

  - 8,000 Hz：电话所用采样率，对于人的说话已经足够；

  - 11,025 Hz：AM 调幅广播所用采样率；

  - 22,050 Hz 和 24,000 Hz：FM调频广播所用采样率；

  - 32,000 Hz：miniDV 数码视频 camcorder、DAT（LP mode）所用采样率；

  - 44100 (44.1k)Hz     CD音质

    > 为什么具体是 44100 这个数字，这个是历史原因：最早的数字录音由一台录像机加上一部 PCM 编码器制作的，由于当时使用的是 PAL 录像制式（帕制，与之对应的有 NTSC），场频 50 Hz，可用扫描线数 294 条，一条视频扫描线的磁迹中记录 3 个音频数据块，把它们相乘，就得到了 44100 这个奇葩数字。
    >
    > 人类听觉范围是 20～20k Hz 内的音频，那么数字音频的采样率需要在 40k Hz 以上。

  - 47,250 Hz：商用 PCM 录音机所用采样率；

  - 48000 (48k) Hz       数字电视，DVD

  - 50,000 Hz：商用数字录音机所用采样率；

  - 96000 (96k) Hz       蓝光，高清DVD

  - 192000(192k) Hz    蓝光，高清DVD

- **量化位深**（采样精度，采样深度，位深）：每个样本的存储大小，常用的大小为8bit， 16bit，24bit

  - 一般为`16bit`，常用的也有`8bit / 24bit`
    - CD 音乐音频使用 16 bit 的位深，DVD 音频使用 24 bit 的位深，而大多数电话设备使用 8 bit 的位深。
    - 为了避免运算中声音信号精度的丢失，目前业界高端音频处理系统里都是用 32 bit float 采样来进行运算的，而输出的时候转化为 16 bit。
  - 位深越大，声色的还原度越高
  - 位深体现的是能表示的值的范围，比如 16 bit 能表示的最大值是 216 - 1 = 65535，那么取其最大值就能计算它能表示的最大声压级：`最大声压级 = 20 × lg(65535) = 96.33`。所以 16 bit 的位深可以最大表示 96 分贝。
  - $动态范围=20\times\lg(2^{位深})$

- **声道数**(通道数)：声音录制时的音源数量或回放时相应的扬声器数量。

  - 声道是指声音在录制或播放时在不同空间位置采集或回放的相互独立的音频信号
  - 每个通道单独进行采样，多个声道的采样数据一般按声道连续间隔排列
    - `123 123 123 123`
  - 不同声道数对应不同声道布局。
    - 常见的声道布局有单声道(mono)、立体声道(stereo)、四声环绕、5.1声道
    - 单声道：只有一个声道，优点数据量小，amr_nb和amr_wb默认为单声道，缺点是缺乏对声音位置定位。
    - 立体声道：一般为两个声道，由左声道、右声道组成，改善对声音位置定位的状况。
    - 四声环绕：由前左、前右、后左、后右组成，形成立体环绕。
      - 4.1声道是在四声环绕基础上，增加一个低音。
    - 5.1声道：在4.1基础上，增加一个中场声道，杜比AC3就是采用5.1声道，也就是影院宣传的杜比音效。
    - 7.1 声道：在 5.1 声道的基础上，把左右的环绕声道拆分为左右环绕声道以及左右后置声道。主要应用于蓝光以及现代的电影院。

![img](https://raw.githubusercontent.com/Mocearan/picgo-server/main/be242605450822d66c6cbf6a85b90923.png)

> 左前 - Front Left 、右前 - Front Right、中置 - Center、LFE - Low Frequency Effect、左侧 - Side Left、 右侧 - Side Right、左后 - Back Left、右后 - Back Right

- 音频帧：一次编码会将若干个采样打包在一起，作为一个编码单元

  > 音视频文件播放时，为了音视频同步，程序需要根据每帧的播放时间戳进行有序播放。但是每个音频采样的时间间隔太小了，所以将一组采样打包为音频帧，匹配每帧图像的显示长度。
  >
  > ![img](https://pics4.baidu.com/feed/5882b2b7d0a20cf475b97840cd5ef43dadaf99e3.png@f_auto?token=15695ec22005ceadd75ec77b87ddf719)

  - MP3通常是1152个采样点作为一个编码单元
  - AAC通常是1024个采样点作为一个编码单元。

- 帧长：帧时长，每帧播放持续的时间。每帧持续时间(秒) = 每帧采样点数 / 采样频率（HZ）。

  - 帧长也可以指压缩后每帧的数据长度。
  - 帧长 = 每帧采样数 / 采样频率 （ 48K，1152个采样点，帧长 = 1152 / 48000 = 0.024s）

  > MP3 48k，1152个采样点，每帧则为1152/48000=0.024 秒=24毫秒。

- PTS：播放时间戳

- 比特率：每秒采集的bit数，单位为：bps（Bit Per Second）

  - 间接衡量声音质量的一个标准。
  - 没有压缩的音频数据的比特率 = 采样频率 * 采样精度 * 通道数。
    - `44100 * 16 * 2 = 1411200 bit/s`
  - PCM数据比特率 = 采样大小 x 采样率 x 声道数

- 码率： 压缩后的音频数据的比特率

  - 码率越大，压缩效率越低，音质越好，压缩后数据越大。 
  - 码率 = 音频文件大小/时长。
  - 常见的码率：
    - 96kbps：FM质量。
    - 128-160kbps：一般质量音频。
    - 192kbps： CD质量。
    - 256-320Kbps：高质量音频。

### PCM

​		脉冲编码调制，是经过采样量化编码的，纯粹的数字音频数据。由于 PCM 编码是无损编码，且广泛应用，所以我们通常可以认为音频的裸数据格式就是 PCM 的

​		PCM是一种线性采样方法，得到 PCM 数据的主要过程是将话音等模拟信号每隔一定时间进行取样，使其离散化，同时将抽样值按分层单位四舍五入取整量化，同时将抽样值按一组二进制码来表示抽样脉冲的幅值。也就是我们在上文中讲到的采样、量化、编码过程。

> 通常所说的音频的裸数据格式就是脉冲编码调制（Pulse Code Modulation, PCM）数据。

​		经过`AudioRecord`和`MediaRecorder`采集的数据就是PCM数据，只是模拟到数字的转换，没有压缩和封装。常用文件拓展为`.pcm / .raw`。

​		在计算机应用中，PCM 是能达到音频最高保真水平的格式，它被广泛用于素材保存及音乐欣赏，PCM 也因此被称为无损编码格式。但这并不意味着 PCM 就能够确保信号绝对保真，它只能做到最大程度的无限接近原始声音。要计算一个 PCM 音频流的码率需要数字音频的三要素信息即可：`码率 = 采样率 × 量化位深 × 声道数`。

​		在处理 PCM 数据时，对于音频不同声道的数据，有两种不同的存储格式（采样格式）：

- 打包模式（交错模式）：指数据以连续帧的方式存放。
  - 首先记录帧1的左声道样本和右声道样本，再开始帧2的记录，以此类推
  - `L1R1 L2R2 L3R3 ...`

- 平面模式（非交错模式）：指先记录一个周期内所有帧的左声道样本，再记录右声道样本
  - `L1L2L3... R1R2R3...`

![图片](https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSuejicmj3BxAiajFBhmTL9mtLuaSrksn2biaV2g9jOarZyCOH9Zp8YEB9w4Py8cQ0XtHiaIibvJF1JgrADlA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

<img src="https://mmbiz.qpic.cn/mmbiz_jpg/gUnqKPeSuejicmj3BxAiajFBhmTL9mtLuaiboCv5omJibFFNlveMibOSHG4TSYH0t5zxcZ3AeIKEHlS9icXZP4yVd8bQ/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom: 80%;" />

> 还需要注意：
>
> - 大端存储和小端存储
> - 有符号和无符号
> - 整型与浮点型
> - 存储精度：`8 / 16 / 32 / 64`
>
> `ffmpeg`中的采样格式：
>
> ```c
> enum AVSampleFormat {
>     AV_SAMPLE_FMT_NONE = -1,
>     AV_SAMPLE_FMT_U8,          // unsigned 8 bits
>     AV_SAMPLE_FMT_S16,         // signed 16 bits
>     AV_SAMPLE_FMT_S32,         // signed 32 bits
>     AV_SAMPLE_FMT_FLT,         // float
>     AV_SAMPLE_FMT_DBL,         // double
>  
>     AV_SAMPLE_FMT_U8P,         // unsigned 8 bits, planar
>     AV_SAMPLE_FMT_S16P,        // signed 16 bits, planar
>     AV_SAMPLE_FMT_S32P,        // signed 32 bits, planar
>     AV_SAMPLE_FMT_FLTP,        // float, planar
>     AV_SAMPLE_FMT_DBLP,        // double, planar
>     AV_SAMPLE_FMT_S64,         // signed 64 bits
>     AV_SAMPLE_FMT_S64P,        // signed 64 bits, planar
>  
>     AV_SAMPLE_FMT_NB           // Number of sample formats
> };
> ```
>
> 

​		为了节省存储空间以及传输成本，通常我们会对音频 PCM 数据进行压缩，这也就是**音频编码**，比如 MP3、AAC、OPUS 都是我们常见的音频编码格式。

​		linux上可以使用`aplay`处理和播放PCM音频，`aplay` 是 ALSA (Advanced [Linux](https://link.csdn.net/?target=https%3A%2F%2Fgitcode.com%2Fopenharmony%2Fkernel_linux_config%2Foverview%3Flogin%3Dfrom_csdn) Sound Architecture) 的一部分，可以用于播放PCM格式的音频文件。

> ### ALSA（Advanced [Linux](https://link.csdn.net/?target=https%3A%2F%2Fgitcode.com%2Fopenharmony%2Fkernel_linux_config%2Foverview%3Flogin%3Dfrom_csdn) Sound Architecture）：
>
> [Linux](https://link.csdn.net/?target=https%3A%2F%2Fgitcode.com%2Fopenharmony%2Fkernel_linux_config%2Foverview%3Flogin%3Dfrom_csdn)[操作系统](https://link.csdn.net/?target=https%3A%2F%2Fgitcode.com%2Fopenharmony%2Fkernel_linux_config%2Foverview%3Flogin%3Dfrom_csdn)上的音频架构，用于处理音频输入和输出。它是[Linux](https://link.csdn.net/?target=https%3A%2F%2Fgitcode.com%2Fopenharmony%2Fkernel_linux_config%2Foverview%3Flogin%3Dfrom_csdn)内核的一部分，并提供了一种标准的音频接口，用于访问计算机的音频硬件和驱动程序。ALSA的主要目标是提供高质量的音频支持，并在[Linux](https://link.csdn.net/?target=https%3A%2F%2Fgitcode.com%2Fopenharmony%2Fkernel_linux_config%2Foverview%3Flogin%3Dfrom_csdn)系统中实现低延迟和高性能的音频处理。
>
> 以下是ALSA的一些主要特点和组成部分：
>
> 1. **驱动程序**：ALSA包括一系列驱动程序，用于支持各种音频硬件设备，如声卡、USB音频接口等。这些驱动程序允许[Linux](https://link.csdn.net/?target=https%3A%2F%2Fgitcode.com%2Fopenharmony%2Fkernel_linux_config%2Foverview%3Flogin%3Dfrom_csdn)系统与音频设备进行通信。
> 2. **音频库**：ALSA提供了音频应用程序开发所需的库，包括C库（libasound）和Python绑定。这些库允许开发人员创建和管理音频应用程序，包括音频播放器、录音应用、音频编辑工具等。
> 3. **用户空间工具**：ALSA附带了一些实用的用户空间工具，用于配置和管理音频设置，例如`alsamixer`和`aplay`。
> 4. **插件架构**：ALSA具有插件架构，允许开发人员创建和使用插件来执行各种音频处理任务，如混音、音频格式转换等。这增强了ALSA的灵活性和可扩展性。
> 5. **低延迟性能**：ALSA旨在提供低延迟和高性能的音频处理，这对于音频专业人士、音频编程和音乐制作应用非常重要。
> 6. **跨平台支持**：虽然ALSA最初是为[Linux](https://link.csdn.net/?target=https%3A%2F%2Fgitcode.com%2Fopenharmony%2Fkernel_linux_config%2Foverview%3Flogin%3Dfrom_csdn)设计的，但它也被移植到其他Unix-like[操作系统](https://link.csdn.net/?target=https%3A%2F%2Fgitcode.com%2Fopenharmony%2Fkernel_linux_config%2Foverview%3Flogin%3Dfrom_csdn)，因此可以在一些BSD系统上找到。
> 7. **支持多声道音频**：ALSA支持多声道音频处理，使其适用于多媒体应用和音频制作工作流程。

[adpcm编解码原理及其代码实现-CSDN博客](https://blog.csdn.net/littlezls/article/details/83501580)



## 音频压缩编码

​		 将音频采样数据（**PCM** ）压缩成音频码流，从而降低音频的数据量。

- 有损压缩：利用人耳遮蔽效应，消除采样数据中的冗余信息

  - 消除冗余信息：人耳不能感知的冗余信号，包括人耳听觉范围之外的音频信号以及被掩蔽掉的音频信号等。

  - 解压后的数据不能完全复原，压缩比越小，丢失的信息越多，信号还原后的失真就会越大。

- 无损压缩

  ​	解压后的数据可以完全复原，单纯进行数据的压缩。

  - 熵编码
    - 哈夫曼编码
    - 算术编码
    - 香农编码


```text
音频编码过程

---> 时域转频域变换-----> 量化编码 -----> 比特流格式化------> 比特流
 |-> 心理声学模型----------↑       辅助数据---↑
```



### 人耳掩蔽效应

​		人耳掩蔽效应：数字音频压缩编码采取去除声音信号中冗余成分的方法来实现。

> ​		所谓冗余成分指的是音频中不能被人耳感知到的信号，它们对确定声音的音色，音调等信息没有任何的帮助。
>
> ​		冗余信号包含人耳听觉范围外的音频信号以及被掩蔽掉的音频信号等。

- 人耳所能察觉的声音信号的频率范围为20Hz～20KHz，除此之外的其它频率人耳无法察觉，都可视为冗余信号。
- 此外，根据人耳听觉的生理和心理声学现象，当一个强音信号与一个弱音信号同时存在时，弱音信号将被强音信号所掩蔽而听不见，这样弱音信号就可以视为冗余信号而不用传送。

​		这就是人耳听觉的掩蔽效应，主要表现在频谱掩蔽效应和时域掩蔽效应。

- 频域遮蔽：多个频率叠加的复合声音中，通过傅里叶变换等手段，去除掉被主频率遮蔽掉的声源信息。

  > 一个频率的声音能量小于某个阈值后，人耳就会听不到。当有另外能量较大的声音出现时， 该声音频率附近的阈值会提高很多。

  ![img](https://raw.githubusercontent.com/Mocearan/picgo-server/main/36d5bfe6593b870a11830ab4f23b4a27.png)

- 时域遮蔽：主频率前后一定时间范围内，声音强度呈梯度下降的被主频率声源所屏蔽。

  > 当强音信号和弱音信号同时出现时，还存在时域掩蔽效应。即两者发生时间很接近的时候，也会发生掩蔽效应。
  > 时域掩蔽效应可以分成三种：前掩蔽，同时掩蔽，后掩蔽。前掩蔽是指人耳在听到强信号之前的短暂时间内，已经存在的弱信号会被掩蔽而听不到。同时掩蔽是指当强信号与弱信号同时存在时，弱信号会被强信号所掩蔽而听不到。后掩蔽是指当强信号消失后，需经过较长的一段时间才能重新听见弱信号，称为后掩蔽。这些被掩蔽的弱信号即可视为冗余信号。
  
  ![img](https://raw.githubusercontent.com/Mocearan/picgo-server/main/ed045450cae2097feaead33ce78fe374.png)













### MP3

​		MP3（ **MPEG-1 or MPEG-2 Audio Layer III**）是一种有损的音频编码方式，旨在在尽量减少文件大小的同时保持较好的音质。

​		其中一种实现为`LAME`编码，使用`LAME`编码的中高码率的MP3文件，听感上非常接近源`WAV`文件，不同的应用场景下，应该调整合适的参数以达到最好的效果。

> 将原始音频信号进行数字化并进行压缩。它通过去除人耳不易察觉的音频信息来降低文件大小，从而实现音频数据的高效存储。

- 音质在128Kbit/s以上表现还不错
- 压缩比较高，大量软件和硬件都支持，兼容性好
- 使用与高比特率下对兼容性有要求的音乐欣赏





### AAC

​		**AAC**，英文全称 **Advanced Audio Coding**，是由 **Fraunhofer IIS**、杜比实验室、**AT&T**、**Sony** 等公司共同开发。是新一代的音频有损压缩技术，MP3的继任者。

​		分为ADIF格式和ADTS格式。

- ADIF格式：Audio DataInterchange Format
  - 特征是可以确定的找到这个音频数据的开始，只能从头开始解码，不能在音频数据流中间开始
  - 常用在磁盘文件中。
- ADTS格式：Audio Data Transport Stream
  - 特征是每一帧都有一个同步字，所以可以再音频流的任何位置开始解码，类似于数据流格式。

> http://www.p23.nl/projects/aac-header/







### Ogg编码

​		Ogg是一种非常有潜力的编码，在各种码率下都有比较优秀的表现，尤其是在中低码率场景下，音质好，且免费。

​		Ogg有着非常出色的算法，可以用更小的码率达到更好音质，128Kbit/s的Ogg比192Kbit/s甚至更高码率的MP3还要出色。但目前没有媒体服务软件支持，因此基于Ogg的数字广播还无法实现。

- 可以用比MP3更小的码率实现比MP3更好的音质，高中低码率下均有良好的表现，兼容性不够好，流媒体特性不支持。.
- 适用场合：语音聊天的音频消息场景



### 各个音频编码对比

![image-20240225192246401](https://raw.githubusercontent.com/Mocearan/picgo-server/main/image-20240225192246401.png)

![image-20240225192432266](https://raw.githubusercontent.com/Mocearan/picgo-server/main/image-20240225192432266.png)



## 音频封装格式

[音频编码格式介绍_ram音频格式-CSDN博客](https://blog.csdn.net/littlezls/article/details/135862140)

### WAV

​		`WAV`是一种封装格式。

​		它能够支持多种音频编码类型，但最常用的情况下是在未压缩的`PCM`数据格式的前面加上44字节，分别用来描述PCM的采样率、声道数、数据格式等信息。

- 音质好
- 大量软件支持
- 适用于多媒体开发中的中间文件、保存音乐和音效素材
- 存储的声音质量非常高，但文件尺寸较大。

### MP3

​		虽然MP3是编码格式，但通常文件扩展名为`.mp3`的文件的确也是一种**音频封装格式**。

​		因为它们不仅包含编码后的音频流，还可能包含一些元数据（如艺术家、歌曲名、专辑信息等）。

​		在实际应用中，MP3文件同时扮演编码和封装的角色。



### AAC



## 音频重采样

​		将音频三元组：位深、采样率和通道数，当前的值转换成另外一组值。

- 设备采集的音频数据与编码器要求的输入数据不一致。
- 样神奇要求的音频数据与要播放的音频数据不一致。
- 更方便运算
  - 回音消除中，将多声道变为单声道进行计算


​		是否需要重采样：

- 了解音频设备的参数
- 查看ffmpeg源码中对各平台不同编码器的实现

​		重采样的步骤：

- 创建采样上下文
- 设置参数
- 初始化重采样
- 进行重采样



## 音频处理

音频分析是指对音频信号进行测量、分析和评估，以获取其特性或质量信息。常见的音频分析技术包括频谱分析、动态分析、清晰度分析等。



## 音频合成

音频合成是指通过声音合成技术，创造新的声音或音乐。常见的音频合成技术包括采样合成、波形合成、算法合成等。



## 其他音频技术

​		音频基础知识还包括音频处理技术，如音频采集、音频数据传输、音频-视频同步、音频效果与编辑、语音编码/解码、文-语转换、音乐合成、语音增强、噪声抑制，回声消除、麦克风阵列、解混响、声源定位、盲源分离、语音识别与理解、合成等。

[语音信号处理 - 深蓝学院 - 专注人工智能与自动驾驶的学习平台 (shenlanxueyuan.com)](https://www.shenlanxueyuan.com/course/728)

[基于RNN的音频降噪算法 (附完整C代码)_音频降噪算法 附完整c代码-CSDN博客](https://blog.csdn.net/littlezls/article/details/111616843)

[音频降噪算法 附完整C代码-CSDN博客](https://blog.csdn.net/littlezls/article/details/111615545)
