# media base

---



## 流媒体

​		使用非明确边界的数据连续传输技术。

- 狭义上是音频和视频形成稳定和连续的传输流和回放流的一系列技术、方法和协议的总称，即流媒体技术；
- 广义上的流媒体是相对于传统的 下载-回放方式而言的，指的是一种从Internet上获取音频和视频等多媒体数据的新方法，它能够支持多媒体数据流的实时传输和实时播放。

​		目前实现流媒体传输主要有两种方法：顺序流（progressive streaming）传输和实时流（realtime streaming）传输，它们分别适合于不同的应用场合。

### 顺序流传输

​    	顺序流传输采用顺序下载的方式进行传输，在下载的同时用户可以在线回放多媒体数据，但给定时刻只能观看已经下载的部分，不能跳到尚未下载的部分，也不能在 传输期间根据网络状况对下载速度进行调整。

​		由于标准的HTTP服务器就可以发送这种形式的流媒体，而不需要其他特殊协议的支持，因此也常常被称作HTTP 流式传输。

​		顺序流式传输比较适合于高质量的多媒体片段，如片头、片尾或者广告等。

### 实时流传输

​    	实时流式传输。

> 对于实时流传输，其核心点在于将时间戳信息封装在流的格式中，使其能够快速被同步和播放。这一点通常是封装容器层做的，但RTP协议也添加了时间戳信息，所以会有人认为RTP协议是封装格式。

- 分组传输，接收端收到的数据包往往有延迟和乱序(UDP)
  - 降低延迟和恢复数据包时序
  - 高效压缩
  - 恢复时序，采用接收缓冲
  - 流畅播放，采用播放缓冲

- 保证媒体信号带宽与网络状况相匹配，使得流媒体数据被实时地传送，适合于现场事件。

- 支持随机访问，即用户 可以通过快进或者后退操作来观看前面或者后面的内容。
  - 理论上实时流媒体一经播放就不会停顿，但事实上有可能发生周期性的暂停现象
  - 尤其是在网络状况恶化时更是如此。

- 与顺序流传输不同的是，实时流传输需要用到特定的流媒体服务器，而且还需要特定网络协议的支持

  

​		互联网流媒体直播需要一种形式的源媒体（如摄像机、音频接口、屏幕捕捉软件）、将内容数字化的编码器、媒体发布者和内容传输网络来分发和传递内容。



## 多媒体文件结构

![img](https://raw.githubusercontent.com/Mocearan/picgo-server/main/b29b31c510649290780b19484c3469f4.png)

- **封装容器**
  - 将已经编码压缩好的视频轨和音频轨按照一定的格式组织到一个文件中
  - 包含多媒体文件所包含的视频信息、音频信息和相关的配置信息
  - mp4、mkv、webm、avi、3gp、mov、wmv、flv、mpeg、asf、rmvb等

## 流媒体基本原理

- 录制![image-20220816211216411](https://raw.githubusercontent.com/Mocearan/picgo-server/main/image-20220816211216411.png)

- 播放![image-20220816211236450](https://raw.githubusercontent.com/Mocearan/picgo-server/main/image-20220816211236450.png)

- 上述过程可以合并成

  ![在这里插入图片描述](https://img-blog.csdnimg.cn/direct/a157887e5d934c2a88e81aa2a8f98d92.png)

​		上述的过程可以描述为一下几个方面：

- 音视频采集

  ​	通过各种音视频采集设备或录制设备，将物理声像按照一定的频率、规则采样成为模拟、数字数据

- 编解码

  ​	采集的原始数据往往较大，通过一定的算法，将数据压缩以便存储或传输。在使用数据时按照相应的算法解压数据。

- 封装

  ​	无论是裸数据还是压缩后的数据，为了方便进行存储、读取和传输，会加上一定的附加数据（元数据、索引数据、描述数据等）来拓展对音视频数据的操作。

- 传输

  ​	不同场景下，对音视频的传输有着不同的要求，所以就需要不同的传输协议来规定传输过程中的控制信息。

- 音视频同步

  ​	在视频和音频数据混合的场景下，音频数据和视频数据需要按照各自采样、编码等的时间来同步数据，避免音画不同步的现象。

- 音视频渲染播放

  ​	在使用音视频文件、码流时，封装和编解码格式数据已经失去意义，需要由使用方的相应组件去除后，将原始数据的渲染成声像。



## 音视频采集

- 图像采集
  - RGB
  - YUV
- 视频采集
  - 连续采集的图像数据构成视频
  - 帧内编码、帧间编码
- 音频采集
  - PCM脉冲编码调制



## 音视频编解码

​		编码时为了尽量保证数据质量的情况下压缩数据量。

​		采集到的像素数据和音频数据由视频编码器或音频编码器，进行压缩编制成一定格式的音视频帧。

- `YUV/RGB`像素数据编码成`H264/H265/VP8/VP9`等视频帧
- `PCM`音频数据编码成`AAC`音频帧

### 视频编码

​		将视频像素数据（RGB，YUV 等）压缩成视频码流

- H.261，主要用于老的视频会议和视频电话系统。是第一个使用的数字视频压缩标准。实质上说，之后的所有的标准视频编解码器都是基于它设计的。

- H.262，等同于 MPEG-2 第二部分，使用在 DVD、SVCD 和大多数数字视频广播系统和有线分布系统中。

- H.263，主要用于视频会议、视频电话和网络视频相关产品。在对逐行扫描的视频源进行压缩的方面，H.263 比它之前的视频编码标准在性能上有了较大的提升。尤其是在低码率端，它可以在保证一定质量的前提下大大的节约码率

- H.264（Advanced Video Coding， AVC），等同于 MPEG-4 第十部分，也被称为高级视频编码，被广泛使用的高精度视频的录制、压缩和发布格式。该标准引入了一系列新的能够大大提高压缩性能的技术，并能够同时在高码率端和低码率端大大超越以前的诸标准。

  H.265（High Efficiency Video Coding， HEVC），被称为高效率视频编码是一种视频压缩标准，是 H.264 的继任者。HEVC 被认为不仅提升图像质量，同时也能达到 H.264 两倍的压缩率（等同于同样画面质量下比特率减少了 50%），可支持 4K 分辨率甚至到超高画质电视，最高分辨率可达到 8192×4320（8K 分辨率），这是目前发展的趋势。

> ​		H.26X 由国际电传视讯联盟远程通信标准化组织（ITU-T）主导，包括 H.261、H.262、H.263、H.264、H.265。
>
> ​		MPEG 系列MPEG 系列由国际标准组织机构（ISO）下属的运动图象专家组（MPEG）开发。
>
> ​		两个组织有所合作，比如H264即合作产生。
>
> - MPEG-1 第二部分，主要使用在 VCD 上，有些在线视频也使用这种格式。该编解码器的质量大致上和原有的 VHS 录像带相当。
> - MPEG-2 第二部分，等同于 H.262，使用在 DVD、SVCD 和大多数数字视频广播系统和有线分布系统中。
> - MPEG-4 第二部分，可以使用在网络传输、广播和媒体存储上。比起 MPEG-2 第二部分和第一版的 H.263，它的压缩性能有所提高。
> - MPEG-4 第十部分，等同于 H.264，是这两个编码组织合作诞生的标准。

![img](https://raw.githubusercontent.com/Mocearan/picgo-server/main/3811ea9bd9eef3f03e74ef5baeaa4a04.png)

### 音频编码

- `MP3 (MPEG-1 or MPEG-2 Audio Layer III)`

  - `MPEG 1993`
  - 是曾经非常流行的一种数字音频编码和有损压缩格式，被设计来大幅降低音频数据量。
  - MP3 的普及，曾对音乐产业造成极大的冲击与影响。

- `AAC (Advanced Audio Coding)`

  - `MPEG 1997`

  - 基于 MPEG-2 的音频编码技术。

  - 2000 年，MPEG-4 标准出现后，AAC 重新集成了其特性，加入了 SBR 技术和 PS 技术

    > 为了区别于传统的 MPEG-2 AAC 又称为 MPEG-4 AAC。

  -  AAC 比 MP3 有更高的压缩比，同样大小的音频文件，AAC 的音质更高。

- `WMA (Windows Media Audio)`

  - 微软
  - 本身包括有损和无损压缩格式



## 音视频封装

​		封装格式也叫容器，将已经编码压缩好的图片流、音频流、字幕信息按照一定的方案组织在一个文件中，便于对音视频数据进行读写操作。

​		封装格式是将视频流、音频流、字幕流以及其他组成部分按一定的规则组合存储或传输，由复用器或解复用器进行组合或拆分。

- 视频文件的后缀一般就是它的封装格式：

  ```
  AVI / MKV / MPE / MPG / MPEG 
  MP4 / WMV / MOV / 3GP
  M2V / M1V / M4V / OGM
  RM / RMS / RMM / RMVB / IFO
  SWF / FLV / F4V
  ASF / PMF / XMB / DIVX / PART
  DAT / VOB / M2TS / TS / PS
  
  # 存储格式常用的有 AVI、MKV、MP4、
  # 传输格式常用的有 FLV、TS、PS
  ```
  
  - `AVI (Audio Video Interleaved)`，`.avi`
    - `Microsoft 1992`
    - 优点是图像质量好，无损 AVI 可保存 alpha 通道
    - 缺点是体积过于庞大，压缩标准不统一，存在较多的高低版本兼容问题
  - `DV-AVI (Digital Video Format)`
    - 索尼、松下、JVC
    - 常见的数码摄像机使用这种格式记录视频数据的。
    - 可通过电脑的 IEEE 1394 端口传输视频数据到电脑，也可将电脑中编辑好的的视频数据回录到数码摄像机中。
  - `WMV (Windows Media Video)`，`.wmv / .asf`
    - 微软
    - 独立编码方式并且可以直接在网上实时观看视频节目的文件封装格式。
    - 同等视频质量下，`WMV `格式的文件可以边下载边播放，很适合在网上播放和传输。
  - `MPEG(Moving Picture Experts Group)`
    - `.mpg / mpeg / .vob / .dat / .3gp / .mp4`
    - 由运动图像专家组制定的视频格式， 1988 年组建该专家组，专门负责视频和音频标准制定，其成员都是视频、音频以及系统领域的技术专家
    - MPEG 格式目前有三个压缩标准，分别是 MPEG-1、MPEG-2和 MPEG-4。
    - MPEG-4 现在用的比较多的视频封装格式，是为播放流式媒体的高质量视频而专门设计的，以求使用最少的数据获得最佳的图像质量。
  - `Matroska`，`mkv`
    - 可将多种不同编码的视频及 16 条以上不同格式的音频和不同语言的字幕流封装到一个 Matroska Media 文件当中
  - `Real Video`，`.rm / .rmvb`
    - `Real Networks`
    - 用户可使用 RealPlayer 根据不同的网络传输速率制定出不同的压缩比率，从而实现在低速率的网络上进行影像数据实时传送和播放。
  - `QuickTime File Format`，`.mov`
    - `Apple `
    - 默认的播放器是苹果的 QuickTime。
    - 这种封装格式具有较高的压缩比率和较完美的视频清晰度等特点，并可以保存 alpha 通道。
  - `Flash Video`，`.flv`
    - `Adobe Flash` 延伸出来的一种网络视频封装格式。
    - 这种格式被很多视频网站所采用。

​		H264 + AAC封装为FLV或MP4是最为流行的封装模式。

![img](https://raw.githubusercontent.com/Mocearan/picgo-server/main/51e31c6fef70210afd9d4b87f96b2167.png)

## 音视频传输



## 音视频同步

### 时间戳

- DTS（Decoding Time Stamp） 解码时间戳

  ​	播放器根据DTS解码一帧数据

- PTS（Presentation Time Stamp）显示时间戳

  ​	播放器根据PTS展示一帧数据

### 同步方式

- Audio Master：同步到音频
- Video Master： 同步音频到视频
- External Clock Master：同步音频和视频到外部时钟

​		一般情况下 Audio Master > External  Clock Master > Video Master

#### 音视频同步

Avsync模块，目前只支持audio master的方式。

各个模块关键时间点的监测：

![在这里插入图片描述](https://img-blog.csdnimg.cn/direct/27634419690040d59b231b7a64c96f14.png)



## 音视频渲染



## 实时流媒体质量评估

​		实时音视频通信追求的本质是尽可能逼近或达到面对面交流的效果。实时流媒体技术的限制在于：

- 实时性损失。音视频经过网络传输后必定带来延时，这种延时对于一些互动性较强通信场景就是不能忍受的了。
- 业务数据的损失。这个主要就是因为设备等因素的限制而无法完全还原直播现场全部的真实场景，包括现场氛围等。

​		在实时音视频通信的场景中有2个指标可以很好的评估通信的“真实感”。一是实时通信中的延迟指标；二是音视频服务质量指标。

### 实时通信延迟

|   延时    |              人的感受              |
| :-------: | :--------------------------------: |
|   200ms   |           优质，身临其境           |
|  300ms内  |             大多数满意             |
|  400ms内  | 小部分人感觉延迟，基本互动可以进行 |
| 500ms以上 | 延迟明显，影响互动，大部分人不满意 |

引起延迟的因素很多，比如音视频采集、编码、传输、渲染等等这些处理过程都会带来延迟。其中，网络传输的延迟是最难评估和控制的，因为影响它的因素众多，且其变化是动态的。

### 音视频服务质量指标

视频服务质量和视频的分辨率、帧率、码率是息息相关的。

- 分辨率：图像占用屏幕上像素的多少。
- 帧率：指视频每秒播放图像的数量。对于实时通信的视频来说，低于 15 帧/s被认为卡顿严重。
- 码率：指视频压缩后每秒数据流的大小。在相同分辨率时，码率越大，视频就越清晰。

除上面三个概念之外，还需要了解MOS值。MOS值是平均意见值，有主观和客观之分，是用来评估音视频服务质量好坏的。一般而言，5分表示优秀，4分表示较好，3分表示还可以，2分表示差，1分表示很坏。

以H264编码为例，在不同MOS值下，码率与分辨率的关系：

![在这里插入图片描述](https://img-blog.csdnimg.cn/img_convert/5b2f70a875771337f40e0e13818f8106.png)

如果希望视频的MOS值为4，分辨率为640*480时需要1.9Mbps的码率，分辨率为1920*1080时，需要7Mbps的码率；而希望视频的MOS值为3，分辨率为640*480时需要0.5Mbps的码率，分辨率为1920*1080时，需要2.5Mbps的码率。可以看到，MOS值越高，视频质量越好，码率也就越大，需要的带宽也就越多。



### 主要矛盾

![在这里插入图片描述](https://raw.githubusercontent.com/Mocearan/picgo-server/main/bec7b581f758c77a9517907ead078f89.png)

​		视频服务质量与带宽大小、网络质量、实时性之间的矛盾。

- 增加带宽

  > 增加带宽是指所有用户的带宽都增加，单一用户增加带宽对服务质量没有提升

  - 5G网络的普及
  - WebRTC支持的选路方案是一个很好的方案，它可以按优先级选择最优质的网络连接线路。
  - 提供更优质的接入服务、保证云端网络的带宽和质量、更合理的路由调度策略来提供更优秀的带宽。

- 减少数据量

  > 网络带宽无法增加时，最有效的解决这一矛盾的方法就是减少音视频的数据量，虽然会牺牲音视频服务的质量。

  - 更好的压缩算法：比如使用H265，AV1等压缩率更高的编解码器。
  - SVC技术：SVC技术就是将视频按时间、空间及质量分成多层编码，然后将它们装在一路流中发给服务端。服务端收到后，再根据每个用户的带宽情况选择不同的层下发。
  - `Simulcast`技术：与SVC的分层思想类似，但它的实现更简单。就是将视频编码出不同分辨率的多路码流，上传给服务器。服务器则根据每个用户带宽情况选择一路最合适的流下发。
  - 动态码率：当网络带宽评估用户带宽不足时，则通过编译器让其减小输出码率；而当评估带宽增大时，则增加输出码率。
  - 甩帧或减少业务：这是一种下下策的方法，只有在用户网络非常差的情况下才可能使用。

- 适当增加延迟

  > 在网络抖动的情况下，使用缓冲队列来平滑处理数据，这种适当增加延时的方法也是可以解决部分业务质量和网络之间的矛盾的。
  >
  > 但在实时流媒体中，必须把时延控制在一定范围内。由于音视频的采集、编解码、渲染等时间是固定的，所以只要把网络时延算出来，就可以确定缓冲区的时延。（这种方式在WebRTC中也是有应用的，比如PacedSender。）

- 提高网络质量

  > 前提是网络没有发生拥塞。可以从丢包、延迟、抖动三个方面来评价网络质量的好坏。

  - 丢包：是网络传输过程中对网络影响最大的指标，优质的网络丢包率不超过2%。
    - 对于WebRTC而言，大于2%且小于10%的丢包率是正常网络。
  - 延迟：相对丢包来说对网络影响要小点。如果网络中延迟持续增大，则可能是网络中发生了拥塞。
  - 抖动：对网络影响最小。一般的抖动都可以通过缓冲队列来解决。

  > 在WebRTC中有很多提高网络质量的方法，比如NACK/RTX、FEC前向纠错、JitterBuffer防抖动、NetEQ等。
  >
  > - NACK/RTX：NACK是RTCP的一种消息类型，由接收端向发送端报告一段时间内有哪些包丢失了；RTX指发送端重传丢失的包，并使用新的SSRC（将音视频包与重传包进行区分）。
  > - FEC前向纠错：使用异或操作传输数据，以便丢包时恢复丢失的包。FEC特别适合随机少量丢包的场景。
  > - JitterBuffer：用于防抖动，可以将抖动较小的乱序包恢复有序。
  > - NetEQ：包括JitterBuffer，专用于音频控制，可以实现音频的防抖动。
  > - 拥塞控制：它需要控制两个点：第一个点是Pacer，降低发送码率。当然仅降低发送码率还不够，因为如果编码器仍然输出大量码流给Pacer，那么Pacer 的缓冲区迟早会被撑爆。所以在控制Pacer让它减少发送码率的同时，一定要降低音视频的编码器的输出码率，从而保持平衡，进而使数据平缓下行。



### 快速评估带宽

​		网络质量提升的前提是网络没有拥塞。只要能够快速准确地评估出带宽，通常就能有效的防止网络拥塞的发生。

在实时通信领域，有4种常见的带宽评估方法：

1. Goog-REMB
2. Goog-TCC
3. NADA
4. SCReAM















