

# Image

---

​		**图像是人对视觉感知的物质再现。**图像是由自发光或反射光源进入人眼而成像的。

- 『视觉感知』对应着图像成像的过程
- 『物质再现』对应着图像信号处理的过程。



## 参考

[图像格式：常见图像格式RAW, RGB, YUV&&图像格式的解析、格式转换和看图软件_raw图片编码-CSDN博客](https://blog.csdn.net/weixin_45264425/article/details/132626509)

[FFMPEG 内部YUV转RGB过程 - 洛笔达 - 博客园 (cnblogs.com)](https://www.cnblogs.com/luoyinjie/p/13669368.html)



## 成像原理

### 视觉感知

​		人眼能够看到物体，是因为人眼的晶状体结构相当于一个**凸透镜**，物体的**反射光**通过晶状体**折射成像于视网膜**上，再由视觉神经感知传给大脑，这样人就看到了物体。这就是物体在人眼成像的原理。

​		相机利用光的直线传播性质和光的折射与反射规律，以光子为载体，把某一瞬间的被摄景物的光信息量，以能量方式经镜头传递给感光材料（模拟的胶卷或数字的硅片），最终成为可视的影像。

​		很多应用场景中将镜头当做理想的针孔，对照小孔成像原理来理解就足够了。但是，如果要处理诸如焦距、曝光、虚影和像差等问题，就需要提出更复杂的模型，这是光学要研究的问题。

​		光是一种电磁波，而人类视觉系统中有三种不同的椎体细胞，它们分别对不同波长段的光最敏感，视锥细胞形成的视觉信号复合后为人呈现了色彩缤纷的世界，这是**人眼视觉感知三原色理论**。人类并不能看见所有的电磁波，因此把能看见的电磁波称为**可见光**，对应的波长在 380-780 nm 之间。

​		日常所见的大多数光，都是不同波长的光组合而成，因此我们才能看到这么多颜色。比如太阳光，它就是由多种不同颜色的光组合而成，牛顿很早的时候就用棱镜揭示过这个事实：**白光包含所有可见光谱的波长**。

> 人类视觉系统中有三种不同的椎体细胞，它们分别对黄绿色、绿色和蓝紫色的光最敏感。第一种对长波长的光响应最大，峰值波长约为 560 nm，有时将这种类型视锥细胞称为 L。第二种类型对中波长的光响应最大，在 530 nm 处达到峰值，通常简称为 M。第三种类型对短波长的光响应最大，在 420 nm 处达到峰值，简称为 S。人类视锥细胞的峰值响应因人而异，所以这三种类型的峰值波长要取决于个人，它们的范围在 564–580 nm，534–545 nm 和 420–440 nm 附近。
>
> 这三种类型不完全对应于如我们所知的特定的颜色。相反，对颜色的感知是由一个开始于这些位于视网膜的细胞差异化的输出，且将在大脑的视觉皮层和其它相关区域中完成的复杂的过程实现的。例如，尽管 L 视锥细胞简称为红色感受器，紫外可见分光光度法表明它们的峰值敏感度在光谱的绿黄色区域。类似的，S 视锥细胞和 M 视锥细胞也不直接对应蓝色和绿色，尽管它们经常被这样描述（在很多资料的描述中，人眼的三种椎体细胞敏感的光分别对应 630 nm 的红光、530 nm 的绿光和 450 nm 的蓝光，因此才把 RGB 作为三基色）。实际上 RGB 颜色模型仅仅是用以表达颜色的一个方便的方式，而不是直接基于人眼中的视锥细胞类型。

​		把人眼对颜色的感受进一步细化，它可以分为如下几个特征：

- **色调（hue）。**太阳或灯泡等光源发射可见波段的全部频率而产生白色光。当白色光投射到一个物体上时，某些频率被反射，某些则被物体吸收了。在反射光中混合的频率确定了我们所感受到的物体的颜色。如果在反射光中以低频率为主，则物体呈现红色。此时，我们可以说光谱中红色端有一个主频率（或主波长），也称为光的色调。
- **亮度（brightness）。**对应于光的能量大小，可量化为光源亮度。
- **饱和度（saturation）。**对应于光的颜色表现接近光谱色（例如红色）的程度。浅色或暗淡的颜色的饱和度较低，它们比较接近白色。
- **色度（chromaticity）**通常是说明『饱和度』和『色调』这两种特征的综合表现。



## 基本概念

- 色彩空间：`RGB/YUV`，是像素点记录色彩数据的方式

- 像素（pixel）：像素是构成图片的基本单位，每个像素就是一个视觉采样的单元

  - 像素由RGB或YUV色彩空间构成

- 分辨率：是指图像的大小或尺寸，同时表达了图片的采样量

  - 比如`1920x1080`表示横`1920`个像素，纵`1080`个像素的排列，两百万像素
  - 分辨率的比例一般是`16:9`
  - 分辨率后面跟`P`表示为逐行扫描；跟`I`为隔行扫描
    - 隔行扫描一般是电视使用，可能出现锯齿
    - 逐行扫描一般是网络、视频文件使用

- DPI：每英寸显示设备上的像素数量

  - 由设备分辨率决定

- 位深：是指在采样视觉数据时，用来描述数字图像颜色数据的数据量

  - 比如RGB中红色分量用`8bit`，YUV中Y分量用`8bit`
  - RGB中用红绿蓝三原色加上透明度alpha分量来描述一个像素，位深越大描述的像素颜色越多
  - YUV中用亮度（Y）、色度描述（U和V）一个像素，位深越大画面越细腻

- 跨距（Stride）：内存中每行像素所占的空间

  - 编码中存在内存对齐导致每行像素在内存中的数据表示和理论上的图像宽度并不一定相同

  - 也称为Padding，如果图像的每一行像素末尾拥有对其内容，Stride 的值一定大于图像的宽度值

  - ![在这里插入图片描述](https://img-blog.csdnimg.cn/direct/8705ced6a6764833ab4ba32cbd14ef56.png)

    > 分辨率638x480的RGB24图像，内存处理的时候如果要以16字节对齐
    >
    > ​	638/16=119.625不能整除，需要在每行尾部填充6个字节：`640 / 16 = 120 /638->640 / 2*24bit=48bit=6byte `。
    >
    > ​	此时该图片的stride为``480*6=1920``字节。





- 画质：画面质量，由清晰度、锐度、解析度、色彩纯度、色彩平衡等指标构成。
- 清晰度：指图像细节纹理及其边界的清晰程度。
- 锐度：反应图像平面清晰程度，以及图像边缘的锐利程度。
- 解析度：指像素点的数量，与分辨率对应，分辨率越高，解析度越高。
- 色彩纯度：指色彩的鲜艳程度。所有色彩都是三原色组成，其他颜色都是三原色混合而成，理论上可以混合出256种颜色。原色的纯度最高。色彩纯度是指原色在色彩中的百分比。
- 色彩平衡：用来控制图像的色彩分布，使得图像整体达到色彩平衡。
- 色域：指某种表色模式所能表达的颜色构成的范围区域，色域空间越大，所能表现的颜色越多。
- HDR：High Danamic Range，高动态范围，比普通图像提供更多动态范围和图像细节，能够更好反应真实环境的视觉效果。颜色值经过归一化后，范围一般是[0,1]。而HDR可以表达超出1的颜色值，拥有更大的颜色范围。
- 旋转角度：视频的YUV储存方向。一般的视频旋转角度是0°，对应的是横屏显示。后置摄像头竖屏拍的视频，旋转角度为90°，对应的是竖屏显示。Android中可以通过MediaMetaDataRetriever获取旋转角度。
- 时长：视频所有图像播放所需要的时间称为视频时长。计算公式：时长(s)=帧数x每帧时长=帧数x(1/帧率)。假设一个视频帧数为1000，帧率为25fps，那么时长为40s。





## 图像数学描述

​		颜色是对图像视觉感知最核心的要素，所以对图像进行数学描述，最重要的是建立『颜色模型（颜色空间）』。

​		颜色模型指的是在某种特定上下文中对颜色的特性和行为进行解释的方法。

> 没有哪种颜色模型能解释所有的颜色问题，因此我们需要使用不同的模型来帮助说明我们看到的不同的颜色特征。

### 颜色建模的背景

- **CIE RGB 颜色模型**：基于人眼视觉感知三原色理论，CIE 通过大量实验数据建立了 RGB 颜色模型，标准化了 RGB 表示。

  > CIE 是国际照明协会的简称，他们是最早采用数学方式来定义颜色模型的。
  >
  > CIE 提出的颜色模型是从 1920 年代后期 W. David Wright（Wright 1928）和 John Guild（Guild 1931）做的一系列实验中得出的。他们的实验结果合并到了 CIE RGB 颜色模型的规定中，CIE XYZ 颜色模型再从它发展而来。

- **CIE XYZ 颜色模型**：为了解决 RGB 模型中与负光混合所带来的种种问题，CIE 从数学上定义了三种标准基色 XYZ，形成了 CIE XYZ 颜色模型。

  > 在后续的学术研究和工业应用中，很多新出的颜色模型就是以 CIE XYZ 为基础制定的。这其中就包括模拟电视时代 NTSC、PAL 和 SECAM 等制式标准推出的颜色模型。

- **NTSC YIQ 颜色模型**：在模拟电视时代，RGB 工业显示器要求一幅彩色图像由分开的 R、G、B 信号组成，而电视显示器则需要混合信号输入，为了实现对这两种标准的兼容，NTSC 基于 XYZ 模型制定了 YIQ 颜色模型，实现了彩色电视和黑白电视的信号兼容。

- **PAL YUV 颜色模型**：为了解决 NTSC YIQ 的组合模拟视频信号中分配给色度信息的带宽较低而影响了图像颜色质量的问题，PAL 引入了 YUV 颜色模型，支持用不同的采样格式来调整传输的色度信息量。

- **ITU-R YCbCr 颜色模型**：进入数字电视时代，ITU-R 为数字视频转换制定了 YCbCr 颜色模型，成为我们现在最常使用的颜色模型。

- **伽马校正**：在早年 CRT 显示器流行的年代，我们遇到了显示伽马问题，从而引入了伽马校正过程并延用至今。

​		在实际应用中，针对某一类型的应用场景，人们还是希望尽量做到颜色模型的统一和兼容，所以我们经历了一系列颜色建模和标准制定的过程。下图是颜色标准制定的关键节点图：

![image-20250417161933720](https://raw.githubusercontent.com/Mocearan/picgo-server/main/image-20250417161933720.png)



### CIE RGB 颜色模型

- **加色模式**：一种构造颜色模型的方式，当光由两个或多个具有不同主频率的光源混合而成时，可以改变各个光源的强度来生成一系列其他颜色的光。

  > 加色模式通常应用于『有源物体』。
  >
  > - 一个能自己发出光波的物体称为有源物体
  > - 它的颜色由该物体发出的光波决定
  > - 物体发出对应颜色的光，被眼睛接收，则感应到对应的颜色
  >   - 比如，太阳、电灯、显示屏等

- **减色模式**：一种构造颜色模型的方式，从光源中减去某些颜色后得到的颜色，比如 CMYK。

  > 减色模式通常应用于『无源物体』。
  >
  > - 一个自己不发出光波的物体称为无源物体
  > - 它的颜色由物体吸收的光波（或反射的光波）决定
  > - 第三方光源照到物体上，有的波长被吸收，有的波长被反射，被反射的光波被眼睛接收，从而感知到对应的颜色
  >   - 比如，油画、印刷品等

- **基色**：用来生成其他颜色光源的色彩。

- **颜色范围（色域）**：通过基色可以产生的所有颜色的集合即该颜色模型的色域。

- **互补色**：两种基色混合则生成白色光，则为互补光。

  > 比如红色和青色、绿色和品红、蓝色和黄色都是互补色。



​		在实际的基本颜色中，没有哪一组集合能组合生成所有可见的颜色（我们后续可以通过色度图来说明）。但是，三种基色对多数应用来说是够用的，并且，不包含在指定基色集的颜色范围中的颜色仍然可以使用扩充的方法进行描述。

​		**国际照明协会（CIE），他们在 1931 年通过使用红、绿、蓝**（波长分别是 700.0、546.1、435.8 nm）三种基色所进行的彩色匹配实验，标准化了 RGB 表示。

> ​		为了测试和量化人眼视觉感知三原色理论，可以尝试选择适当的三种基色来混合以再现所有单色（单个波长）的颜色（单色光可以用棱镜或特殊制造的滤镜来获得）。
>
> <img src="https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSuejNvw8NibeuVBD92p4kq0b1DliaQpFYAlUh5oYsMFsp66bibG1rla2riaqWgkchxUOh1XRrL2oCRI97eQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:50%;" />
>
> ​		需要注意的是，在 500 nm 附近的颜色需要从蓝光和绿光的混合光中再『减去』对应的红光得到（红光曲线在 500 nm 附近是负值）。由于这个『负光』的效果在 RGB 彩色显示器无法实现，所以 RGB 彩色显示器不能显示 500 nm 左右的颜色。

​		在 RGB 坐标轴定义的单位立方体来描述 RGB 颜色模型。坐标原点表示黑色，其对角坐标点 (1, 1, 1) 表示白色，在三个坐标轴上的顶点分别表示三个基色，余下的顶点则代表每个基色的补色。

​		RGB 是一种**加色模式**，多种基色的量加在一起生成另一种颜色。立方体边界中的每一个颜色点都可以表示为三基色的加权向量和。

<img src="https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSuejNvw8NibeuVBD92p4kq0b1DRicRjKykrPfCrdtac1WPK4lbluhicZq4oky1x3w0Z3GU05AABcJ9kRdQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:50%;" />

​		在 RGB 系统中，标准白光是按下列比例的 RGB 光通量混合而成：$\Phi_R : \Phi_G : \Phi_B = 1 : 4.5907 : 0.0601$

> 光通量，是一种表示光的功率的物理量，单位为『流明(lm)』，用来衡量光源整体亮度的指标。指单位时间内由光源所发出或由被照物体所吸收的光能。

​		通常把光通量为 1 lm 的红光、4.5907 lm 的绿光、0.0601 lm 的蓝光作为三基色的单位基色量，用  $\vec{R}$, $\vec{G}$, $\vec{B}$ 表示，三基色各自的比例用系数 R、G、B 表示。因此，任何一种具有一定亮度的彩色光的光通量为：

​			$$C(\lambda) = R\vec{R} + G\vec{G} + B\vec{B}$$

- 其中 $C(\lambda)$ 表示彩色光的亮度（luminance），对应颜色的亮度（brightness）特征。

​	当我们**只关心颜色的色度（chromaticity）时**，要知道色度依赖于色调（hue）和饱和度（saturation），反映的是 R、G、B 之间的比例关系，这时候我们可以做**归一化处理**： 

​			$r = \frac{R}{R+G+B}$ ，$g = \frac{G}{R+G+B}$ ， $b = \frac{B}{R+G+B}$

- 我们把 r、g、b 称为**色度坐标**，色度坐标舍弃了给定色彩样本的绝对亮度而只表示其纯色。

- 由于 r + g + b = 1，因此任意颜色只需要 r、g 两个色度坐标进行描述即可，即色度空间是二维的。

- 一般以 r-g 为色度坐标给出 **RGB 颜色模型的色度图**，如下图所示。其中标准白光位置在 (r = 1/3, g = 1/3) 处。

  <img src="https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSuejNvw8NibeuVBD92p4kq0b1D1n2Vh0rOUa7f4SCzFAdSYCvlnia8vq6JSQZfnKYOicmHNP7Mn4XuL0hg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:33%;" />



### CIE XYZ 颜色模型

​		为解决RGB模型中因为负光混合带来的问题，CIE从数学角度定义了三种标号尊基色XYZ（理论颜色，而非实际颜色）。同时定义了一组输出全部为正的 XYZ颜色匹配函数，指定了描述任何一种光谱颜色所需要的各基色分量，XYZ 颜色匹配函数是基于 RGB 三基色颜色匹配函数的线性组合。

​		CIE XYZ 颜色模型是定义各种颜色的国际标准。

<img src="https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSuej9ZkgXlRQL76tCic890UDcs6yEW1E2MZSibY2cIEvIc2eZEkUlj4tSjkdiav0wDZYYa5V62zG5sDuicg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom: 50%;" />

- X、Y、Z 分别表示生成一种颜色所需的 CIE 基色量的系数。
- 因此，在 XYZ 颜色模型中描述一种颜色的方式与 RGB 模型中是一样的。在三维 XYZ 颜色空间中，任何一种颜色 $C(\lambda)$ 可以表示成： $C(\lambda) = (X,Y,Z)$
  - $$X = k \int_{\text{visible}} f_X(\lambda) I(\lambda) d\lambda$$
  - $$Y = k \int_{\text{visible}} f_Y(\lambda) I(\lambda) d\lambda$$
  - $$Z = k \int_{\text{visible}} f_Z(\lambda) I(\lambda) d\lambda$$
    -  k 的取值为 683 流明/瓦特（lm/W），等于一个均匀点光源在单位主体角内发出的光通量。
    - $I(\lambda)$表示光谱辐射率，即在某一方向上某种光的强度。
    - 彩色匹配函数 $f_Y$ 对应的参数 Y 是颜色的亮度，亮度值的范围一般是 0 到 100.0，其中 100.0 表示白光的亮度。
  - 在 XYZ 颜色空间中任何颜色都可以表示为三个基色的单位向量  $\vec{X}$、$\vec{Y}$ 、$\vec{Z}$  的加性组合，即：$C(\lambda) = X\vec{X} + Y\vec{Y} + Z\vec{Y}$
    - $C(\lambda)$​ 表示彩色光的亮度（luminance），对应颜色的亮度（brightness）特征
    - X、Y、Z 则为三基色比例系数。XYZ 颜色模型表示颜色时满足以下 3 个条件：
      - **X、Y、Z 三色比例系数大于 0；**
      - Y 的数值正好表示光的**亮度**值；
      - **当 X = Y = Z 时，表示标准的白光。**

####  RGB 模型与 XYZ 模型的转换关系

$$
\begin{bmatrix}
X \\
Y \\
Z
\end{bmatrix}
=
\begin{bmatrix}
2.7689 & 1.7517 & 1.1302 \\
1.0000 & 4.5907 & 0.0601 \\
0.0000 & 0.0565 & 5.5943
\end{bmatrix}
\begin{bmatrix}
R \\
G \\
B
\end{bmatrix}
$$

- $x = \frac{X}{X+Y+Z}$，$y = \frac{Y}{X+Y+Z}$，$z = \frac{Z}{X+Y+Z}$

​		我们把 x、y、z 称为色度坐标，由于 x + y + z = 1，任意颜色可仅用 x 和 y 表示。一般以 x-y 为色度坐标给出 CIE XYZ 颜色模型的色度图，**CIE 1931 年的 x-y 色度图**如下所示：

<img src="https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSuej9ZkgXlRQL76tCic890UDcsuibic2ZWeLRibWF2DUQzwlhP7YGuJqloA5NPMDJggOCxTXsROHSqhCO8Q/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:50%;" />

- 曲线上的点是电磁光谱中的纯色
  - 按波长的顺序从光谱的红色端到紫色端方向来标明
  - 连接红色和紫色光谱点的直线称为**紫色线**，它不属于光谱
- 曲线内部的点表示所有可能的可见颜色的组合
  - 其中 C 点对应与 (x = 1/3, y = 1/3) 的位置，表示白色
  - 在实际中，C 点通常作为白光源或日光色度近似值
- 由于归一化的处理，色度图中没有亮度值。所有具有统一色度但不同亮度的颜色都映射到色度图中的同一点。

​		

​		色度图主要用于：

- **为不同基色组比较整个颜色范围；**

  - 可以用直线段或多边形来表示颜色范围

    - 如果用 C1 和 C2 两种颜色作为基色，它们的颜色范围就是它们的连线

      - 如果 C1 占比大，则结果色就更接近 C1

    - 三点 C3、C4、C5 作为三基色的颜色范围是他们连成的三角形区域（包含边上）

      - 三基色只能生成对应三角形区域的颜色

        > 这也是为什么没有哪一个三基色组可以通过加色混合生成所有的颜色，因为没有一个三角形能包含色度图中所有的区域
        >
        > <img src="https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSuej9ZkgXlRQL76tCic890UDcs34gvQAKxgZmcY2KrYsJcepT297Bdoz1cUiaWZJs0BkYXHYWU6vXHYkg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom: 50%;" />

      -  CIE 色度图上可以很容易对比不同颜色标准的颜色范围

        <img src="https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSuej9ZkgXlRQL76tCic890UDcseajicaVg6ibUnZtBGb0mskZ88yh8EvHiaNAedQ5IUMJ7d95HBGB7yATHA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:50%;" />

        > |            | R              | G              | B              |
        > | ---------- | -------------- | -------------- | -------------- |
        > | CIE        | (0.735, 0.265) | (0.274, 0.717) | (0.167, 0.009) |
        > | NTSC 制式  | (0.670, 0.323) | (0.214, 0.710) | (0.140, 0.084) |
        > | PAL 制式   | (0.640, 0.330) | (0.290, 0.600) | (0.150, 0.060) |
        > | 彩色显示器 | (0.628, 0.346) | (0.268, 0.588) | (0.150, 0.070) |

- **标识互补色；**

  - 互补色是两个混合在一起为白色的颜色

  - 色度图上两种基色的颜色范围是一条线段

  - 所以一对互补色在色度图上对应的两个点一定位于白色` C` 点的两边，并且它们的连线经过 `C`

    <img src="https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSuej9ZkgXlRQL76tCic890UDcsZhr7nsWjSKflNCck9l9cshgibC6iaibhEDaR0lXicrlFqAtfRatk9elWfQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom: 25%;" />

- **确定指定颜色的主波长；**

  - 在色度图中确定一种颜色的主波长
  - 从 `C` 通过 `C1` 画一条直线与光谱曲线相交于 `Cs`，这时候就可以认为颜色` C1` 可以表示成白光 `C` 和光谱颜色 `Cs` 的混合，因此 `C1` 的主波长就是 `Cs`
    - 不适用于 `C` 与紫色线之间的颜色点
  - 画一条从 `C` 经过 `C2` 的直线与紫色线相交于 `Cp`，`Cp` 并不在可见光谱中，这种情况下，点 `C2 `称为**非光谱颜色**
    - 它的主波长根据 `Cp` 的补点 `Csp` 得到
    - `Csp` 是从` C` 经过 `C2` 直线的反向延长线与光谱曲线的交点
    - **非光谱颜色是在紫-品红范围内，具有从白光减去主波长（如 `Csp`）的光谱分布。**

  <img src="https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSuej9ZkgXlRQL76tCic890UDcsW4HFqv2NeBYiaBxDzVibCAHPX1V4OzMoN06bZv3Nl7VAd5rsFAKI5CNQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:33%;" />

- **确定指定颜色的饱和度。**

  - 以上图中的 `C1` 颜色为例，我们通过沿 `C` 到 `Cs` 的直线计算 `C1` 到 `C` 的相对位置来确定饱和度。
  - 如果` dC1` 表示从 `C` 到 `C1` 的距离，且 `dCs` 表示 `C` 到 `Cs` 的距离
  - 可以按比率 `dC1/dCs` 来计算饱和度
  - 在上图中，颜色` C1` 的纯度大概是 `25%`，因为它位于` C` 到 `Cs` 全程大约四分之一处。在 `Cs` 处颜色的饱和度为 `100%`



### NTSC YIQ 颜色模型

​		RGB 工业显示器要求一幅彩色图像由分开的 R、G、B 信号组成，而电视显示器则需要混合信号输入。NTSC（美国国家电视系统委员会）制定了 『YIQ 颜色模型』，实现对彩色电视和黑白电视的兼容，即可以用黑白电视收看彩色电视信号。

​		YIQ 颜色模型是以 CIE XYZ 颜色模型为基础来定义的

- 参数 Y 与 XYZ 模型中的参数 Y 相同，表示图像的亮度信息
  - 在没有色度的情况下，Y 也就对应于黑白图像，或者说黑白电视只接收 Y 信号
- 参数 I 包含有橙-青颜色信息，提供鲜艳色彩的明暗度
- 参数 Q 包含绿-品红颜色信息

​		NTSC 组合颜色信号的设计允许黑白电视机从一幅占 6 MHz 带宽的图像信息中提取所需的灰度信息，因此，YIQ 信息必须在 6 MHz 带宽限制下编码。亮度值和色度值用不同的模拟信号进行编码，这样只是在原来的带宽内增加了颜色信息，黑白电视机仍然可以按原来的方式取得原样的亮度信号。亮度信息（Y 值）以调幅的方式用带宽约为 4.2 MHz 的载波传输；色度信息（I、Q 值）被结合在一起用带宽约为 1.8 MHz 的载波传输。参数名称 I、Q 指的就是用来在载波上编码颜色信息的调制方法。在 NTSC 信号中，亮度信息（4.2 MHz 带宽）的编码精度高于色度信息（1.8 MHz 带宽），这是因为**人眼对亮度的变化比对色度的变化更敏感**。因此，NTSC 用较低的精度传输色度信息并没有造成图像颜色质量的明显下降。

#### YIQ 可以与 RGB 之间转换

​		这里的 R、G、B 是经过伽马校正的，表示为 R’、G’、B’。

YIQ 的亮度信号 Y 为： $$Y' = 0.299R' + 0.587G' + 0.114B'$$

YIQ 规定的色差信号如下：  $I' = 0.74(R' - Y') - 0.27(B' - Y') $  ，Q' = 0.48(R' - Y') + 0.41(B' - Y')$

 		映射到色度图上，也可以发现参数 I 包含有橙-青颜色信息，参数 Q 包含有绿-品红颜色，I 和 Q 混合可以提高颜色的色调和饱和度。根据上面算式即可得到 YIQ 与 R’G’B’ 之间的转换矩阵为： 
$$
\begin{bmatrix}
Y' \\
I' \\
Q'
\end{bmatrix}
=
\begin{bmatrix}
0.299 & 0.587 & 0.114 \\
0.596 & -0.274 & -0.322 \\
0.211 & -0.523 & 0.312
\end{bmatrix}
\begin{bmatrix}
R' \\
G' \\
B'
\end{bmatrix}
$$

$$
\begin{bmatrix}
R' \\
G' \\
B'
\end{bmatrix}
=
\begin{bmatrix}
1.000 & 0.956 & 0.621 \\
1.000 & -0.272 & -0.647 \\
1.000 & -1.106 & 1.703
\end{bmatrix}
\begin{bmatrix}
Y' \\
I' \\
Q'
\end{bmatrix}
$$

- $$R'/G'/B' \in [0, 255];$$
- $$Y' \in [0, 255];$$
- $$I' \in [-152, 152];$$
- $$Q' \in [-134, 134]$$



### PAL YUV 颜色模型

​		NTSC YIQ 的组合模拟视频信号中分配给色度信息的带宽较低，所以 NTSC YIQ 图像的颜色质量会受到一些影响。『YUV 颜色模型』是一种变体，它为 PAL 广播制式提供视频传输的组合颜色信息，它可以用不同的采样格式来调整传输的色度信息量。

​		YUV 颜色模型中用亮度、色度来表示颜色。亮度信息和色度信息分离，其中 Y 表示亮度通道，U 和 V 则表示色度通道。

- 如果只有 Y 信息，没有 U、V 信息，那么表示的图像就是灰度图像。
- YUV 常用在各种影像处理场景中。
- YUV 在对照片或视频编码时，考虑到人眼对亮度信息的敏感度高于色度信息，允许降低色度的带宽。



####  YUV 与 RGB 的转换

​		R、G、B 是经过伽马校正的，表示为 R’、G’、B’

- $$Y' = 0.299R' + 0.587G' + 0.114 \times B'$$
- $$U' = -0.147R' - 0.289G' + 0.436 \times B' = 0.492(B' - Y')$$
- $$V' = 0.615R' - 0.515G' - 0.100 \times B' = 0.087(R' - Y')$$

​		换成矩阵运算表示： 
$$
\begin{bmatrix}
Y' \\
U' \\
V'
\end{bmatrix}
=
\begin{bmatrix}
0.299 & 0.587 & 0.114 \\
-0.147 & -0.289 & 0.436 \\
0.615 & -0.515 & -0.100
\end{bmatrix}
\begin{bmatrix}
R' \\
G' \\
B'
\end{bmatrix}
$$
$$
\begin{bmatrix}
R' \\
G' \\
B'
\end{bmatrix}
=
\begin{bmatrix}
1.000 & -0.000 & -1.140 \\
1.000 & -0.395 & -0.581 \\
1.000 & 2.032 & 0.000
\end{bmatrix}
\begin{bmatrix}
Y' \\
U' \\
V'
\end{bmatrix}
$$

- $$R'/G'/B' \in [0, 255];$$
- $$Y' \in [0, 255];$$
- $$U' \in [-112, 112];$$
- $$V' \in [-157, 157]$$

​		在实际使用中，上面的方程式通常会被缩放处理来简化 PAL 制式数字信号的编解码实现



### ITU-R YCbCr 颜色模型

​		`YCbCr `颜色模型是目前广泛使用的一种 `YUV `变体，它是为数字视频转换而设计的颜色模型。`YCbCr `由` ITU-R`（国际电信联盟无线电通信部门，前身是国际无线电咨询委员会 `CCIR`）在 `ITU-R BT.601` 首次制定，并在后续的 `ITU-R BT.709`、`ITU-R BT.2020` 等标准中都有涉及。

>  ITU-R BT.601/709/2020 系列标准，规定了彩色视频转换成数字图像时使用的采样率，RGB 和 YCbCr 两个彩色模型之间的转换关系等，它们分别面向标清电视（SDTV）、高清电视（HDTV）、超清电视（UDTV）应用场景。
>
> 对应的色域的 RGB 三基色以及白色点在 CIE 1931 x-y 色度图的坐标分别是：
>
> |                     | R              | G              | B              | 白色 D65         |
> | ------------------- | -------------- | -------------- | -------------- | ---------------- |
> | ITU-R BT.601/625 行 | (0.640, 0.330) | (0.290, 0.600) | (0.150, 0.060) | (0.3127, 0.3290) |
> | ITU-R BT.601/525 行 | (0.640, 0.340) | (0.310, 0.595) | (0.155, 0.070) | (0.3127, 0.3290) |
> | ITU-R BT.709        | (0.640, 0.330) | (0.300, 0.600) | (0.150, 0.060) | (0.3127, 0.3290) |
> | ITU-R BT.2020       | (0.708, 0.292) | (0.170, 0.797) | (0.131, 0.046) | (0.3127, 0.3290) |
>
> <img src="https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSuej9ZkgXlRQL76tCic890UDcskVlGJEgrrcQlCneJGhXt0bHWagoEofCTuWkIicM9qoMYHKZgxchGTIQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:50%;" />

​		`YCbCr `不是一种绝对颜色模型（绝对颜色模型是指不依赖任何外部因素就可以准确表示颜色的模型），而是在 `YUV `颜色模型的基础上经过缩放和偏移的版本。

- 其中 `Y `与 `YUV `中 `Y` 的含义一致，表示亮度；
- `Cb、Cr `与` U、V `一样都表示色度，只不过在表示方法上不同而已
  - `Cb `反映的是 `RGB `输入信号蓝色部分与 `RGB `信号亮度值之间的差值
  - `Cr `则反映的是红色部分与亮度之间的差值



#### YCbCr采样格式

​		常见的 YCbCr 的采样格式有：

- **4:4:4**：表示完整采样，保持了 CbCr 分量的完整信息。

  <img src="https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSuej9ZkgXlRQL76tCic890UDcs9Wvs8BU97Ag8G8ibtZVJTzZGtibanoBwuX3pzmFbwVsZwdHQKyR05icuA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom: 50%;" />

- **4:2:2**：表示 CbCr 分量具有 2:1 的水平采样，垂直完全采样。相对于完整信息压缩了 **33.3%** 的数据量。

  <img src="https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSuej9ZkgXlRQL76tCic890UDcsuywWYicPwMAdfUhWuNlSUP2JuI47Mkb50IQE9BaxmuZeRx1YTl1GPEA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:50%;" />

- **4:1:1**：表示 CbCr 分量具有 4:1 的水平采样，垂直完全采样。相对于完整信息压缩了 **50%** 的数据量。

  <img src="https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSuej9ZkgXlRQL76tCic890UDcs5Ns3via51RVWxInqdIic9k9OWt1DdSMM9xiaIyA1ib77xpKLyNjWxGkDicg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:50%;" />

- **4:2:0**：表示 CbCr 分量具有 2:1 的水平采样，2:1 的垂直采样，这里并不是指只有 Cb，没有 Cr，而是对于每一行，只有一个 Cb 或者 Cr 分量，如果第一行是 4:2:0，那么下一行就是 4:0:2，以此类推。相对于完整信息压缩了 **50%** 的数据量。

  <img src="https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSuej9ZkgXlRQL76tCic890UDcsa1HZqiaGlnGQxSyic73NtmrKPcaLpicqTak9hUw9RJ9N1mJhhkx4jsIlg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:50%;" />

  <img src="https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSuej9ZkgXlRQL76tCic890UDcsDL293E3VobzkFweg7GwcfxMye55LXNnw8PaXhQPUOz7lnNDcugYFWQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:50%;" />

  <img src="https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSuej9ZkgXlRQL76tCic890UDcsu2hroMMdImicdgklIr1PvcmouRCJnOpVxPvUgGFdiaqSlyAbx1rjQbAA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:50%;" />

  <img src="https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSuej9ZkgXlRQL76tCic890UDcsmITukJpkiao3DQ1Wzc5pZX4DiaepjkIH0hhG4VqSBMGrUmiaykGqqkQ2Q/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:50%;" />

#### **YCbCr 存储格式**

​		在 YCbCr 中常见的存储格式一般分为两种：

- **平面格式（planar）**：先连续存储所有像素点的 Y，紧接着存储所有像素点的 Cb、Cr。
- **紧缩格式（packed）**：每个像素点的 Y、Cb、Cr 是连续交叉存储的。

​		有时候，平面格式和紧缩格式会混合使用。

​		我们经常听到的 `I420`、`YV12`、`NV12`、`NV21 `等名词其实就对应着 `YCbCr `各分量的存储方式。它们都属于` 4:2:0` 采样格式，只是按存储方式又分为两大类：

- **420P（planar）平面格式**，`I420 `和 `YV12 `属于此类。
- **420SP（simi-planar）混合格式**，`NV12 `和 `NV21 `属于此类。

<img src="https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSuej9ZkgXlRQL76tCic890UDcsK7zibExUeick99bjDYMZt67g9NXN5OoYx9L3FWSiadXop4iclcBKBmb1Zg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom: 67%;" />

#### **SDTV 的 YCbCr 与 RGB 的转换**

​		R、G、B 是经过伽马校正的，表示为 R’、G’、B’

- $$Y_{601}' = 0.299R' + 0.587G' + 0.114 \times B'$$
- $$C_b = -0.172R' - 0.339G' + 0.511 \times B' + 128$$
- $$C_r = 0.511R' - 0.428G' - 0.083 \times B' + 128$$

​		换成矩阵运算

- 视频亮度/色度分离技术

$$
\begin{bmatrix}
Y_{601}' \\
C_b \\
C_r
\end{bmatrix}
=
\begin{bmatrix}
0.299 & 0.587 & 0.114 \\
-0.172 & -0.339 & 0.511 \\
0.511 & -0.428 & -0.083
\end{bmatrix}
\begin{bmatrix}
R' \\
G' \\
B'
\end{bmatrix}
+
\begin{bmatrix}
0 \\
128 \\
128
\end{bmatrix}
$$

- 视频亮度/色度混合技术

$$
\begin{bmatrix}
R' \\
G' \\
B'
\end{bmatrix}
=
\begin{bmatrix}
1.000 & 0.000 & 1.371 \\
1.000 & -0.336 & -0.698 \\
1.000 & 1.732 & 0.000
\end{bmatrix}
\begin{bmatrix}
Y_{601}' \\
C_b - 128 \\
C_r - 128
\end{bmatrix}
$$

名义上，R’、G’、B’ 和 Y、Cb、Cr 的取值范围为：

-  $$R'/G'/B' \in [16, 235];$$
- $$Y' \in [16, 235];$$
- $$C_b/C_r \in [16, 240]$$

> ​		当进行 Y、Cb、Cr 到 R’、G’、B’ 的转换时，R’、G’、B’ 名义上的范围是 16-235，但也有可能会得到 0-15 和 236-255 的值。这是由于视频数据处理或者噪音的原因会导致 Y 和 CbCr 的取值可能落入 16-235 和 16-240 之外。所以，我们在数据处理时，还是要给予他们 0-255 的数值空间，以防止溢出问题。
>
> ​		在计算机系统中，如果可以保证 R’G’B’ 的取值范围为 0-255，则用下面的转换矩阵会更方便：
> $$
> \begin{bmatrix}
> Y_{601}' \\
> C_b \\
> C_r
> \end{bmatrix}
> =
> \begin{bmatrix}
> 0.257 & 0.504 & 0.098 \\
> -0.148 & -0.291 & 0.439 \\
> 0.439 & -0.368 & -0.071
> \end{bmatrix}
> \begin{bmatrix}
> R' \\
> G' \\
> B'
> \end{bmatrix}
> +
> \begin{bmatrix}
> 16 \\
> 128 \\
> 128
> \end{bmatrix}
> $$
>
> $$
> \begin{bmatrix}
> R' \\
> G' \\
> B'
> \end{bmatrix}
> =
> \begin{bmatrix}
> 1.164 & 0.000 & 1.596 \\
> 1.164 & -0.391 & -0.813 \\
> 1.164 & 2.018 & 0.000
> \end{bmatrix}
> \begin{bmatrix}
> Y_{601}' - 16 \\
> C_b - 128 \\
> C_r - 128
> \end{bmatrix}
> $$
>
> $R', G', B'$ 和 $Y, C_b, C_r$ 的取值范围为：
>
> - $$R'/G'/B' \in [0, 255]$$
> - $$Y \in [16, 235]$$
> - $$C_b/C_r \in [16, 240]$$

 

#### **HDTV 的 YCbCr 与 RGB 的转换**

​		当 R’、G’、B’ 名义上的范围是 16-235 时，YCbCr 与 RGB 的转换矩阵为： 
$$
\begin{bmatrix}
Y_{709}' \\
C_b \\
C_r
\end{bmatrix}
=
\begin{bmatrix}
0.213 & 0.715 & 0.072 \\
-0.117 & -0.394 & 0.511 \\
0.511 & -0.464 & -0.047
\end{bmatrix}
\begin{bmatrix}
R' \\
G' \\
B'
\end{bmatrix}
+
\begin{bmatrix}
0 \\
128 \\
128
\end{bmatrix}
$$

$$
\begin{bmatrix}
R' \\
G' \\
B'
\end{bmatrix}
=
\begin{bmatrix}
1.000 & 0.000 & 1.540 \\
1.000 & -0.183 & -0.459 \\
1.000 & 1.816 & 0.000
\end{bmatrix}
\begin{bmatrix}
Y_{709}' \\
C_b - 128 \\
C_r - 128
\end{bmatrix}
$$

以上，$R', G', B'$ 和 $Y, C_b, C_r$ 的取值范围为：

- $$R'/G'/B' \in [16, 235]$$
- $$Y \in [16, 235]$$
- $$C_b/C_r \in [16, 240]$$
  

> 在计算机系统中，如果可以保证 R’G’B’ 的取值范围为 0-255，则用下面的转换矩阵会更方便： 
> $$
> \begin{bmatrix}
> Y_{709}' \\
> C_b \\
> C_r
> \end{bmatrix}
> =
> \begin{bmatrix}
> 0.183 & 0.614 & 0.062 \\
> -0.101 & -0.338 & 0.439 \\
> 0.439 & -0.399 & -0.040
> \end{bmatrix}
> \begin{bmatrix}
> R' \\
> G' \\
> B'
> \end{bmatrix}
> +
> \begin{bmatrix}
> 16 \\
> 128 \\
> 128
> \end{bmatrix}
> $$
>
> $$
> \begin{bmatrix}
> R' \\
> G' \\
> B'
> \end{bmatrix}
> =
> \begin{bmatrix}
> 1.164 & 0.000 & 1.793 \\
> 1.164 & -0.213 & -0.534 \\
> 1.164 & 2.115 & 0.000
> \end{bmatrix}
> \begin{bmatrix}
> Y_{709}' - 16 \\
> C_b - 128 \\
> C_r - 128
> \end{bmatrix}
> $$
>
> R’、G’、B’ 和 Y、Cb、Cr 的取值范围为：
>
> - $$R'/G'/B' \in [0, 255]$$
>
> - $$Y \in [16, 235]$$
>
> - $$C_b/C_r \in [16, 240]$$

 

### 伽马校正

​		阴极射线管（CRT）显示设备的显示原理是使用一个电压轰击它的屏幕来发光以展示图像。人们在使用 CRT 时发现它有一个问题：调节电压为原来的 n 倍，对应的屏幕发光亮度并没有提高 n 倍，而是一个类似幂律曲线的关系，其公式粗略表示为： $V_{out} = V_{in}^\gamma$

​		典型的 CRT 显示器产生的亮度约为输入电压的 2.2 次幂，即在上述公式中 γ 为 2.2，这个称为**显示伽马（display gamma）**。

​		由于显示伽马问题的存在，在将图像输入到显示器之前需要对应的进行一个**伽马校正（gamma correction）**，以使得最终显示出来的图像亮度与捕捉到的真实场景的亮度是成线性比例关系的。这里的伽马处理叫做**编码伽马（encoding gamma）**。

​		这个处理过程通常是在图像采集设备的电路中完成的，比如对于 TV 摄像机，需要将感知到的亮度 Y 通过以典型的数值 1/γ = 0.45 做逆伽马重新映射：$Y' = Y^\frac{1}{\gamma}$

<img src="https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSuejkg4FuPhQSvvezR87YRbYzYia0xN1lz3I1hglPaDtdyQdA2F3TicAxupyg7EU3iaDgcg1tITrfQUItA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:50%;" />

​		伽马校正的非线性转换的过程除了解决显示伽马的问题外，还带来了一个**有益的副效应**：传输期间增加的噪声（模拟信号时代），在噪声比较明显的较暗信号区域（在接收器做了伽马校正后）会被减少。因为我们的视觉系统对相对亮度差别是敏感的，如下图所示，经过伽马校正后的非线性梯度明显对人眼感知来说更均匀：

<img src="https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSuejkg4FuPhQSvvezR87YRbYz90J8zhRlelNCG0JtDjt6LZicgoymRQvRaxtUG3D9SMzDJIPF6Wyqzeg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:50%;" />

​		彩色电视发明后，R、G、B 信号会被分别做完伽马校正后再合起来编码（这也就是我们前文中表示的 R’、G’、B’）。

​		到如今，尽管在传输系统中我们不再有模拟噪声，但信号压缩时仍然需要量化，因此在传感数据上做伽马校正仍然是有用的。

​		不过，在计算机视觉的一些图像处理场景，需要图像的亮度信息在线性空间中才能进行，这时候则需要撤销伽马校正后再进行处理。在处理完成后，将图像输入显示器之前可能需要再重新做伽马校正。

​		所以，一个完整的图像获取和显示系统，需要至少两个伽马值：1）编码伽马（encoding gamma），体现了设备获取到的场景亮度值和编码像素值之间的关系；2）显示伽马（display gamma），体现了编码像素值和显示器亮度之间的关系。

​		编码伽马（encoding gamma）和显示伽马（display gamma）的乘积就是整个图像系统的**端到端伽马（end-to-end gamma）**。如果这个乘积为 1，那么显示出来的图像亮度与捕捉到的真实场景的亮度就是成线性比例的。

当你的显示器已校准为 2.2 的标准伽马时，下图展示了在编码伽马确定时，不同显示伽马对系统端到端伽马的影响以及对最终图像展示效果的影响：

![图片](https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSuejkg4FuPhQSvvezR87YRbYziazlDPnZB3EEUThLSGjxeRtqRZu1vBbtzvQkKwxVTuGF70ZQVe1adiaw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



​		上面提到过，显示伽马是 CRT 显示器带来的问题，如今我们已经基本告别 CRT 显示器普遍使用 LCD 显示器了，那显示伽马的问题是不是就没有了呢？事实上，LCD 显示器本身确实没有 CRT 显示器的伽马效应，但是为了兼容性，LCD 以及其他非 CRT 显示设备都模拟了这个伽马效应以实现先前兼容。



## 数字图像

​		图像数字化的流程，细节是很复杂的，探讨一下最简单的理论环节，建立一个初步的概念。

<img src="https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSuejkg4FuPhQSvvezR87YRbYzYiaEb4I1XxuicuSTeF1JWQq1TzG0bEsRG55DWialh5ibIe5fRIK3GeQoUw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom: 50%;" />

​		图像的数字化跟声音的数字化也类似，最终都是要把模拟信号转换为数字信号，这种转换包括两种处理过程：**采样**和**量化**。

​		为了产生一幅数字图像，我们需要把连续的感知数据转换为数字形式。

- 一幅平面图像中各个点的颜色值可以用其位置坐标 (x, y) 的函数 f(x, y) 来描述。
- 由于图像的 x、y 坐标和颜色值可能都是连续的，f(x, y) 作为二维连续函数，会有无穷多个取值。
- 用连续函数表示的图像无法用计算机进行处理，也无法在各种数字系统中传输和存储，所以必须在坐标值和颜色值上将连续的模拟信号转换为离散的数字信号。
- **对坐标值的数字化称为采样，对颜色值的数字化称为量化。**

​		<img src="https://mmbiz.qpic.cn/mmbiz_jpg/gUnqKPeSuejkg4FuPhQSvvezR87YRbYzWO15cIwu4RU455eLE8n6WnlVtBXOdLMzCa52rtOlJcfxnpG93WkFicg/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:67%;" />

> ​		上图是生成一幅数字图像的简化过程
>
> - 右上角图中的一维函数是左上角图中沿线段 AB 的连续图像幅度值（灰度级）的曲线。随机变化是由图像噪声引起的。
> - 为了对该函数采样，我们沿线段 AB 等间隔的对函数进行采样，如左下角图中所示，每个样本的空间位置由图像底部的垂直刻度指出，样本则由函数曲线上的小方块表示。
> - 这样的一组离散位置就给出了采样函数。
> - 但是，样本值仍跨越了灰度值的连续范围。为了形成数字函数，灰度值也必须转换为离散量，图中显示了已经分为 8 个离散区间的灰度标尺，范围从黑到白。垂直刻度标尺赋予了 8 个灰度各自的特定值，通过对每一样本赋予 8 个离散灰度级中的一个，来量化连续灰度级赋值多少取决于该样本与哪个垂直刻度标记更接近。
> - 通过采样和量化，就生成了右下角图中的数字样本。如果我们从该图像的顶部到底部逐行执行这一过程，则会产生一幅二维数字图像。

​		得到的数字图像，我们怎么展示它呢？

<img src="https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSuejkg4FuPhQSvvezR87YRbYzicEsl6s9IEHETicqP1ksHZh2PEcUhqbefANZOP2llYkr030LEwUF4apg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:50%;" />



​		延用上面提到的 f(x, y) 函数表示法的，上图展示了 3 种数字图像的基本展示方式：

1. 第一种用两个坐标轴 x、y 决定空间位置，第三个坐标轴决定 x、y 对应的灰度值。
   1. 这种展示法对于细节太多的复杂图像来说很难理解。
2. 第二种是更一般的展示方法，它显示了图像出现在显示器的情况，这里每个点的灰度与该点处 f 值成正比。
   1. 比如图中如果仅由三个等间隔且归一化到 [0, 1] 区间的灰度值时，那么图像中的每个点的灰度是 0、0.5、1 中的某一个值，在显示器上就简单的把这三个值变换成黑色、灰色、白色即可。
   2. 这种展示法可以让我们快速的观察图像结果。
3. 第三种则是将 f(x, y) 的数值简单地展示为一个矩阵。
   1. 这种展示法打印起来麻烦，而且传达的信息也不多，但是在开发图像相关的算法需要做数值分析时就非常有用了。
   2. 其中，矩阵中的每个元素我们称为**像素（图像单元、图像元）**。

​		所以，上面第二种和第三种数字图像的展示方式是最有用的，第二种允许我们快速观察结果，第三种则可用于数值处理和算法开发。

​		经过数字化处理后的图像包含如下几个基本属性：

- **图像分辨率**
- **像素深度**



### 图像分辨率

​		图像分辨率也称为**空间分辨率**，表示图像中可辨别的最小细节的度量。空间分辨率有很多方法来说明，其中最通用的是**单位距离线对数**和**单位距离点数（像素数）**。

- 单位距离线对数可以这样来理解：假设我们用交替的黑色和白色垂直线来构造一幅图像，如果一条线宽是 0.1 mm，每单位距离（mm）就有 5 个线对（10 条黑白交替的线）。
- 单位距离点数是印刷和出版业中常用的图像分辨率的度量。在美国，这一度量常用**每英寸点数（dpi）**来表示，比如，报纸用 75 dpi 的分辨率来印刷，书页用 2044 dpi 印刷。

​		单位距离像素数常用在电子设备上。比如我们常常会听到用**每英寸像素数（ppi）**来衡量显示屏的成像分辨率，比如 iPhone 4 使用 326 ppi 的屏幕，iPhone 13 Pro Max 则使用 458 ppi 的屏幕。

下图是图像使用不同空间分辨率时的展示效果：

<img src="https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSuejkg4FuPhQSvvezR87YRbYzVIjhmEzJibvZic4gXyOSeuKibErVfnMovuruW5TJUhxZia3KyLCOJOVd5w/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:50%;" />

### 像素深度

​		像素深度决定了图像每个像素的颜色级数。对于灰度图像，则决定了每个像素的灰度级数。像素深度通常是 2 的整数次幂，比如，当像素深度为 24 位时，那么每个像素的颜色可以是 16777216（224）种颜色中的一种。

​		提高像素深度，每个像素能显示的颜色种类也就更多了，图像也就更细腻自然。但受到人眼分辨率的限制，像素深度不一定要特别大，人类眼睛感知的颜色种类的上限大概是 1000 万种颜色，24 位的颜色深度已经完全够用。

​		下图是灰度图像使用不同灰度级数时的展示效果：

<img src="https://mmbiz.qpic.cn/mmbiz_png/gUnqKPeSuejkg4FuPhQSvvezR87YRbYzqZC3kaa1ic4ozZAsTvnBKD3EqKoNmROQksxQoCs7K4bsZMH8hh0ZJAQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:50%;" />

## 图像表示

​		在手机、电脑上处理的图像数据，也就是经过数字化处理后的**数字图像数据**。

> ​		在音视频开发中，处理最多的图像数据其实是 `RGB`、`YCbCr `数据，在前面的文章里我们已经详细介绍过这两种颜色模型。
>
> - `RGB `数据主要是用于屏幕显示
> - `YCbCr `数据则由于较好的压缩性，则主要用于图像数据处理、编码、传输。
>
> ​      它们之间的转换，则需要根据具体使用的颜色模型标准、采样格式及存储格式借助转换矩阵来实现。



​		图像有两种色彩成像原理：自发光物体的RGB色彩空间，和基于人眼成像原理的YUV色彩空间。

- 光源成像（RGB）：白光能被分解为三原色，红光（R）、绿光（G）、蓝光（B），即RGB。等量的三原色光叠加会变为白光
  - 电子设备显像是自发光的，不同于其他自然物体是由于反射日光
  -  RGB主要用于电子显示设备（如电脑显示器、电视、数字摄影等），因为这些设备的发光原理与RGB模型相符
- 人眼成像（YUV）：人眼对亮度变化更敏感，对色度变化感知较弱
  - RGB模式下的图像数据通常较大，特别是对于高分辨率视频，这可能导致带宽需求很高
  - YUV将亮度分量与色度分量分开，UV可以采用色度子采样来减少数据量
    - 保持亮度分量的高分辨率的同时降低色度分量的分辨率
    - 适合于视频流媒体、电视广播、视频压缩（如MPEG、H.264）等需要处理和传输大量数据的场景
  - 人的视网膜有对红、绿、蓝颜色敏感程度不同的三种锥体细胞
    - 红、绿和蓝三种锥体细胞对不同频率的光的感知程度不同，对不同亮度的感知程度也不同
      - 红、绿和蓝三种锥体细胞对不同频率的光的感知程度不同，对不同亮度的感知程度也不同。

​		所以电子设备展示图像时有两个概念，一个是电子设备的物理像素块（RGB），二是图像数据的逻辑像素块（YUV / RGB）。电子设备展示图像时，图像数据的逻辑像素块经过驱动程序的转换让电子设备的物理像素块显示图像。

> 如果程序渲染时没有显式将YUV转换为RGB，意味着显卡或其他渲染组件隐式进行了转换。





### RGB:  电子设备图像表示

​		显示器(RGB)的每个像素点背后都有三个发光二极管组成，即三个通道，每个通道按照位深，显示不等量的三原色，这些色点紧邻且小人眼无法分辨而将其混合，从而构成该像素点的颜色。

​		RGB表示上，除了红绿蓝三个色彩通道，还有一个透明度通道（alpha分量， ARGB）

​		每个通道上，按照一定的规则来定义对应颜色的分级。RGB通道的分级数值表示组成一个像素点的数据格式

- 浮点表示：`0/0~10`，OpenGL ES中每个通道点的表示使用这种方式

- 整数表示：`RGB_8888`,``0~255``或``00~FF``,8位表示一个分量通道上的值。即8位位深度

  - 一些平台上采用其他的整数表示方式

    - 如Android采用`RGB_565`共`16bit`来表示一个像素

    - `RGB_8888` 表示的`1280X720`的图像大小为：`1280 x 720 x 4byte=3.516MB`

      > 这也是位图（bitmap）在内存中所占用的大小，所以每一张图像的裸数据都是很大的

​		RGB像素点中各个分量通常是按照顺序排列的，但有些图像处理要转换成其他的顺序，`opencv`经常转换成BGR的排列方式。

![image-20220907235455776](https://raw.githubusercontent.com/Mocearan/picgo-server/main/image-20220907235455776.png)

		一般称24bit以上位深的色彩为真彩色，当然还有采用30bit、36bit、42bit的。使用的色彩代码越长，同样像素的文件的文件大小也就相应的成幂次级增长。使用超过16位以上的色彩文件在普通的显示器，尤其是液晶显示器上看不出任何区别，原因是液晶显示器本身不能显示出那么多的色彩。但是对于彩色印刷就非常有用，因为油墨的点非常的细，同时由于印刷尺幅的放大原因， 更大的文件可以在印刷的时候呈现出更细腻的层次和细节。

![img](https://raw.githubusercontent.com/Mocearan/picgo-server/main/ed2a79d16be7aa56aea066d248e04421.png)



### YUV(YCbCr):  数字图像表示

​		人眼对亮度敏感而对色度不敏感。因而可以将亮度信息和色度信息分离，以这样“欺骗”人的眼睛的手段来节省空间，从而适合于图像处理领域，从而提高压缩效率。

​		与 RGB 相比，YUV 在响应亮度信息方面更为准确，同时去除了人眼感知中色度无关的特性，使得相对于 RGB，它具有更高的压缩性能，更适合于视频传输或存储。

- Y，明亮度（Luminance或Luma），也称灰阶值

  - 亮度是通过RGB输入信号来建立的概念
  - 方法是将RGB信号的特定部分叠加到一起。

- U / V，色度（Chrominance或Chroma）

  - U表示蓝色色度的信息，V表示红色色度的信息

    - 绿色的色度信息通常是通过蓝色（U）和红色（V）的差值来表示的。

      > 因为人眼对绿色的感知更为敏感，所以通过差值编码可以更有效地表示绿色色度信息，同时减少数据量和保持图像质量。

  - 描述影像的色彩（Cr）及饱和度（Cb），用于指定像素的颜色

  - Cr反映了RGB输入信号红色部分与RGB信号亮度值之间的差异

  - Cb反映的则是RGB输入信号蓝色部分与RGB信号亮度值之间的差异

​		用灰度图来描述图像亮度变化，然后再灰度图上叠加色度图来渲染颜色。同时降低色度的采样率而不会对图像质量影响太大，降低了视频信号传输时对频宽（带宽）的要求。

- 如果只有Y信号分量而没有U、V分量，那么这样表示的图像就是黑白灰度图像。

  - 黑白电视的原理是只有亮度信号
  - 使用YUV能够兼容黑白电视

- 分离亮度和色度的方式有助于视频编码和压缩。

  > 因为人眼对亮度变化更敏感，而对颜色变化的敏感度较低。
  >
  > 因此，通过将图像的色度信息分开编码，减少色度采样，可以降低数据量同时保持图像质量。

- 最常用的表示形式是Y、U、V都使用8个bit来表示

  - 取值范围就是``0～255``

    > 为了防止信号变动造成过载，在广播电视系统中不传输很低和很高的数值。把边界的数值作为“保护带”。
    >
    > 不论是Rec.601还是BT.709的广播电视标准中，Y的取值范围都是16～235, UV的取值范围都是16～240。

- 很早之前在绘画界就有了先用灰色颜料描绘亮度变化，然后再上色的技法

  - 这与灰度图叠加色度图的原理是一致的

​		

​		YCbCr 其实是 YUV 经过缩放和偏移的翻版。其中 Y 与 YUV 中的 Y 含义一致, Cb，Cr 同样都指色彩, 只是在表示方法上不同而已。在 YUV 家族中, YCbCr 是在计算机系统中应用最多的成员，其应用领域很广泛，JPEG、MPEG 均采用此格式。一般人们所讲的 YUV 大多是指YCbCr。

-  **Cb（相当于U ，blue）：**反映的是 RGB 输入信号蓝色部分与 RGB 信号亮度值之间的差异。
-  **Cr（相当于V ，red）：**反映了 RGB 输入信号红色部分与 RGB 信号亮度值之间的差异。

```c
\\ 公式 并不是固定的， 不同的RGB的格式，转换的的公式也是不一样的
\\ RGB 转换为 Ycbcr 公式

Y = 0.257*R+0.564*G+0.098*B+16
Cb = -0.148*R-0.291*G+0.439*B+128
Cr = 0.439*R-0.368*G-0.071*B+128

\\ Ycbcr 转换为 RGB 公式

R = 1.164*(Y-16)+1.596*(Cr-128)
G = 1.164*(Y-16)-0.392*(Cb-128)-0.813*(Cr-128)
B = 1.164*(Y-16)+2.017*(Cb-128)
```

​		**使用YUV的优点有两个:** 

- 彩色YUV图像兼容黑白YUV图像。 只保留Y亮度分量就是黑白灰度图像。
- YUV是数据总尺寸小于RGB格式
  - 减少颜色分量，减少体积



#### YUV的采样格式

​		YUV采用`A:B:C`表示法来描述Y、U、V采样频率的关系。

​		对非压缩的`8 bit`量化的采样数据来说，每个分量占一个字节（char或byte）。为节省带宽，大多数 YUV 格式平均使用的每像素位数都少于`24 bit`。

​		YUV采样时，将水平连续两个像素，垂直两行的两个像素，共4个像素看做一个宏像素块（macro-pixel)来进行共同采样，其中每个像素中都采集亮度分量Y，色度分量UV（cr/cb，红色分量和蓝色分量）的同比例采样，但与亮度分量的采样比例不同。从而产生了不同的YUV的数据存储格式。

![image-20240828223910705](https://raw.githubusercontent.com/Mocearan/picgo-server/main/image-20240828223910705.png)

- `YUV444`：`(4*8 + 4*8 + 4*8) / 4 = 24 bit`
  - 每个像素中都采集色度分量
  - 和`RGB`大小一样
- `YUV422`：`(4*8 + 2*8 + 2*8) / 4 = 16 bit`
  - `2:1`水平色度采样，即水平的两个像素中采集一个的色度，即隔列采集
  - `1:1`垂直色度采样，即垂直的两个像素都采集色度，即按行采集
  - 比RGB小1/3
- `YUV420`：`(4*8 + 1*8 + 1*8) / 4 = 12 bit`
  - `2:1`水平色度采样，即水平的两个像素中采集一个的色度，即隔列采集
  - `2:1`垂直色度采样，即垂直的两个像素中采集一个的色度，即隔行采集
  - 比RGB小半



#### YUV的存储格式

##### packed 打包格式

​		也称交错模式，每个像素点为单位的Y、U、V分量视作一个`packed`，以像素点为单元连续存储数据。

> ​		之所以称为交错模式，是因为不同采样格式下，YUV的数据量不同，亮度色度要进行的处理也不同，但存储时不加说明的以流式写入同一存储，需要读取时交错读取处理。

![image-20220908211732290](https://raw.githubusercontent.com/Mocearan/picgo-server/main/image-20220908211732290.png)

##### planar 平面格式

​		将Y、U、V分量数据分别存储在不同的存储块中。

> 不同格式处理时，只需按比例从不同的存储中读出相应大小的数据即可恢复像素点。															

![image-20220908211748811](https://raw.githubusercontent.com/Mocearan/picgo-server/main/image-20220908211748811.png)

![image-20220908221051838](https://raw.githubusercontent.com/Mocearan/picgo-server/main/image-20220908221051838.png)



##### 混合模式

​		因为先存储哪个分量并没有关系，所以根据存储顺序有着不同的存储格式，以YUV420举例：

- `YUV420P`平面格式，能形成三个组
  - `I420：YYYYYYYY UU VV`
  - `YV12：YYYYYYYY VV UU`
- `YUV420SP`打包格式，一般只会将`UV`交错，而`Y`按序存储
  - `NV12：YYYYYYYY UVUV`
  - `NV21：YYYYYYYY VUVU`



##### 分离YUV

```c
int split_yuv(char *str, uint height, uint width)
{

    FILE *fp;
    FILE *fpy;
    FILE *fpu;
    FILE *fpv;

    unsigned char  *buf = (unsigned char *)malloc(height * width * 3 / 2);

    fp = fopen(str, "r");
    fpy = fopen("y.bin", "wa");
    fpu = fopen("u.bin", "wa");
    fpv = fopen("v.bin", "wa");
    if(!fpv || !fpu || !fpy || !fp){
         fprintf(stderr, "line %d open file error.\n", __LINE__);
        return FALSE;
    }

    fread(buf, 1, height * width * 3 / 2, fp);
    fwrite(buf, 1, height * width , fpy);
    fwrite(buf + height * width, 1, height * width >> 2, fpu);
    fwrite(buf + (uint)(height * width * 5 / 4), 1, height * width >> 2, fpv);

    fclose(fpv);
    fclose(fpu);
    fclose(fpy);
    fclose(fp);
    free(buf);

    return TRUE;
}
```





![`I420`](https://raw.githubusercontent.com/Mocearan/picgo-server/main/v2-ab9144880c191266bb26dda9445538d6_1440w.webp)



#### YUV和RGB的转化

​		凡是渲染到屏幕上的东西（文字、图片或者其他），都要转换为RGB的表示形式。

​		通常情况下RGB和YUV直接的相互转换都是调用接口实现，比如`Ffmpeg`的`swscale`或者`libyuv`等库。主要转换标准是 BT601 和 BT709。

![image-20220908221221048](https://raw.githubusercontent.com/Mocearan/picgo-server/main/image-20220908221221048.png)

​		YUV(256 级别) 可以从8位 RGB 直接计算：

```
Y = 0.299R + 0.587G + 0.114B
U = -0.169R - 0.331*G + 0.5B
V = 0.5 R - 0.419G - 0.081B
```

8bit位深的情况下，TV range是16-235(Y)、16-240(UV) , 也叫Limited Range；PC range是0-255，也叫Full Range。而RGB没有range之分，全是0-255。

​		反过来，RGB 也可以直接从YUV (256级别) 计算：

```
R = Y + 1.402 (Y-128)
G = Y - 0.34414 (U-128) - 0.71414 (U-128)
B = Y + 1.772 (V-128)
```

- 从YUV转到RGB，如果值小于0要取0，大于255要取255.



​		比较典型的场景：

> ​		iOS平台中使用摄像头采集出YUV数据之后，上传显卡成为一个纹理ID，这个时候就需要做YUV到RGB的转换（具体的细节会在后面的章节中详细讲解）。在iOS的摄像头采集出一帧数据之后（CMSampleBufferRef），我们可以在其中调用CVBufferGetAttachment来获取YCbCrMatrix，用于决定使用哪一个矩阵进行转换。
>
> ​		对于Android的摄像头，由于其是直接纹理ID的回调，所以不涉及这个问题。
>
> ​		其他场景下需要自行寻找对应的文档，以找出适合的转换矩阵进行转换。

为什么解码出错显示绿屏？

> ​		因为解码失败时YUV分量都填为0值，然后根据公式：R = 1.402 * (-128) = -126.598，G = -0.34414 * (-128) - 0.71414 * (-128) = 44.04992 + 91.40992 = 135.45984，B = 1.772 * (-128) = -126.228。
> ​		RGB 值范围为[0，255]， 所以最终的值为：R = 0，G = 135.45984，B = 0。
> ​		此时只有G分量有值所以为绿色。







## 图像的编码：压缩

​		提到数字图像数据的格式，常听到的是 PNG、JPEG、GIF 等名词，这些是图像的文件存储格式。

​		它们是对数字图像数据进行编码后进行存储。如果要展示，则需要读取文件数据，进行解码再展示。

### JPEG

​		静态图像压缩标准，ISO指定。

- 良好的压缩性能

- 较好的重建质量

- 图像处理领域

- 有损压缩

- 不能直接用于视频压缩

  > 视频需要考虑时域因素，不仅要考虑帧内编码，还要考虑帧间编码。（帧，视频中的一幅图像）

