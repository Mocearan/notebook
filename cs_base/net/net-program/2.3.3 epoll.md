[图解 | 深入揭秘 epoll 是如何实现 IO 多路复用的！ - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/361750240)

[浅谈线程池（中）：独立线程池的作用及IO线程池 - Jeffrey Zhao - 博客园 (cnblogs.com)](https://www.cnblogs.com/JeffreyZhao/archive/2009/07/24/thread-pool-2-dedicate-pool-and-io-pool.html)

[经典IO模型及线程模型总结 - 掘金 (juejin.cn)](https://juejin.cn/post/6874898561985839118)

[在poller线程读取还是独立的I/O线程 - 搜索 (bing.com)](https://cn.bing.com/search?q=在poller线程读取还是独立的I%2FO线程&cvid=aede6fbd70ed4e0bbaeb115d4181decb&aqs=edge..69i57j69i58.12167j0j1&pglt=513&FORM=ANNTA1&PC=CNNDDB)

[Tomcat源码分析使用NIO接收HTTP请求(一)----简单实现Acceptor、Poller、PollerEvent - 一十三 - 博客园 (cnblogs.com)](https://www.cnblogs.com/yishi-san/p/16900079.html)

[技术派-epoll和IOCP之比较 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/106957967)

[acceptor poller - 搜索 (bing.com)](https://cn.bing.com/search?q=acceptor+poller&cvid=74f117cf38074d6bb05d8c9215738119&aqs=edge..69i57j0l3.7193j0j1&pglt=513&FORM=ANNTA1&PC=CNNDDB)

[技术派-epoll和IOCP之比较 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/106957967)

[routine - 搜索 (bing.com)](https://cn.bing.com/search?q=routine&aqs=edge..69i57.1257j0j1&pglt=513&FORM=ANCMS9&PC=CNNDDB)



[io多路复用：epoll水平触发（LT）和边沿触发（ET）的区别和优缺点 (qq.com)](https://mp.weixin.qq.com/s/gPHODubEoqu8SlKjVkhiCw)

[面试官：epoll 为什么用红黑树？ (qq.com)](https://mp.weixin.qq.com/s/_OOg41Pm0PD3XOMSBR9wjQ)

[什么是树？为什么有二叉树还需要红黑树？+手写红黑树代码 (qq.com)](https://mp.weixin.qq.com/s/DDhAl3deFBew9XMX1J433Q)

# epoll

---

## epoll

​		epoll API执行与poll(2)类似的任务：监视多个文件描述符，以查看其中是否有I/O可能。 

​		epoll API既可以用作边缘触发接口，也可以用作水平触发接口，可以很好地扩展到大量可监视的文件描述符。 

```c
#include <sys/epoll.h>
```

​		`epoll_create`可以认为是内部分配了共享内存，减少了用户空间到内核空间的拷贝。`epoll_ctl`控制添加到内核共享内存的数据。

### epoll_event

> ```c
> typedef union epoll_data {
> void    *ptr;
> int      fd;
> uint32_t u32;
> uint64_t u64;
> } epoll_data_t;
> 
> struct epoll_event {
> uint32_t     events;    /* Epoll events */
> epoll_data_t data;      /* User data variable */
> };
> 
> // The data of each returned structure will contain the same data the user set with an epoll_ctl(2)  (EPOLL_CTL_ADD,EPOLL_CTL_MOD) while the events member will contain the returned event bit field.
> ```
>
> >   **events：**
> >
> >   ```c
> >   enum EPOLL_EVENTS
> >   {
> >     EPOLLIN = 0x001,
> >   #define EPOLLIN EPOLLIN
> >     EPOLLPRI = 0x002,
> >   #define EPOLLPRI EPOLLPRI
> >     EPOLLOUT = 0x004,
> >   #define EPOLLOUT EPOLLOUT
> >     EPOLLRDNORM = 0x040,
> >   #define EPOLLRDNORM EPOLLRDNORM
> >     EPOLLRDBAND = 0x080,
> >   #define EPOLLRDBAND EPOLLRDBAND
> >     EPOLLWRNORM = 0x100,
> >   #define EPOLLWRNORM EPOLLWRNORM
> >     EPOLLWRBAND = 0x200,
> >   #define EPOLLWRBAND EPOLLWRBAND
> >     EPOLLMSG = 0x400,
> >   #define EPOLLMSG EPOLLMSG
> >     EPOLLERR = 0x008,
> >   #define EPOLLERR EPOLLERR
> >     EPOLLHUP = 0x010,
> >   #define EPOLLHUP EPOLLHUP
> >     EPOLLRDHUP = 0x2000,
> >   #define EPOLLRDHUP EPOLLRDHUP
> >     EPOLLWAKEUP = 1u << 29,
> >   #define EPOLLWAKEUP EPOLLWAKEUP
> >     EPOLLONESHOT = 1u << 30,
> >   #define EPOLLONESHOT EPOLLONESHOT
> >     EPOLLET = 1u << 31
> >   #define EPOLLET EPOLLET
> >   };
> >   ```



### 创建epoll

```c
// create

// Epoll_create()返回指向新epoll实例的文件描述符。 这个文件描述符用于所有对epoll接口的后续调用。 
// 当不再需要时，epoll_create()返回的文件描述符应该使用close(2)关闭。 
// 当所有引用epoll实例的文件描述符都被关闭时，内核将销毁该实例并释放相关资源以供重用。  

int epoll_create(int size); 

// size, 
//		epoll_create 为hash map实现，size指定hash map的容量，不代表实际fd的上限
```

```c
// 如果flags为0，epoll_create1()与epoll_create()相同。
int epoll_create1(int flags);

//  	epoll_create1 为红黑树实现，不需要指定容量， 内核版本较高时，推荐使用。
// flags:
//  	EPOLL_CLOEXEC  在新的文件描述符上设置close-on-exec (FD_CLOEXEC)标志。
//请参阅open(2)中O_CLOEXEC标志的描述，了解这可能有用的原因。  
```

### 操作

```c
// opt
int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);

// wait
int epoll_wait(int epfd, struct epoll_event *events,
               int maxevents, int timeout);
int epoll_pwait(int epfd, struct epoll_event *events,
                int maxevents, int timeout,const sigset_t *sigmask);

///////////////
// epfd, epoll_create* 返回的 epoll实例文件描述符
// events, out， 传出被触发的epoll_events结构列表
// maxevents, 能够接收的最大返回个数， events的个数
// timeout， 超时时间
//     -1， 不启用超时，阻塞直到有事件触发
// sigmask 
```

> **O_CLOEXEC: **
>
> ​		进程被替换的时候，文件描述符会被替换。
>
> ![image-20220704224223400](https://raw.githubusercontent.com/Mocearan/picgo-server/main/image-20220704224223400.png)



## 触发模式

​		可读事件意味着缓冲区有数据没处理完，可以读出数据

​		可写事件意味着缓冲区未满，可以写入数据

### EPOLLLT 水平触发

​		完全依靠kernel epoll驱动，应用程序只需要处理从`epoll_wait`返回的`fds`， 这些 `fds `就是处于就绪状态的文件描述符。

​		`epoll`维持着这个就绪态的队列，持续检测其上的事件。持续检测意味着持续触发。

​		实际上，`EPOLLLT`模式和`select/poll`几乎一样。

#### Level-Triggered 的busy-loop

​		如果在没有写事件发生的时候关注写事件，发送缓冲区会在可写的情况下，持续触发写事件。造成busy-loop。

![image-20220704224246136](https://raw.githubusercontent.com/Mocearan/picgo-server/main/image-20220704224246136.png)

​		水平触发模式下的`EPOLLOUT`事件的处理，在需要发送时直接调用`write`，当`write`非阻塞返回剩余未发送的数据量，表示内核发送缓冲区已经填满，这时将未充入内核缓冲区的数据在应用层缓存，并关注`EPOLLOUT`事件，`epoll`在内核缓冲区有空闲时，就会触发可写事件。

![image-20220704230629317](https://raw.githubusercontent.com/Mocearan/picgo-server/main/image-20220704230629317.png)



### EPOLLET 边缘触发

​		kernel epoll只维护`fd`的极限情况，即从可读到不可读，从不可读到可读；从可写到不可写，从不可写到可写，对于其他的中间状态一概忽略，不会持续触发。

> 这意味着对于每次边缘触发的事件，都需要一次做完，使其能够回到极限状态状态，以使得下一次事件能够正确触发。
>
> 在没有可写事件时关注`EPOLLOUT`不会造成busy-loop

​		当`fd`触发成为就绪状态，``epoll``将其从实例中移除，直到通过 r/w 操作触发`EAGAIN`，`fd`变为空闲状态，`epoll`又将其加入实例检测。随着``epoll_wait``的返回，``epoll``实例中的fds是在减少的，所以在大并发的系统中，`EPOLLET`更有优势。

> ​		对于读来说，如果一次读不完，导致不能恢复到不可读的状态，就导致不会再触发可读事件。
>
> ​		对于写事件，每个读事件都会触发一次写事件，注意特殊的一点是``EPOLLOUT``在注册时的第一次会就绪。
>
> ​		`EAGAIN`，表示一次未能将内核缓冲区的数据读完，或者将数据都发送到内核缓冲区，需要再次进行I/O操作。 

> **[有关于epollout事件触发的实验&epoll坑_心灵迷宫-CSDN博客_epollout事件](https://blog.csdn.net/weixin_43468441/article/details/88710514)**
>
> [关于epoll边缘触发模式（ET）下的EPOLLOUT触发_Tristone的专栏-CSDN博客](https://blog.csdn.net/tc725210/article/details/42686171)
>
> [Epoll ET模型下，为什么每次EPOLLIN事件都会带一次EPOLLOUT事件？-CSDN社区](https://bbs.csdn.net/topics/390630226)

​		![image-20220704231701677](https://raw.githubusercontent.com/Mocearan/picgo-server/main/image-20220704231701677.png)



## epoll server

```c
// 将事件注册时的events中加上EPOLLET即可使该套接字上的I/O事件变为边沿触发。

#include <unistd.h>
#include <sys/types.h>
#include <fcntl.h>
#include <sys/socket.h>
#include <netinet/in.h>
#include <arpa/inet.h>
#include <signal.h>
#include <fcntl.h>
#include <sys/wait.h>
#include <sys/epoll.h>

#include <stdlib.h>
#include <stdio.h>
#include <errno.h>
#include <string.h>

#include <vector>
#include <algorithm>
#include <iostream>

typedef std::vector<struct epoll_event> EventList;

#define ERR_EXIT(m) \
        do \
        { \
                perror(m); \
                exit(EXIT_FAILURE); \
        } while(0)

int main(void)
{
	signal(SIGPIPE, SIG_IGN);
	signal(SIGCHLD, SIG_IGN);

	int idlefd = open("/dev/null", O_RDONLY | O_CLOEXEC);
	int listenfd;
	//if ((listenfd = socket(PF_INET, SOCK_STREAM, IPPROTO_TCP)) < 0)
	if ((listenfd = socket(PF_INET, SOCK_STREAM | SOCK_NONBLOCK | SOCK_CLOEXEC, IPPROTO_TCP)) < 0)
		ERR_EXIT("socket");

	struct sockaddr_in servaddr;
	memset(&servaddr, 0, sizeof(servaddr));
	servaddr.sin_family = AF_INET;
	servaddr.sin_port = htons(5188);
	servaddr.sin_addr.s_addr = htonl(INADDR_ANY);

	int on = 1;
	if (setsockopt(listenfd, SOL_SOCKET, SO_REUSEADDR, &on, sizeof(on)) < 0)
		ERR_EXIT("setsockopt");

	if (bind(listenfd, (struct sockaddr*)&servaddr, sizeof(servaddr)) < 0)
		ERR_EXIT("bind");
	if (listen(listenfd, SOMAXCONN) < 0)
		ERR_EXIT("listen");

	std::vector<int> clients;
	int epollfd;
	epollfd = epoll_create1(EPOLL_CLOEXEC);

	struct epoll_event event;
	event.data.fd = listenfd;
	event.events = EPOLLIN/* | EPOLLET*/;
	epoll_ctl(epollfd, EPOLL_CTL_ADD, listenfd, &event);
	
	EventList events(16);
	struct sockaddr_in peeraddr;
	socklen_t peerlen;
	int connfd;

	int nready;
	while (1)
	{
		nready = epoll_wait(epollfd, &*events.begin(), static_cast<int>(events.size()), -1);
		if (nready == -1)
		{
			if (errno == EINTR)
				continue;
			
			ERR_EXIT("epoll_wait");
		}
		if (nready == 0)	// nothing happended
			continue;

		if ((size_t)nready == events.size())
			events.resize(events.size()*2);

		for (int i = 0; i < nready; ++i)
		{
			if (events[i].data.fd == listenfd)
			{
				peerlen = sizeof(peeraddr);
				connfd = ::accept4(listenfd, (struct sockaddr*)&peeraddr,
						&peerlen, SOCK_NONBLOCK | SOCK_CLOEXEC);

				if (connfd == -1)
				{
					if (errno == EMFILE)
					{
						close(idlefd);
						idlefd = accept(listenfd, NULL, NULL);
						close(idlefd);
						idlefd = open("/dev/null", O_RDONLY | O_CLOEXEC);
						continue;
					}
					else
						ERR_EXIT("accept4");
				}


				std::cout<<"ip="<<inet_ntoa(peeraddr.sin_addr)<<
					" port="<<ntohs(peeraddr.sin_port)<<std::endl;

				clients.push_back(connfd);
				
				event.data.fd = connfd;
				event.events = EPOLLIN/* | EPOLLET*/;
				epoll_ctl(epollfd, EPOLL_CTL_ADD, connfd, &event);
			}
			else if (events[i].events & EPOLLIN)
			{
				connfd = events[i].data.fd;
				if (connfd < 0)
					continue;

				char buf[1024] = {0};
				int ret = read(connfd, buf, 1024);
				if (ret == -1)
					ERR_EXIT("read");
				if (ret == 0)
				{
					std::cout<<"client close"<<std::endl;
					close(connfd);
					event = events[i];
					epoll_ctl(epollfd, EPOLL_CTL_DEL, connfd, &event);
					clients.erase(std::remove(clients.begin(), clients.end(), connfd), clients.end());
					continue;
				}

				std::cout<<buf;
				write(connfd, buf, strlen(buf));
			}

		}
	}

	return 0;
}
```





## epoll 优势

- 查找效率

  ​		不同于`select`和`poll`的轮询实现，`epoll`实现为`hash map`或红黑树，具有极高的查找效率，因此在并发请求数量较大时，效率会很高。

- 基于回调

  ​		`epoll`是基于回调实现的，`fd `注册的事件被触发，就通过回调函数将`fd`加入`epoll`就绪队列中，后续只处理这些活跃的fd， 与实际总的fd数目无关。

- 系统调用的效率

  ​		从内核将fd消息（IO复用相关的数据结构）通知到用户空间的方式上，select / poll采用了内存拷贝的方式，而epoll使用了共享内存。避免了拷贝。

- 事件的处理方式

  ​		通知应用程序发生事件的 fd，并通知触发的相应事件，和其他信息。依据这些信息能够直接定位并处理事件，不必遍历整个fd集合。

  > poll：
  >
  > ![image-20220704224314937](https://raw.githubusercontent.com/Mocearan/picgo-server/main/image-20220704224314937.png)
  >
  > epoll：
  >
  > ![image-20220704224334489](https://raw.githubusercontent.com/Mocearan/picgo-server/main/image-20220704224334489.png)

