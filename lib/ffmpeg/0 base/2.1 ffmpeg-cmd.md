# ffmpeg-cmd

[ffmpeg Documentation](https://ffmpeg.org/ffmpeg.html)

---



## cmd 结构

```shell
ffmpeg [options] {[infile options] -i infile} ... {[outfile options] outfile} ...
```





## 参数

### `-h`查看帮助

```shell
ffmpeg -h 		# 基本信息
ffmpeg -h long 	# 高级信息
ffmpeg -h full 	# 所有信息，信息过多，可以通过 ffmpeg -h full > ffmpe_h_full.log导出到文件查看
```

![img](https://developer.qcloudimg.com/http-save/yehe-7620466/8e6394f7965f43a22e2ef01022afa973.png)

- 查看某类组件帮助

  ```shell
  ffmepg -h type=name # ffmepg -h type=name
  
  # eg
  ffmpeg -h muxer=flv
  ffmpeg -h filter=atempo(atempo调整音频播放速率)
  ffmpeg -h encoder=libx264
  ```

  

### 通用参数

- ``-i`` 设定输入流
- ``-f`` 设定输出格式（format）
- ``-ss`` 开始时间
- ``-t`` 时间长度
- `-y`： 输出时覆盖输出目录已存在的同名文件
- `-target type` 设置目标文件类型(vcd,svcd,dvd)

  - `所有的格式选项（比特率，编解码以及缓冲区大小）自动设置 ，只需要输入如下的就可以了

    ```shell
    ffmpeg -i myfile.avi -target vcd /tmp/vcd.mpg
    ```

- `-hq` 高质量设置

- `-itsoffset offset ` 设置以秒为基准的时间偏移，该选项影响所有后面的输入文件

  - 该偏移被加到输入文件的时戳
  - 定义一个正偏移意味着相应的流被延迟了 offset秒
  - `[-]hh:mm:ss[.xxx]`的格式也支持




- `-title string` 设置标题
- `-author string `设置作者
- `-copyright string `设置版权
- `-comment string `设置评论



### 查询参数

- `-L` ：license
- `-version`： 显示版本
- `-buildconf`： 显示编译配置
- `-bsfs` ：显示可用比特流filter
- `-protocols` ： 显示可用的协议
- `-filters` ： 显示可用的过滤器
- `-pix_fmts` ： 显示可用的像素格式
- `-layouts` ： 显示标准声道名称
- `-sample_fmts` ： 显示可用的音频采样格式
- `-colors` ： 显示可用的颜色名称
- `-formats` ： 显示可用格式(muxers+demuxers)
- `-muxers` ： 显示可用复用器
- `-demuxers` ： 显示可用解复用器
- `-codecs` ： 显示可用编解码器(decoders+encoders)
- `-decoders` ： 显示可用解码器
- `-encoders` ： 显示可用编码器
- `-devices`：显示可用音视频设备



### 采集参数

- `-vd device` ：设置视频捕获设备。比如/dev/video0
- `-vc channel`：设置视频捕获通道 DV1394专用
- `-tvstd standard`： 设置电视标准 NTSC PAL(SECAM)
- `-dv1394` ：设置DV1394捕获
- `-av device`： 设置音频设备 比如/dev/dsp
- `-devices`：查看看可用的设备
- `-f` 指定采集数据的设备

  - `gdigrab`  Windows桌面

    ```shell
    ffmpeg -f gdigrab -i desktop -r 30 out.rgb # rgb32
    ffplay -video_size 3440x1440 -pixel_format bgra ./out.rgb
    ```

  - `dshow` Windows音频

    ```shell
    ffmpeg -f dshow -i audio="麦克风 (Realtek High Definition Audio)" out.wav
    
    ffmpeg -f gdigrab -s 1920x1080 -i desktop -f dshow -i audio="麦克风 (Realtek High Definition Audio)" out.mp4 # 同录
    ```

    

  



### 高级参数

- `-map file:stream`： 设置输入流映射
- `-debug `：打印特定调试信息
- `-benchmark `：为基准测试加入时间
- `-hex`： 倾倒每一个输入包
- `-bitexact`： 仅使用位精确算法 用于编解码测试
- `-ps size` ：设置包大小，以bits为单位
- `-re` ：以本地帧频读数据，主要用于模拟捕获设备
  - 按照既定速率处理输入数据，这个速率即是输入文件的帧率

- `-loop `：循环输入流。只工作于图像流，用于ffserver测试



### 音频参数

- ``aframes ``设置要输出的音频帧数
- ``-b:a bitrate ``音频码率
  - `-ab`

- ``-ar freq``  设定采样率
- `-ac channels` 设定声音的channel数
- `-an`不处理音频
- `-af` 音频过滤器
- `-acodec codec` 设定声音编解码器
  - 未设定时则使用与输入流相同的编解码器
  - `copy` 表示原始编码数据必须被拷贝

- `-c:a`：输出视频格式

 

```shell
ffmpeg -i test.mp4 -b:a 192k -ar 48000 -ac 2 -acodec libmp3lame -aframes 200 out2.mp3
```



### 视频参数

- `-vframes` 设置要输出的视频帧数
- `-bf` B帧数量控制
- `-g` 关键帧间隔控制
  - 视频跳转需要关键帧

- `-b` 设定视频码率（`Kbit/s`）
  - 缺省`200kb/s`
  - `-b:v` 视频码率

- `-bt tolerance`  设置视频码率容忍度`kbit/s`
  - `-maxrate bitrate`设置最大视频码率容忍度
  - `-minrate bitreate `设置最小视频码率容忍度

- `-bufsize size` 设置码率控制缓冲区大小
- `-r`  设定帧率（图像频率）
  - 用于视频截图
  - 缺省25
- `-s` 设定画面的宽高（分辨率）
  -  格式为`wXh `
  - 缺省160X128.
  - 下面的简写也可以直接使用：
    - `Sqcif `：128X96 
    - `qcif `：176X144 
    - `cif `：252X288 
    - `4cif `：704X576

- `-vn` 不处理视频
- `-aspect` 设置画幅纵横比
  - `4:3 / 16:9`
  - `1.3333 / 1.7777`
- `-croptop size` 设置顶部切除带大小 像素单位
  - `-cropbottom size `
  - `–cropleft size `
  - `–cropright size`

- `-padtop size` 设置顶部补齐的大小 像素单位
  - `-padbottom size `
  - `–padleft size `
  - `–padright size `
  - `–padcolor color ` 设置补齐条颜色(hex,6个16进制的数，红:绿:兰排列，比如 000000代表黑色)

- `-vcodec` 设定视频编解码器
  - 未设定时则使用与输入流相同的编解码器
  - `copy` 表示原始编解码数据必须被拷贝

- `-vf` 视频过滤器
- `-c:v`：输出视频格式
- `-sameq` 使用同样视频质量作为源（VBR）
- `-pass n` 选择处理遍数（1或者2）
  - 两遍编码非常有用
    - 第一遍生成统计信息
    - 第二遍生成精确的请求的码率

  - `-passlogfile file` 选择两遍的纪录文件名为file



- `-g gop_size`：设置图像组大小
- `-intra`： 仅适用帧内编码
- `-qscale q`： 使用固定的视频量化标度(VBR)
- `-qmin q`： 最小视频量化标度(VBR)
- `-qmax q`： 最大视频量化标度(VBR)
- `-qdiff q`： 量化标度间最大偏差 (VBR)
- `-qblur blur `：视频量化标度柔化(VBR)
- `-qcomp compression` 视频量化标度压缩(VBR)
- `-rc_init_cplx complexity` 一遍编码的初始复杂度
- `-b_qfactor factor `在p和b帧间的qp因子
- `-i_qfactor factor` 在p和i帧间的qp因子
- `-b_qoffset offset` 在p和b帧间的qp偏差
- `-i_qoffset offset` 在p和i帧间的qp偏差
- `-rc_eq equation` 设置码率控制方程 默认tex^qComp
- `-rc_override override` 特定间隔下的速率控制重载
- `-me method` 设置运动估计的方法 可用方法有 zero phods log x1 epzs(缺省) full
- `-dct_algo algo` 设置dct的算法 可用的有 
  - 0 FF_DCT_AUTO 缺省的DCT 
  - 1 FF_DCT_FASTINT 
  - 2 FF_DCT_INT 
  - 3 FF_DCT_MMX 
  - 4 FF_DCT_MLIB 
  - 5 FF_DCT_ALTIVEC

- `-idct_algo algo` 设置idct算法。可用的有 
  - 0 FF_IDCT_AUTO 缺省的IDCT 
  - 1 FF_IDCT_INT 2 FF_IDCT_SIMPLE
  -  3 FF_IDCT_SIMPLEMMX 
  - 4 FF_IDCT_LIBMPEG2MMX 
  - 5 FF_IDCT_PS2 
  - 6 FF_IDCT_MLIB 
  - 7 FF_IDCT_ARM 
  - 8 FF_IDCT_ALTIVEC
  -  9 FF_IDCT_SH4
  -  10 FF_IDCT_SIMPLEARM

- `-er n` 设置错误残留为n 
  - 1 FF_ER_CAREFULL 缺省 
  - 2 FF_ER_COMPLIANT 
  - 3 FF_ER_AGGRESSIVE 
  - 4 FF_ER_VERY_AGGRESSIVE

- `-ec bit_mask` 设置错误掩蔽为bit_mask,该值为如下值的位掩码 1 FF_EC_GUESS_MVS (default=enabled) 2 FF_EC_DEBLOCK (default=enabled)
- `-bf frames` 使用frames B 帧，支持mpeg1,mpeg2,mpeg4
- `-mbd mode` 宏块决策 0 FF_MB_DECISION_SIMPLE 使用mb_cmp 1 FF_MB_DECISION_BITS 2 FF_MB_DECISION_RD
- `-4mv` 使用4个运动矢量 仅用于mpeg4
- `-part` 使用数据划分 仅用于mpeg4
- `-bug param` 绕过没有被自动监测到编码器的问题
- `-strict strictness` 跟标准的严格性
- `-aic `使能高级帧内编码 h263+
- `-umv` 使能无限运动矢量 h263+
- `-deinterlace` 不采用交织方法
- `-interlace` 强迫交织法编码 仅对mpeg2和mpeg4有效。当你的输入是交织的并且你想要保持交织以最小图像损失的时候采用该选项。可选的方法是不交织，但是损失更大
- `-psnr` 计算压缩帧的psnr
- `-vstats` 输出视频编码统计到vstats_hhmmss.log
- `-vhook module` 插入视频处理模块 module 包括了模块名和参数，用空格分开






```shell
ffmpeg -i test.mp4 -vframes 300 -b:v 300k -r 30 -s 640x480 -aspect 16:9 -vcodec libx265

#-i test.mp4：指定输入文件。
#-vframes 300：限制输出为前300帧。
#-b:v 300k：设置视频的比特率为300 kbps。
#-r 30：设置输出帧率为每秒30帧。
#-s 640x480：将输出视频的分辨率调整为640x480像素。
#-aspect 16:9：设置纵横比为16:9（但请注意，640x480的实际纵横比是4:3）。
#-vcodec libx265：指定使用H.265编码进行视频压缩。
```



### 滤镜参数

​	`-vf filters` 

>  除了`source`和`sink filter`，其他filter都至少有一个输入、至少一个输出。

- source filter （只有输出） 
- audio filter 
- video filter 
- Multimedia filter
- sink filter （只有输入）


​		在应用滤镜效果时可能会消耗大量计算资源和时间，因此应该根据具体需求谨慎调整。

  	在 FFmpeg 的滤镜链中，通常多个滤镜会连接在一起使用，通过`[in][input_tag]filter[out]`来连接连续处理的两个滤镜

- **`[in]`**: 输入标签，代表输入流（通常是主视频）。

- **`[input_tag]`**: 另一个滤镜标签

  - `filter[output_tag]`可以给一个过滤器的输出打上tag
  - 如，`movie=logo2.png[watermark]`

- **`filter`**:接收输入的滤镜

- **`[out]`**: 输出标签，代表处理后的流

- `[in]` 和 ``[out]`` 是常用的标签，但并不是必须使用的。

  - 当你定义了一个完整的滤镜链，并且在滤镜之间使用了自定义标签，可以省略 `[in]` 和 `[out]`

- 如，`[in][watermark]overlay=50:10[out]`

  > `"movie=logo2.png[watermark];[in][watermark]overlay=50:10[out]"`



#### `crop`

​		`crop=ow[:oh[:x[:y[:keep_aspect]]]]`

​		将输入视频帧的宽度和高度从x/y表示的位置裁剪到指定的宽度和高度。

- `i/o`：input / output
- `w/h`：width / height，左上角坐标，协调系统的中心是输入视频帧的左上角
- `in_w, iw` ：输入的宽度
- `in_h`,：ih输入的高度
- `out_w`,：ow输出(裁剪)宽度,默认值=iw
- `out_h`： oh输出(裁剪)高度,默认值= ih
- `x, y`：从左上角对每个帧进行定位
  - x的默认值为`(iw -ow)/2`,y的默认值为`(ih-oh)/2`
- `keep_aspect`，改变输出SAR(样本宽比)补偿新的DAR（显示长宽比）
- `a`：纵横比,与iw/ih相同
- `sar`：输入样本比例
- `dar`：输入显示宽比,等于表达式a*sar
- `hsub, vsub`：水平和垂直的色度子样本值,对于像素格式yuv422p, hsub的值为2,vsub为1
- `n`：输入帧的顺序编号，从0开始
- `pos`：位置在输入框的文件中,如果不知道NAN
- `t`：时间戳以秒表示,如果输入时间戳未知

![img](https://raw.githubusercontent.com/Mocearan/picgo-server/main/2717bdefaa4b63b7a4cd5d1d9498afc2.png)



#### `drawtext`

- `text	`，字符串，文字
- `textfile	`，字符串，文字文件
- `box	`，布尔，文字区域背景框(缺省false)
- `boxcolor	`，色彩，展示字体区域块的颜色
- `font	`，字符串，字体名称(默认为Sans字体)
- `fontsize	`，整数，显示字体的大小
- `x	`，字符串，缺省为0
- `y`	，字符串，缺省为0
- `alpha	`，浮点数，透明度(默认为1),值从0~1
- `enable`，表示在指定的时间范围内显示文本



#### `movie`

​		`movie=<filename>[?params]  `

- `filename`，字符串，输入的文件名,可以是文件,协议,设备
- `format_name, f` ，字符串输入的封装格式
- `stream_index, si ` ，  整数输入的流索引编号
- `seek_point, sp`，浮点数Seek输入流的时间位置
- `streams, s`，字符串输入的多个流的流信息
- `loop`，整数循环次数
- `discontinuity`，时间差值支持跳动的时间戳差值

#### `overlay`

​		`overlay=x:y:params`

​		`overlay`滤镜用于将第二输出（前景）窗口覆盖在第一输入（背景窗口）的指定位置：

-  x，y 是可选的，默认为 0
- `params` 是可选的
  - `eof_action`，整数，遇到`eof`的行为
    - `repeat`，0，重复歉意帧，默认值
    - `endcall`，1，停止所有流
    - `pass`，2，保留主图层

  - `shortest`，布尔，终止最短的视频时会全部终止，默认false
  - `format`，整数，设置`output`的像素格式
    - `yuv420`，值为0，默认值
    - `yuv422`，值为1
    - `yuv444`，值为2
    - `rgb`，值为3




![img](https://raw.githubusercontent.com/Mocearan/picgo-server/main/a161981bf3852f595a7eb6cf50e869e4.png)

> - `mian_W / W `， 视频单帧图像宽度
> - `main_h / H`， 视频单帧图像高度
> - `overlay_w`，水印图片的宽度
> - `overlay_h`，水印图片的宽度
>
> 左上角:` x:y `
>
> 右上角 `main_w - overlay_w-x:y`
>
> 左下角:`x:mian_h-overlay_h-y`
>
> 右下角:`main_w-overlay_w-x:main_h-overlay_h-y`

## in use

### 提取

- 提取视频

  ```shell
  ffmpeg -i test.mp4 -vcodec copy -an test_copy.h264 # 保留编码格式
  ffmpeg -i test.mp4 -vcodec copy -an video.mp4  # 保留封装格式
  ffmpeg -i test.mp4 -vcodec libx264 -an test.h264 # 强制格式
  
  # -acodec == -codec:a
  # -vcodec == -codec:v
  ```

- 提取音频

  ```shell
  ffmpeg -i test.mp4 -acodec copy -vn test.aac # 保留编码格式
  ffmpeg -i test.mp4 -acodec copy -vn audio.mp4 # 保留封装格式
  ffmpeg -i test.mp4 -acodec libmp3lame -vn test.mp3 # 强制编码格式
  
  ffmpeg -i xxx.mp4 -vn -c:a libfdk_aac -ar 44100 -channels 2 -profile:a aac_he_v2 audio_name.aac # 重新采样编码
  ```

- 提取像素格式

  ```shell
  ffmpeg -i test.mp4 -t 3 -pix_fmt yuv420p out.yuv # 提取YUV 3秒数据，分辨率和源视频一致
  ffmpeg -i test.mp4 -t 3 -pix_fmt yuv420p -s 320x240 out.yuv # 提取YUV 3秒数据， 分辨率转为320x240
  
  ffmpeg -i test.mp4 -t 3 -pix_fmt rgb24 -s 320x240 out.rgb # 提取RGB 3秒数据，分辨率转为320x240
  
  ffmpeg -s 320x240 -t 3 -pix_fmt yuv420p -i input.yuv -pix_fmt rgv24 out.rgb # YUV -> RGB
  ```

- 提取音频格式

  ```shell
  ffmpeg -i test.mp3 -ar 48000 -ac 2 -f s16le out.pcm # 可以省略后缀 .pcm
  ffmpeg -i test.mp4 -ar 48000 -ac 2 -f f32le out.pcm # 可以省略后缀 .pcm
  ffmpeg -i out.mp4 -vn -ar 44100 -ac 2 -f sl6le out.pcm
  # ffplay -ar 44100 -ac 2 -f s16le out.pcm
  
  ffmpeg -i test.mp3 -ar 48000 -ac 2 -smaple_fmt s16 out.wav
  ffmpeg -i test.mp3 -ar 48000 -ac 2 -codec:a pcm_s16le out.wav
  
  # wav是在pcm音频裸数据前面打上WAV头部
  ```


### 转封装(转码)

- 解封装

- 解码

- 重新编码

- 重新封装


  ```shell
  ffmpeg -i input.mp4 output.avi
  
  # 转封装保持编码格式
  ffmpeg -i test.mp4 -vcodec copy -acodec copy out.ts
  ffmpeg -i test.mp4 -codec copy out.ts # -codec == -vcodec + -acodec
  
  # 转封装改变编码格式
  ffmeg -i test.mp4 -vcodec libx265 -acodec libmp3lame out.mkv
  
  # 转封装修改帧率
  ffmpeg -i test.mp4 -r 15 -codec copy out.mp4 # error, 帧率不会改变
  ffmepg -i test.mp4 -r 15 out.mp4
  
  # 转封装修改视频码率
  ffmpeg -i test.mp4 -b 400k out.mkv 
  ffmpeg -i test.mp4 -b:v 400k out.flv
  
  # 转封装修改音频码率
  ffmpeg -i test.mp4 -b:a 192k out.mp4 # 不重新编码
  
  # 转封装修改音视频码率
  ffmpeg -i test.mp4 -b:v 400k -b:a 192k out.mp4 
  
  # 转封装修改音频采样率
  ffmpeg -i test.mp4 -ar 44100 out.mp4
  
  # -bf B帧数目控制, -g 关键帧间隔控制, -s 分辨率控制
  ffmpeg -i test.mp4 -vcodec h264 -s 352*278 -an -f m4v test.264    #转码为码流原始文件
  ffmpeg -i test.mp4 -vcodec h264 -bf 0 -g 25 -s 352-278 -an -f m4v test.264    #转码为码流原始文件
  ffmpeg -i test.avi -vcodec mpeg4 -vtag xvid -qsame test_xvid.avi    #转码为封装文件 
  ```

### 视频解封装

```shell
ffmpeg -i test.mp4 -vcodec copy -an -f m4v test.264
ffmpeg -i test.avi -vcodec copy -an -f m4v test.264
```

### 视频封装

```shell
ffmpeg -i video_file -i audio_file -vcodec copy -acodec copy output_file
```



### 切分视频

```shell
ffmpeg -i input.avi -ss 0:1:30 -t 0:0:20 -vcodec copy -acoder copy output.avi 
# 剪切视频 -r 提取图像频率， -ss 开始时间， -t 持续时间

ffmpeg -i input.mp4 -c:v libx264 -c:a aac -strict -2 -f hls -hls_time 20 -hls_list_size 0 -hls_wrap 0 output.m3u8 # 切分视频并生成M3U8文件
```



### 拼接视频

- 准备好待拼接的文件片段，音视频封装格式编码格式需要统一，不统一则需要转码转封装。

  ```shell
  ffmpeg-i 沙海02.mp4 -ss 00:05:00 -t 10 -codec copy 1.mp4
  ffmpeg -i 复仇者联盟3.mp4 -ss 00:05:00 -t 10 -codec copy 2.mp4
  ffmpeg-i 红海行动.mp4 -ss 00:05:00 -t 10 -codec copy 3.mp4
  # 如果音视频格式不统一则强制统一为-vcodeclibx264-acodecaac
  
  ffmpeg-i 1.mp4 -codec copy -vbsf h264_mp4toannexb 1.ts
  ffmpeg-i 2.mp4 -codec copy -vbsf h264_mp4toannexb 2.ts
  ffmpeg-i 3.mp4 -codec copy -vbsf h264_mp4toannexb 3.ts
  # 分离某些封装格式（例如MP4/FLV/MKV等）中的H.264的时候，需要首先写入SPS和PPS，否则会导致分离出来的数据没有SPS、PPS而无法播放。H.264码流的SPS和PPS信息存储在AVCodecContext结构体的extradata中。需要使用ffmpeg中名称为“h264_mp4toannexb”的bitstream filter处理
  
  ffmpeg-i 1.mp4 -codec copy 1.flv
  ffmpeg-i 2.mp4 -codec copy 2.flv
  ffmpeg-i 3.mp4 -codec copy 3.flv
  ```

- 视频分辨率可以不同，但是编码格式需要统一，封装格式也建议统一为TS输入流，输出时转为目标封装格式

- 音频编码格式需要统一，音频参数（采样率，声道数，位深等）也需要统一

```shell
# 1
ffmpeg-i "concat:1.mp4|2.mp4|3.mp4" -codec copy out_mp4.mp4
ffmpeg-i"concat:1.ts|2.ts|3.ts" -codec copy out_ts.mp4 
ffmpeg-i "concat:1.flv|2.flv|3.flv" -codec copy out_flv.mp4

# 2
ffmpeg-f concat-i mp4list.txt -codec copy out_mp42.mp4	
ffmpeg-f concat-i tslist.txt -codec copy out_ts2.mp4
ffmpeg-f concat-i flvlist.txt -codec copy out_flv2.mp4

# 方法1只适用部分封装格式，比如TS流
# 建议使用方法2进行拼接，或者转为ts流再进行拼
```

### 截图

```shell
ffmpeg -i test.mp4 -y -f image2 -ss 00:00:02 -vframes 1 -s 640x360 test.jpg
ffmpeg -i test.mp4 -y -f image2 -ss 00:00:02 -vframes 1 -s 640x360 test.bmp
ffmpeg -i test.avi -r 1 -f image2 image.jpeg # 视频截图
ffmpeg -i input_file -y -f mjpeg -ss 8 -t 0.001 -s 320x240 output.jpg # 第8.01秒出截取230x240的缩略图
ffmpeg -i out.mp4 -f image2 -vf fps=fps=1 out%d.png # 每隔一秒截一张图
ffmpeg -i out.mp4 -f image2 -vf fps=fps=1/20 out%d.png # 每隔20秒截一张图
ffmpeg -i out.mp4 -frames 3 -vf "select=not(mod(n\,1000)),scale=320:240,tile=2x3" out.png # 每隔一千帧(秒数=1000/fps25)即40s截一张图,多张截图合并到一个文件里（2x3）

# -y 确认覆盖
# -f 图片格式 image2
# -ss 起始时间
# -vframes 截取帧数
# -s 分辨率大小
```

### 视频图片集转换

```shell
ffmpeg -i out.mp4 out%4d.png # 转换视频为图片（每帧一张图)
ffmpeg -i test.mp4 -t 5 -s 640x360 -r 15 frame%03d.jpg # -r 指定gop提取中帧数，%03d为提取的图片集命名规则

ffmpeg -f image2 -i frame%03d.jpg -r 25 video.mp4 # -r 指定生成的视频gop帧率
ffmpeg -f image2 -i out%4d.png -r 25 video.mp4
```

### 视频GIF转换

```shell
ffmpeg -i test.mp4 -t 5 -r 1 image1.gif
ffmpeg -i test.mp4 -t 5 -r 25 -s 640x360 image2.gif
ffmpeg -i out.mp4 -t 10 -pix_fmt rgb24 out.gif
ffmpeg -i input_file -vframes 30 -y -f gif output.gif # 前30帧转换成一个Animated Gif
ffmpeg -ss 3 -t 5 -i input.mp4 -s 480*270 -f gif out.gif # 从视频截选指定长度的内容生成GIF图片

ffmpeg -f gif -i image2.gif image2.mp4
```

### 视频转录

```shell
ffmpeg -i rtsp://hostname/test -vcodec copy out.avi
```

### 前后反转

```shell
# For video only
ffmpeg -i input-file.mp4 -vf reverse output.mp4
 
# For audio and video:
ffmpeg -i input-file.mp4 -vf reverse -af areverse output.mp4
```

### 添加logo

```shell
ffmpeg -i input2.mp4 -i logo.jpg -filter_complex overlay output_logo.mp4 
ffmpeg -i input2.mp4 -i logo.jpg -filter_complex overlay=W-w output.mp4 
ffmpeg -i input2.mp4 -i logo.jpg -filter_complex overlay=0:H-h output.mp4 

# 需要限制logo图片的大小，这样才不至于让logo图片占据过大
ffmpeg -i input2.mp4 -vf "movie=logo.jpg,scale= 60: 30[watermask]; [in] [watermask] overlay=30:10 [out]" output_logo.mp4
# scale是用来设置宽高的

# 去掉视频的logo
# -vf delogo=x:y:w:h[:t[:show]]
# x:y 离左上角的坐标 
# w:h logo的宽和高 
# t: 矩形边缘的厚度默认值4 
# show：若设置为1有一个绿色的矩形，默认值0。
ffmpeg -i output_logo.mp4 -vf delogo=30:10:60:30:1 output_no_logo.mp4
```

### 查看本地的可用录制设备

```shell
# linux
ffmpeg -devices

# windows
ffmpeg -list_devices true -f dshow -i dummy 
```

### 采集

```shell
# windows

# 采集音频
ffmpeg -f dshow -i audio="内装麦克风 (Conexant ISST Audio)" window.mp3 
ffmpeg -f dshow -i audio="内装麦克风 (Conexant ISST Audio)" -acodec libmp3lame window.mp3 # 指定音频格式

# 采集系统声音
系统声音：ffmpeg -f dshow -i audio="virtual-audio-capturer" a-out.aac

# 采集视频频
 ffmpeg -f dshow -i video="HP HD Camera" window.mp4
 
 # 系统+麦克风声音
 ffmpeg -f dshow -i audio="麦克风 (Realtek Audio)"-f dshow -i audio="virtual-audio-capturer" -filter_complex amix=inputs=2:duration=first:dropout_transition=2 a-out2.aac
 
 # 采集桌面
 ffmpeg -f dshow -i video="screen-capture-recorder" v-out.mp4
 
 # 采集音视频
 ffmpeg -f dshow -i audio="内装麦克风 (Conexant ISST Audio)" -f dshow -i video="HP HD Camera" destop.mp4
ffmpeg -f dshow -i audio="麦克风(Realtek Audio)" -f dshow -i audio="virtual-audio-capturer" -filter_complex amix=inputs=2:duration=first:dropout_transition=2 -f dshow -i video="screen-capture-recorder"  -y av-out.flv

# 桌面+摄像头+麦克风
ffmpeg  -f dshow -framerate 15 -i video="screen-capture-recorder"  -f dshow -framerate 10 -i video="Integrated Webcam"  -filter_complex "[1]scale=iw/2:ih/2[pip];[0][pip]overlay=main_w-overlay_w-10:main_h-overlay_h-10" -f dshow -i audio="麦克风 (Realtek Audio)" -c:a aac -c:v h264_qsv -r 10 -b 3M -f flv  rtmp://111.229.231.225/live/33
```

- `-list_options true`
- `dshow-list_options true `

```shell
ffmpeg -f dshow -i audio="麦克风(Realtek Audio)" -f dshow -i audio="virtual-audio-capturer" -filter_complex amix=inputs=2:duration=first:dropout_transition=2 -fdshow -video_size1920x1080 -framerate 15 -pixel_format yuv420p  -i video="screen-capture-recorder" -vcodec h264_qsv  -b:v 3M  -y av-out.flv
ffmpeg -fdshow -i audio="麦克风(Realtek Audio)" -f dshow -i audio="virtual-audio-capturer" -filter_complex amix=inputs=2:duration=first:dropout_transition=2 -f dshow -i video="screen-capture-recorder" -vcodec h264_qsv  -b:v 3M-r 15 -y av-out2.mp4
ffmpeg -fdshow -i audio="麦克风(Realtek Audio)" -f dshow -i audio="virtual-audio-capturer" -filter_complex amix=inputs=2:duration=first:dropout_transition=2 -f dshow-framerate 15 -pixel_format yuv420p -i video="screen-capture-recorder" -vcodec h264_qsv  -b:v 3M-r 15 -y av-out3.mp4
```



### 推流

```shell
# rtp推流
# 先用ffplay检测摄像头是否正常
ffplay -f dshow -i video="USB2.0 PC CAMERA"
ffmpeg -f dshow -i video="USB2.0 PC CAMERA" -vcodec libx264 -f rtp rtp://192.168.2.208:6970 > test.sdp

# rtp 拉流
ffplay -protocol_whitelist "file,udp,rtp" -i test.sdp
```

```shell
# rtmp拉流
ffplay rtmp://server/live/streamName 
ffmpeg -i rtmp://server/live/streamName -c copy dump.flv

#ffmpeg推流
ffmpeg -re -i out.mp4 -c copy flv rtmp://server/live/streamName
```



### 裁剪

```shell
ffmpeg -i input -vf crop=iw/3:ih:0:0   output 
ffmpeg -i input -vf crop=iw/3:ih:iw/3:0   output 
ffmpeg -i input -vf crop=iw/3:ih:iw/3*2:0 output
```

> 练习题：（1）裁剪100x100的区域，起点为(12,34). `crop=100:100:12:34` 相同效果:` crop=w=100:h=100:x=12:y=34`
>
> （2）裁剪中心区域，大小为100x100` crop=100:100`
>
> （3）裁剪中心区域，大小为输入视频的2/3 `crop=2/3*in_w:2/3*in_h`
>
> （4）裁剪中心区域的正方形，高度为输入视频的高 `crop=out_w=in_h crop=in_h`
>
> （5）裁剪偏移左上角100像素 `crop=in_w-100:in_h-100:100:100`
>
> （6）裁剪掉左右10像素，上下20像素 `crop=in_w-2*10:in_h-2*20`
>
> （7）裁剪右下角区域 `crop=in_w/2:in_h/2:in_w/2:in_h/2`



### 文字水印

​		在视频中增加文字水印需要准备的条件比较多:

- 需要有文字字库处理的相关文件
- 在编译FFmpeg时需要支持FreeType、FontConfig、iconv
- 系统中需要有相关的字库
- 在FFmpeg中增加纯字母水印可以使用drawtext滤镜进行支持

```shell
# 将文字的水印加在视频的左上角：
ffplay -i input.mp4 -vf "drawtext=fontsize=100:fontfile=FreeSerif.ttf:text='hello world':x=20:y=20"
# 将字体的颜色设置为绿色：
ffplay -i input.mp4 -vf "drawtext=fontsize=100:fontfile=FreeSerif.ttf:text='hello world':fontcolor=green"
# 调整文字水印显示的位置
ffplay -i input.mp4 -vf "drawtext=fontsize=100:fontfile=FreeSerif.ttf:text='hello world':fontcolor=green:x=400:y=200"
# 修改透明度
ffplay -i input.mp4 -vf "drawtext=fontsize=100:fontfile=FreeSerif.ttf:text='hello world':fontcolor=green:x=400:y=200:alpha=0.5"
ffplay -i input.mp4 -vf "drawtext=fontsize=40:fontfile=FreeSerif.ttf:text='liaoqingfu':x=mod(50*t\,w):y=abs(sin(t))*h*0.7:alpha=0.5:fontcolor=white:enable=lt(mod(t\,3)\,1)"
# 文字水印还可以增加一个框，然后给框加上背景颜色：
ffplay -i input.mp4 -vf "drawtext=fontsize=100:fontfile=FreeSerif.ttf:text='hello world':fontcolor=green:box=1:boxcolor=yellow"
# 本地时间作为水印内容
# 可以在drawtext滤镜中配合一些特殊用法来完成，在text中显示本地当前时间，格式为年月日时分秒的方式
ffplay  -i input.mp4 -vf "drawtext=fontsize=60:fontfile=FreeSerif.ttf:text='%{localtime\:%Y\-%m\-%d %H-%M-%S}':fontcolor=green:box=1:boxcolor=yellow"
# 在使用ffmpeg转码将水印存储到文件时需要加上-re，否则时间不对。
ffmpeg -re -i input.mp4 -vf "drawtext=fontsize=60:fontfile=FreeSerif.ttf:text='%{localtime\:%Y\-%m\-%d %H-%M-%S}':fontcolor=green:box=1:boxcolor=yellow" out.mp4
# 周期显示水印
# 这种方式同样可以配合drawtext滤镜进行处理，使用drawtext与enable配合即可
# 表达式参考：https://www.ffmpeg.org/ffmpeg-utils.html#Expression-Evaluation
ffplay -i input.mp4 -vf "drawtext=fontsize=60:fontfile=FreeSerif.ttf:text='test':fontcolor=green:box=1:boxcolor=yellow:enable=lt(mod(t\,3)\,1)"
# 跑马灯效果
ffplay -i input.mp4 -vf "drawtext=fontsize=100:fontfile=FreeSerif.ttf:text='helloworld':x=mod(100*t\,w):y=abs(sin(t))*h*0.7"
```

### 图片水印

- movie
- overlay

```shell
ffmpeg -i input.mp4 -vf "movie=logo.png[watermark];[in][watermark]overlay=x=10:y=10[out]" output.mp4
+ffplay -i input.mp4 -vf "movie=logo.png[watermark];[in][watermark]overlay=main_w-overlay_w-10:10[out]" # 右上角
# 跑马灯
# mod(50*t\,main_w) 表示 x 坐标随时间变化，每秒钟移动 50 个像素，当超出屏幕宽度时自动循环
# abs(sin(t))*h*0.7 则表示 y 坐标随时间变化，根据正弦函数周期性地上下浮动，并占据整个屏幕高度的 70%
ffplay -i input.mp4 -vf "movie=logo.png[watermark];[in][watermark]overlay=x=mod(50*t\,main_w):y=abs(sin(t))*h*0.7[out]"
```



### 画中画

​		通过overlay将多个视频流、多个多媒体采集设备、多个视频文件合并到一个界面中，生成画中画的效果。

```shell
 # 输入流中的某一个结束时，滤镜将停止处理
 ffplay -i input.mp4 -vf "movie=sub_320x240.mp4[sub];[in][sub]overlay=x=20:y=20:shortest=1[out]"
 # 当叠加层结束时，将停止处理
 ffplay -i input.mp4 -vf "movie=sub_320x240.mp4[sub];[in][sub]overlay=x=20:y=20:eof_action=1[out]"
 # 缩放并叠加
 ffplay -i input.mp4 -vf "movie=sub_320x240.mp4,scale=640x480[sub];[in][sub]overlay=x=20:y=20[out]"
 # 跑马灯
 ffplay -i input.mp4 -vf "movie=sub_320x240.mp4[test];[in][test]overlay= x=mod(50*t\,main_w):y=abs(sin(t))*main_h*0.7[out]"
```



### 多宫格

​		可以输入视频文件，还可以输入视频流、采集设备等，自己建立一个足够大的画布。

```shell
ffmpeg -i 1.mp4 -i 2.mp4 -i 3.mp4 -i 4.mp4 -filter_complex "nullsrc=size=640x480[base];[0:v] setpts=PTS-STARTPTS,scale=320x240[upperleft];[1:v]setpts=PTS-STARTPTS,scale=320x240[upperright];[2:v]setpts=PTS-STARTPTS, scale=320x240[lowerleft];[3:v]setpts=PTS-STARTPTS,scale=320x240[lowerright];[base][upperleft]overlay=shortest=1[tmp1];[tmp1][upperright]overlay=shortest=1:x=320[tmp2];[tmp2][lowerleft]overlay=shortest=1:y=240[tmp3];[tmp3][lowerright]overlay=shortest=1:x=320:y=240" out.mp4

# 只叠加左上右上的命令：
ffmpeg -i 1.mp4 -i 2.mp4 -i  3.mp4 -i  4.mp4 -filter_complex "nullsrc=size=640x480[base];[0:v]setpts=PTS-STARTPTS,scale=320x240[upperleft];[1:v]setpts=PTS-STARTPTS,scale=320x240[upperright];[base][upperleft]overlay=shortest=1[tmp1];[tmp1][upperright]overlay=shortest=1:x=320" out2.mp4
```

> 通过nullsrc创建overlay画布，画布大小640:480, 使用`[0:v][1:v][2:v][3:v]`将输入的4个视频流去除，分别进行缩放处理，然后基于nullsrc生成的画布进行视频平铺，命令中自定义upperleft,upperright,lowerleft,lowerright进行不同位置平铺。

![img](https://raw.githubusercontent.com/Mocearan/picgo-server/main/b3f8f1fa79fd4fd3b6344f23afb5b6b5.png)

![img](https://raw.githubusercontent.com/Mocearan/picgo-server/main/71e43005f09e394491adf5ddbd336442.png)
